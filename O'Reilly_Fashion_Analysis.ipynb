{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fashion MNIST with Keras\n",
    "Reference: Chapter Ten (O'Reilly)\n",
    "\n",
    "Fashion MNIST is the same structure as the Handwriting MNIST dataset. 28 x 28 pixels each with 10 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.11.0\n",
      "2.11.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "print(tf.__version__)\n",
    "print(tf.keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load in the fasion MNIST dataset\n",
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('uint8')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_full.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid, X_train, = X_train_full[:5000] / 255.0, X_train_full[5000:] / 255.0\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Coat'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names= [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\", \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]\n",
    "class_names[y_train[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function that displays an image with its label based on the index\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "   \n",
    "def plot_image(image_array, label_array, num):\n",
    "    image=image_array[num]\n",
    "    plt.imshow(image, cmap=\"binary\")\n",
    "    plt.axis(\"off\")\n",
    "    label = class_names[label_array[num]]\n",
    "    plt.title(label)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_image(X_train, y_train, 45)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the Model Using Sequential API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
    "model.add(keras.layers.Dense(300, activation=\"relu\"))\n",
    "model.add(keras.layers.Dense(100, activation=\"relu\"))\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\"))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explaination of the dense layers added in the above sequential call to Keras.\n",
    "\n",
    "The first line creates a Sequential model. Simple and easy; they may only express models with a single input and a single output via a simple stack of layers.\n",
    "\n",
    "The FLATTEN layer is built into the model first. Its role is to flatten the image into a 1D array for preprocessing purposes (think grayscaling). As the first layer, one should specify the input shape, which doesn't include the batch size, only the shape of instances.\n",
    "\n",
    "Next, we add a DENSE layer with 300 neurons. Each Desnse layer manages its own weight matrix, containing all the connectino weights between the neurons and their inputs. \n",
    "\n",
    "We then add another DENSE layer with 100 neurons to further funnel the outputs.\n",
    "\n",
    "Last, we add a DENSE output layher with 10 neurons (ONE per CLASS) using the softmax function (because the classes are EXCLUSIVE)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_1 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 300)               235500    \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 100)               30100     \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 266,610\n",
      "Trainable params: 266,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that Dense layers (unlike what playground.tensorflow.org may have impressed), DENSE layers tend to have a LOT of parameters. \n",
    "\n",
    "In this case, the first layer has *784 (pixel matrixes) x 300* connection weights (per neuron), plus *300 bias terms* (per neuron), which end up to *235,500 parameters*. This gives us much flexibility but risks overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.layers.reshaping.flatten.Flatten at 0x2962cad1b88>,\n",
       " <keras.layers.core.dense.Dense at 0x2962cad6308>,\n",
       " <keras.layers.core.dense.Dense at 0x2962cad8bc8>,\n",
       " <keras.layers.core.dense.Dense at 0x2962cad8948>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can get a model's list of layers, to fetch a layer by index, or you can fetch it by name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden1 = model.layers[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dense_10'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden1.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.layers.reshaping.flatten.Flatten at 0x2962cad1b88>,\n",
       " <keras.layers.core.dense.Dense at 0x2962cad6308>,\n",
       " <keras.layers.core.dense.Dense at 0x2962cad8bc8>,\n",
       " <keras.layers.core.dense.Dense at 0x2962cad8948>]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No such layer: dense. Existing layers are: ['flatten_1', 'dense_10', 'dense_11', 'dense_12'].",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_38060\\1426901790.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_layer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'dense'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mhidden1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mget_layer\u001b[1;34m(self, name, index)\u001b[0m\n\u001b[0;32m   3352\u001b[0m                     \u001b[1;32mreturn\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3353\u001b[0m             raise ValueError(\n\u001b[1;32m-> 3354\u001b[1;33m                 \u001b[1;34mf\"No such layer: {name}. Existing layers are: \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3355\u001b[0m                 \u001b[1;34mf\"{list(layer.name for layer in self.layers)}.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3356\u001b[0m             )\n",
      "\u001b[1;31mValueError\u001b[0m: No such layer: dense. Existing layers are: ['flatten_1', 'dense_10', 'dense_11', 'dense_12']."
     ]
    }
   ],
   "source": [
    "model.get_layer('dense') is hidden1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All parameters of a layer can be accessed by using its 'get_weights()' and 'set_weights' functions. For Dense layers, this includes both the connection weights and the bias terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights, biases = hidden1.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.07126597,  0.02746464,  0.02417776, ..., -0.06754255,\n",
       "        -0.03695148,  0.02144049],\n",
       "       [ 0.02382305, -0.04854286, -0.02558806, ...,  0.00784048,\n",
       "        -0.01633128, -0.03687744],\n",
       "       [-0.01580964,  0.00238874, -0.01975573, ..., -0.06454739,\n",
       "         0.01676957,  0.07035838],\n",
       "       ...,\n",
       "       [-0.04870027,  0.05170664,  0.0337043 , ...,  0.01456058,\n",
       "         0.06841913, -0.02340898],\n",
       "       [ 0.03847016, -0.05185176,  0.03938385, ...,  0.05068918,\n",
       "         0.05937178,  0.04027274],\n",
       "       [-0.05432635,  0.02924786,  0.07335368, ..., -0.03133662,\n",
       "         0.04832038, -0.04983228]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 300)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biases.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After creating a model, you must call its compile() method to specify the loss function and the optimizer to use. Optionally, you can also specify a list of extra metrics to compute during training and evaluation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"sgd\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Evaluation\n",
    "# TODO - EXPLAINATION\n",
    "\n",
    "\"Sparse Categorical Cross Entropy\" is the loss called upon because we have \"sparse labels\" (i.e. for each instance there is a target class index from 0 to 9). \n",
    "\n",
    "If we had one target probability per class for each instance (such as with one-hot vectors to represent a class) we'd use \"categorical_crossentropy\" loss instead. If we were doing binary classification we'd use \"sigmoid (i.e. logistic) activation in the output layer instead of \"softmax\" activation and we'd use \"binary_crossentrophy\" loss.\n",
    "\n",
    "As we call the .fit() method, we pass in the input features (X_train) and the target classes (y_train). We set a number of epochs, and optionally, a validation data set. \n",
    "\n",
    "**Loss** - The differenc between the predicted output of a neural network and the actual output. This should be going down with further epochs.\n",
    "\n",
    "\n",
    "Keras will measure the loss and extra metrics on this set at the end of each epoch. This is useful for gauging how well the model is performing. If performance on the training set is much better than on the validation set, the model is probably overfitting the training set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.7119 - accuracy: 0.7656 - val_loss: 0.4912 - val_accuracy: 0.8406\n",
      "Epoch 2/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.4813 - accuracy: 0.8325 - val_loss: 0.4466 - val_accuracy: 0.8484\n",
      "Epoch 3/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.4385 - accuracy: 0.8447 - val_loss: 0.4209 - val_accuracy: 0.8578\n",
      "Epoch 4/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.4105 - accuracy: 0.8545 - val_loss: 0.4258 - val_accuracy: 0.8448\n",
      "Epoch 5/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3908 - accuracy: 0.8618 - val_loss: 0.3685 - val_accuracy: 0.8732\n",
      "Epoch 6/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3741 - accuracy: 0.8668 - val_loss: 0.3839 - val_accuracy: 0.8680\n",
      "Epoch 7/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3604 - accuracy: 0.8729 - val_loss: 0.3671 - val_accuracy: 0.8724\n",
      "Epoch 8/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3495 - accuracy: 0.8758 - val_loss: 0.3586 - val_accuracy: 0.8762\n",
      "Epoch 9/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3378 - accuracy: 0.8795 - val_loss: 0.3527 - val_accuracy: 0.8748\n",
      "Epoch 10/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3299 - accuracy: 0.8821 - val_loss: 0.3582 - val_accuracy: 0.8756\n",
      "Epoch 11/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3219 - accuracy: 0.8859 - val_loss: 0.3308 - val_accuracy: 0.8864\n",
      "Epoch 12/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3133 - accuracy: 0.8884 - val_loss: 0.3370 - val_accuracy: 0.8826\n",
      "Epoch 13/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3056 - accuracy: 0.8899 - val_loss: 0.3265 - val_accuracy: 0.8858\n",
      "Epoch 14/30\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.2980 - accuracy: 0.8934 - val_loss: 0.3188 - val_accuracy: 0.8858\n",
      "Epoch 15/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2914 - accuracy: 0.8965 - val_loss: 0.3267 - val_accuracy: 0.8866\n",
      "Epoch 16/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2867 - accuracy: 0.8968 - val_loss: 0.3149 - val_accuracy: 0.8866\n",
      "Epoch 17/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2802 - accuracy: 0.8996 - val_loss: 0.3202 - val_accuracy: 0.8856\n",
      "Epoch 18/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2743 - accuracy: 0.9008 - val_loss: 0.3185 - val_accuracy: 0.8840\n",
      "Epoch 19/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2695 - accuracy: 0.9028 - val_loss: 0.3160 - val_accuracy: 0.8876\n",
      "Epoch 20/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2657 - accuracy: 0.9031 - val_loss: 0.3244 - val_accuracy: 0.8836\n",
      "Epoch 21/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2599 - accuracy: 0.9063 - val_loss: 0.3151 - val_accuracy: 0.8884\n",
      "Epoch 22/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2550 - accuracy: 0.9089 - val_loss: 0.3043 - val_accuracy: 0.8912\n",
      "Epoch 23/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2509 - accuracy: 0.9092 - val_loss: 0.3366 - val_accuracy: 0.8746\n",
      "Epoch 24/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2469 - accuracy: 0.9113 - val_loss: 0.3074 - val_accuracy: 0.8914\n",
      "Epoch 25/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2418 - accuracy: 0.9134 - val_loss: 0.3429 - val_accuracy: 0.8776\n",
      "Epoch 26/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2380 - accuracy: 0.9145 - val_loss: 0.2972 - val_accuracy: 0.8952\n",
      "Epoch 27/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2343 - accuracy: 0.9161 - val_loss: 0.3158 - val_accuracy: 0.8892\n",
      "Epoch 28/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2303 - accuracy: 0.9177 - val_loss: 0.3097 - val_accuracy: 0.8896\n",
      "Epoch 29/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2251 - accuracy: 0.9196 - val_loss: 0.3008 - val_accuracy: 0.8926\n",
      "Epoch 30/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2223 - accuracy: 0.9211 - val_loss: 0.2970 - val_accuracy: 0.8952\n"
     ]
    }
   ],
   "source": [
    "# Training and Evaluation\n",
    "history = model.fit(X_train, y_train, epochs=30, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The neural network is now trained. The \"fit\" method of the model returns a History object containing the training parameters and their history. \n",
    "\n",
    "This can be used to create a plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'verbose': 1, 'epochs': 30, 'steps': 1719}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXPLAINATION for above\n",
    "The loss and accuracy curves should more or less correllate to the validation loss and accuracy curves. Otherwise we'd have overfitting.\n",
    "\n",
    "If not satisified, one can tune the hyperparemeters. Among them is to first check the...\n",
    "\n",
    "    -Learning Rate\n",
    "    -Optimizer\n",
    "    -Number of layers\n",
    "    -Number of neurons per layer\n",
    "    -Batch size\n",
    "    -Types of activation for each hidden layer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next you can evaluate your model on a test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 1ms/step - loss: 58.1531 - accuracy: 0.8560\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[58.15305709838867, 0.8560000061988831]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 67ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using the model to make predictions\n",
    "X_new = X_test[:3]\n",
    "y_proba = model.predict(X_new)\n",
    "y_proba.round(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 17ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X_new)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 2, 1], dtype=uint8)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_new = y_test[:3]\n",
    "y_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "model.save(\"my_keras_fashion_model.h5\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Regression MLP using Sequential API\n",
    "Let's go back to the California Housing Data Problem and do it with Keras. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll use the sklearn version of the dataset as it contains only numerical features and no missing values\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "housing = fetch_california_housing()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.526, 3.585, 3.521, ..., 0.923, 0.847, 0.894])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the housing data\n",
    "housing.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_full, X_test, y_train_full, y_test = train_test_split(housing.data, housing.target)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.7958 - val_loss: 3.8316\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 2.1290 - val_loss: 0.5063\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4550 - val_loss: 0.6530\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4750 - val_loss: 0.4445\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4239 - val_loss: 0.3992\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3837 - val_loss: 0.3855\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3743 - val_loss: 0.3969\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3701 - val_loss: 0.3818\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3672 - val_loss: 0.3799\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3662 - val_loss: 0.3942\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3631 - val_loss: 0.3709\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3578 - val_loss: 0.3707\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3568 - val_loss: 0.3689\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3550 - val_loss: 0.3746\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3523 - val_loss: 0.3645\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3504 - val_loss: 0.3633\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3481 - val_loss: 0.3680\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3478 - val_loss: 0.3637\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3450 - val_loss: 0.3710\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3446 - val_loss: 0.3558\n"
     ]
    }
   ],
   "source": [
    "# Building a Regression MLP Using the Sequential API\n",
    "model = keras.models.Sequential([keras.layers.Dense(30, activation=\"relu\", input_shape=X_train.shape[1:]), \n",
    "                                    keras.layers.Dense(1)])\n",
    "\n",
    "# time to compile the model\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=\"sgd\")\n",
    "history = model.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 826us/step - loss: 0.3378\n",
      "1/1 [==============================] - 0s 40ms/step\n"
     ]
    }
   ],
   "source": [
    "# test the mse\n",
    "mse_test = model.evaluate(X_test, y_test)\n",
    "X_new = X_test[:3]\n",
    "y_pred = model.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3378487825393677\n"
     ]
    }
   ],
   "source": [
    "# print the mse\n",
    "print(mse_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5812476086310959\n"
     ]
    }
   ],
   "source": [
    "#print the root mean squared error\n",
    "print(np.sqrt(mse_test))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras Functional API\n",
    "The Keras Sequential API is rather simple to use, but sometimes you need something  with more complex topologies, or multiple inputs or outputs. For this purpose, Keras offers the **Functional API**.\n",
    "\n",
    "One example is a *Wide and Deep* neural network. This connects all or part of the inputs *directly* to the output layer. This makes it possible for the neural network to learn both deep patterns (using the deep path) and simple rules (through the short path). In contrast, a normal MLP forces all data to flow through the full stack of layers. Simple data patterns may end up distored by this sequence of transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First, we create the input object. This is a specification for the kind of input we want to feed to our model, including its shape and dtype.\n",
    "input_ = keras.layers.Input(shape=X_train.shape[1:])\n",
    "#Next, we create the first hidden layer, specifying the number of neurons and the activation function. \n",
    "# Note that as soon as it's created we pass the input into it like a funcion, hence the term, functional API.\n",
    "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_)\n",
    "#Then we create the second hidden layer, again specifying the number of neurons and the activation function.\n",
    "# Note that we pass the output of the first hidden layer into this one.\n",
    "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "#We then create the concat layer, which will concatenate the input and the output of the second hidden layer.\n",
    "concat = keras.layers.Concatenate()([input_, hidden2])\n",
    "#Finally, we create the output layer, which will take the output of the concat layer and pass it through a single neuron with no activation function.\n",
    "output = keras.layers.Dense(1)(concat)\n",
    "#Finally, we create the model, specifying the inputs and outputs.\n",
    "model = keras.models.Model(inputs=[input_], outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.7359 - val_loss: 0.5480\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4546 - val_loss: 2.1722\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.2925 - val_loss: 50.0261\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n"
     ]
    }
   ],
   "source": [
    "# time to compile the model\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=\"sgd\")\n",
    "history = model.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 751us/step - loss: nan\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "nan\n"
     ]
    }
   ],
   "source": [
    "# test the mse\n",
    "mse_test = model.evaluate(X_test, y_test)\n",
    "X_new = X_test[:3]\n",
    "y_pred = model.predict(X_new)\n",
    "\n",
    "# print the mse\n",
    "print(mse_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if you want to send a subset of the features through the wide path, and a different subset (possibly overlapping) through the deep path? In this case, you will need multiple inputs. For example, suppose you want to send the first five features through the wide path, and the remaining 6 features through the deep path. You could do this using the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputA = keras.layers.Input(shape=[5], name=\"wide_input\")\n",
    "inputB = keras.layers.Input(shape=[6], name=\"deep_input\")\n",
    "hidden1 = keras.layers.Dense(30, activation=\"relu\")(inputB)\n",
    "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "concat = keras.layers.concatenate([inputA, hidden2])\n",
    "output = keras.layers.Dense(1, name=\"output\")(concat)\n",
    "model = keras.models.Model(inputs=[inputA, inputB], outputs=[output])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time to compile the model, however when we call the fit method, we must pass it a tuple containing both the inputs (X_train_A and X_train_B) and the targets (y_train).\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=\"sgd\")\n",
    "\n",
    "X_train_A, X_train_B = X_train[:, :5], X_train[:, 2:]\n",
    "X_valid_A, X_valid_B = X_valid[:, :5], X_valid[:, 2:]\n",
    "X_test_A, X_test_B = X_test[:, :5], X_test[:, 2:]\n",
    "X_new_A, X_new_B = X_test_A[:3], X_test_B[:3]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.8311 - val_loss: 3.2897\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.4000 - val_loss: 4.0849\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n"
     ]
    }
   ],
   "source": [
    "history = model.fit((X_train_A, X_train_B), y_train, epochs=20, validation_data=((X_valid_A, X_valid_B), y_valid))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 879us/step - loss: nan\n",
      "1/1 [==============================] - 0s 46ms/step\n"
     ]
    }
   ],
   "source": [
    "mse_test = model.evaluate((X_test_A, X_test_B), y_test)\n",
    "y_pred = model.predict((X_new_A, X_new_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n",
      "nan\n"
     ]
    }
   ],
   "source": [
    "# print the mse and rmse\n",
    "print(mse_test)\n",
    "print(np.sqrt(mse_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The root mean squared error is:  nan\n"
     ]
    }
   ],
   "source": [
    "#print out the conclusion statement\n",
    "print(\"The root mean squared error is: \", np.sqrt(mse_test))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cases you may want to have mulitple outputs\n",
    "\n",
    "### Task Demands It.\n",
    "Say you want to locate and classify the main object of a picture. This is BOTH a *regression* AND a *classification* task (find the object in the center, it's width and height, then classify it).\n",
    "\n",
    "### You Have Multiple Independent Tasks on the Same Data\n",
    "You *COULD* train one neural network per task...\n",
    "...\n",
    "...better idea: train a single neural network with multiple outputs per task. This is because the NN can then learn features in the data that useful across tasks. \n",
    "\n",
    "Example: **multitask** classification - you want to identify a human face in a picture AND identify their facial expression.\n",
    "\n",
    "### You Want to Reduce Overfitting by Training a Regularization\n",
    "You may want to add auxiliary outputs to an NN to ensure the underlying part of the NN learns something useful on its own without relying on the rest of the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## To add extra outputs, just connect them to the appropriate layers and create a model with the appropriate inputs and outputs.\n",
    "\n",
    "output = keras.layers.Dense(1, name=\"main_output\")(concat)\n",
    "aux_output = keras.layers.Dense(1, name=\"aux_output\")(hidden2) #now we have hidden2 branching off into it's own output, without concatenating it with inputA.\n",
    "model = keras.models.Model(inputs=[inputA, inputB], outputs=[output, aux_output]) # just add the aux_output to the outputs list.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time to compile the model (again), however when we call the fit method, we must pass it a tuple containing both the inputs (X_train_A and X_train_B) and the targets (y_train).\n",
    "model.compile(loss=[\"mse\", \"mse\"], loss_weights=[0.9, 0.1], optimizer=\"sgd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: nan - main_output_loss: nan - aux_output_loss: nan - val_loss: nan - val_main_output_loss: nan - val_aux_output_loss: nan\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - main_output_loss: nan - aux_output_loss: nan - val_loss: nan - val_main_output_loss: nan - val_aux_output_loss: nan\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - main_output_loss: nan - aux_output_loss: nan - val_loss: nan - val_main_output_loss: nan - val_aux_output_loss: nan\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: nan - main_output_loss: nan - aux_output_loss: nan - val_loss: nan - val_main_output_loss: nan - val_aux_output_loss: nan\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: nan - main_output_loss: nan - aux_output_loss: nan - val_loss: nan - val_main_output_loss: nan - val_aux_output_loss: nan\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - main_output_loss: nan - aux_output_loss: nan - val_loss: nan - val_main_output_loss: nan - val_aux_output_loss: nan\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - main_output_loss: nan - aux_output_loss: nan - val_loss: nan - val_main_output_loss: nan - val_aux_output_loss: nan\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - main_output_loss: nan - aux_output_loss: nan - val_loss: nan - val_main_output_loss: nan - val_aux_output_loss: nan\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - main_output_loss: nan - aux_output_loss: nan - val_loss: nan - val_main_output_loss: nan - val_aux_output_loss: nan\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - main_output_loss: nan - aux_output_loss: nan - val_loss: nan - val_main_output_loss: nan - val_aux_output_loss: nan\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - main_output_loss: nan - aux_output_loss: nan - val_loss: nan - val_main_output_loss: nan - val_aux_output_loss: nan\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - main_output_loss: nan - aux_output_loss: nan - val_loss: nan - val_main_output_loss: nan - val_aux_output_loss: nan\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - main_output_loss: nan - aux_output_loss: nan - val_loss: nan - val_main_output_loss: nan - val_aux_output_loss: nan\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - main_output_loss: nan - aux_output_loss: nan - val_loss: nan - val_main_output_loss: nan - val_aux_output_loss: nan\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: nan - main_output_loss: nan - aux_output_loss: nan - val_loss: nan - val_main_output_loss: nan - val_aux_output_loss: nan\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - main_output_loss: nan - aux_output_loss: nan - val_loss: nan - val_main_output_loss: nan - val_aux_output_loss: nan\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - main_output_loss: nan - aux_output_loss: nan - val_loss: nan - val_main_output_loss: nan - val_aux_output_loss: nan\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: nan - main_output_loss: nan - aux_output_loss: nan - val_loss: nan - val_main_output_loss: nan - val_aux_output_loss: nan\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - main_output_loss: nan - aux_output_loss: nan - val_loss: nan - val_main_output_loss: nan - val_aux_output_loss: nan\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - main_output_loss: nan - aux_output_loss: nan - val_loss: nan - val_main_output_loss: nan - val_aux_output_loss: nan\n"
     ]
    }
   ],
   "source": [
    "# now we need to provide labels for each output when we call the fit() method.\n",
    "history = model.fit([X_train_A, X_train_B], [y_train, y_train], epochs=20, validation_data=([X_valid_A, X_valid_B], [y_valid, y_valid]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 873us/step - loss: nan - main_output_loss: nan - aux_output_loss: nan\n",
      "WARNING:tensorflow:5 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000029627C73288> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 55ms/step\n"
     ]
    }
   ],
   "source": [
    "# finally, we reevaluate the model on the test set, and we get the total loss, as well as each output's loss.\n",
    "total_loss, main_loss, aux_loss = model.evaluate([X_test_A, X_test_B], [y_test, y_test])\n",
    "y_pred_main, y_pred_aux = model.predict([X_new_A, X_new_B])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n",
      "nan\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]]\n"
     ]
    }
   ],
   "source": [
    "# print the mse and rmse\n",
    "print(total_loss)\n",
    "print(np.sqrt(total_loss))\n",
    "print(y_pred_main)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subclassing API: Building Dynamic Models \n",
    "Both the Sequential and Functional APIs are declarative, but at the cost of being potentially static. You start by declaring the layers you want, how they should be connected, then and ONLY then do you start feeding it information, etc. \n",
    "\n",
    " \n",
    "This makes them easy to save, share and clone. The structure can be displayed and analyzed so errors can be caught early. \n",
    "For **supervised learning**, this generally is enough.\n",
    "\n",
    "Sometimes however you'll want models that may involve loops, various shapes, conditional branching, or other dynamic behaviors for the sake of **generative learning**, **self-supervised learning**, and **reinforcement learning**.\n",
    "\n",
    "In this case, the built-in *fit()* command won't be enough; you'll want a more *imperitive* coding style, for which the Subclassing API exist. \n",
    "\n",
    "Simply subclass the Model class, create the layers you need in the constructor, and use the *call()* method.\n",
    "\n",
    "For example, we'll take the functional WideAndDeepModel we did above its own class and declare it within a constructor.\n",
    "\n",
    "(312, O'Reilly) (182, Manning)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To review, the typical training loop: \n",
    "\n",
    "### 1. Run the forward pass (compute the model's output) inside a gradient tape to obtain a *loss value* for the current batch of data.\n",
    "### 2. Retrieve the gradients of the *loss* with regard to the model's weights.\n",
    "### 3. Update the model's weights to minimize the loss value on the current data batch.\n",
    "\n",
    "These steps are repeated for as many epochs as called for and necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WideAndDeepModel(keras.Model):\n",
    "    def __init__(self, units=30, activation=\"relu\", **kwargs):\n",
    "        super().__init__(**kwargs) # handles standard args (e.g., name)\n",
    "        self.hidden1 = keras.layers.Dense(units, activation=activation)\n",
    "        self.hidden2 = keras.layers.Dense(units, activation=activation)\n",
    "        self.main_output = keras.layers.Dense(1)\n",
    "        self.aux_output = keras.layers.Dense(1)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        input_A, input_B = inputs\n",
    "        hidden1 = self.hidden1(input_B)\n",
    "        hidden2 = self.hidden2(hidden1)\n",
    "        concat = keras.layers.concatenate([input_A, hidden2])\n",
    "        main_output = self.main_output(concat)\n",
    "        aux_output = self.aux_output(hidden2)\n",
    "        return main_output, aux_output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *call()* method is very flexible, enabling us to do all kinds of things; for loops, if statements, low-level tensor operations, use your imagination!\n",
    "\n",
    "The cost is that because the architecture is hidden beneath the call() method, when  you call the summary method, you'll only get a list of lyaers without information on how they're connected. Can't easily save or load either, nor check shapes ahead of time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving a model. \n",
    "It's as simple as calling the .save() method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving and restoring a model\n",
    "model.save(\"my_keras_model.h5\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checkpoint saving the model\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_keras_model.h5\")\n",
    "history = model.fit([X_train_A, X_train_B], [y_train, y_train], epochs=10, validation_data=([X_valid_A, X_valid_B], [y_valid, y_valid]), callbacks=[checkpoint_cb])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "84d8cac4d95fdd2ab02498a6ec40a50cb9882041e67cb52e6d8bcfda00d28db9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
