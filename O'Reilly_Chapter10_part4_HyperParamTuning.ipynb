{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow \n",
    "import tensorflow as tf\n",
    "# import keras\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "model = keras.models.load_model('my_keras_fashion_model.h5')\n",
    "\n",
    "## load in the fasion MNIST dataset\n",
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "X_valid, X_train, = X_train_full[:5000] / 255.0, X_train_full[5000:] / 255.0\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine Tuning Hyperparameters \n",
    "\n",
    "The good thing about Neural Networks is that they're flexible. The downside is that it's tricky figuring out what combiniation of hyperparameters would be best.\n",
    "\n",
    "One option is to simply try many combinations of hyperparameters and see which is best on the validation set (or use K-Fold Validation). \n",
    "\n",
    "To do so, wrap the keras models in objects that mimic Scikit-Learn regressors. \n",
    "\n",
    "(320, O'Reilly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(n_hidden=1, n_neurons=30, learning_rate=3e-3, input_shape=[28, 28]):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Flatten(input_shape=input_shape))\n",
    "    for layer in range(n_hidden):\n",
    "        model.add(keras.layers.Dense(n_neurons, activation=\"relu\"))\n",
    "    model.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
    "    optimizer = keras.optimizers.SGD(lr=learning_rate)\n",
    "    model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras Regressor\n",
    "\n",
    "The keras regressor object is a thin wrapper around the Keras model built using the *build_model()* function defined above. Since hyperparameters weren't defined, it'll use the default hyperparameters defined in the *build_model()* method. Now it can it can be used like a normal sklearn regressor: We can train it using the *fit()* method, then evaulate it using the *score()* method. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\David\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "keras_reg = keras.wrappers.scikit_learn.KerasRegressor(build_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1719/1719 [==============================] - 3s 1ms/step - loss: 0.7860 - accuracy: 0.7423 - val_loss: 0.5728 - val_accuracy: 0.8060\n",
      "Epoch 2/100\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.5293 - accuracy: 0.8195 - val_loss: 0.4986 - val_accuracy: 0.8364\n",
      "Epoch 3/100\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.4827 - accuracy: 0.8329 - val_loss: 0.4606 - val_accuracy: 0.8470\n",
      "Epoch 4/100\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.4573 - accuracy: 0.8420 - val_loss: 0.4486 - val_accuracy: 0.8512\n",
      "Epoch 5/100\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.4399 - accuracy: 0.8479 - val_loss: 0.4299 - val_accuracy: 0.8596\n",
      "Epoch 6/100\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.4256 - accuracy: 0.8523 - val_loss: 0.4346 - val_accuracy: 0.8454\n",
      "Epoch 7/100\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.4143 - accuracy: 0.8561 - val_loss: 0.4037 - val_accuracy: 0.8648\n",
      "Epoch 8/100\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.4055 - accuracy: 0.8591 - val_loss: 0.4084 - val_accuracy: 0.8624\n",
      "Epoch 9/100\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.3970 - accuracy: 0.8625 - val_loss: 0.4004 - val_accuracy: 0.8662\n",
      "Epoch 10/100\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.3914 - accuracy: 0.8638 - val_loss: 0.3903 - val_accuracy: 0.8642\n",
      "Epoch 11/100\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.3855 - accuracy: 0.8666 - val_loss: 0.3904 - val_accuracy: 0.8706\n",
      "Epoch 12/100\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.3802 - accuracy: 0.8682 - val_loss: 0.3834 - val_accuracy: 0.8704\n",
      "Epoch 13/100\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.3755 - accuracy: 0.8697 - val_loss: 0.3880 - val_accuracy: 0.8672\n",
      "Epoch 14/100\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.3704 - accuracy: 0.8713 - val_loss: 0.3722 - val_accuracy: 0.8744\n",
      "Epoch 15/100\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.3669 - accuracy: 0.8717 - val_loss: 0.3796 - val_accuracy: 0.8704\n",
      "Epoch 16/100\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.3632 - accuracy: 0.8732 - val_loss: 0.3796 - val_accuracy: 0.8726\n",
      "Epoch 17/100\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.3594 - accuracy: 0.8741 - val_loss: 0.3707 - val_accuracy: 0.8732\n",
      "Epoch 18/100\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.3556 - accuracy: 0.8755 - val_loss: 0.3730 - val_accuracy: 0.8734\n",
      "Epoch 19/100\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.3524 - accuracy: 0.8777 - val_loss: 0.3811 - val_accuracy: 0.8692\n",
      "Epoch 20/100\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.3496 - accuracy: 0.8775 - val_loss: 0.3619 - val_accuracy: 0.8752\n",
      "Epoch 21/100\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.3456 - accuracy: 0.8789 - val_loss: 0.3676 - val_accuracy: 0.8720\n",
      "Epoch 22/100\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.3428 - accuracy: 0.8803 - val_loss: 0.3634 - val_accuracy: 0.8744\n",
      "Epoch 23/100\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.3405 - accuracy: 0.8810 - val_loss: 0.3559 - val_accuracy: 0.8782\n",
      "Epoch 24/100\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.3377 - accuracy: 0.8811 - val_loss: 0.3624 - val_accuracy: 0.8766\n",
      "Epoch 25/100\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.3358 - accuracy: 0.8820 - val_loss: 0.3537 - val_accuracy: 0.8778\n",
      "Epoch 26/100\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.3335 - accuracy: 0.8832 - val_loss: 0.3552 - val_accuracy: 0.8794\n",
      "Epoch 27/100\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.3301 - accuracy: 0.8833 - val_loss: 0.3550 - val_accuracy: 0.8756\n",
      "Epoch 28/100\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.3284 - accuracy: 0.8852 - val_loss: 0.3517 - val_accuracy: 0.8756\n",
      "Epoch 29/100\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.3254 - accuracy: 0.8843 - val_loss: 0.3532 - val_accuracy: 0.8760\n",
      "Epoch 30/100\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.3237 - accuracy: 0.8860 - val_loss: 0.3576 - val_accuracy: 0.8784\n",
      "Epoch 31/100\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.3217 - accuracy: 0.8867 - val_loss: 0.3598 - val_accuracy: 0.8782\n",
      "Epoch 32/100\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.3200 - accuracy: 0.8870 - val_loss: 0.3486 - val_accuracy: 0.8818\n",
      "Epoch 33/100\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.3179 - accuracy: 0.8879 - val_loss: 0.3495 - val_accuracy: 0.8740\n",
      "Epoch 34/100\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.3157 - accuracy: 0.8889 - val_loss: 0.3701 - val_accuracy: 0.8720\n",
      "Epoch 35/100\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.3149 - accuracy: 0.8892 - val_loss: 0.3569 - val_accuracy: 0.8756\n",
      "Epoch 36/100\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.3133 - accuracy: 0.8894 - val_loss: 0.3502 - val_accuracy: 0.8776\n",
      "Epoch 37/100\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.3113 - accuracy: 0.8896 - val_loss: 0.3485 - val_accuracy: 0.8754\n",
      "Epoch 38/100\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.3090 - accuracy: 0.8906 - val_loss: 0.3445 - val_accuracy: 0.8792\n",
      "Epoch 39/100\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.3073 - accuracy: 0.8914 - val_loss: 0.3513 - val_accuracy: 0.8740\n",
      "Epoch 40/100\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.3053 - accuracy: 0.8920 - val_loss: 0.3449 - val_accuracy: 0.8810\n",
      "Epoch 41/100\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.3044 - accuracy: 0.8937 - val_loss: 0.3455 - val_accuracy: 0.8778\n",
      "Epoch 42/100\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.3035 - accuracy: 0.8929 - val_loss: 0.3417 - val_accuracy: 0.8818\n",
      "Epoch 43/100\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.3014 - accuracy: 0.8946 - val_loss: 0.3518 - val_accuracy: 0.8722\n",
      "Epoch 44/100\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.3004 - accuracy: 0.8934 - val_loss: 0.3379 - val_accuracy: 0.8802\n",
      "Epoch 45/100\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2989 - accuracy: 0.8939 - val_loss: 0.3401 - val_accuracy: 0.8790\n",
      "Epoch 46/100\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2972 - accuracy: 0.8958 - val_loss: 0.3404 - val_accuracy: 0.8802\n",
      "Epoch 47/100\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2963 - accuracy: 0.8957 - val_loss: 0.3424 - val_accuracy: 0.8768\n",
      "Epoch 48/100\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2950 - accuracy: 0.8955 - val_loss: 0.3350 - val_accuracy: 0.8824\n",
      "Epoch 49/100\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2928 - accuracy: 0.8953 - val_loss: 0.3411 - val_accuracy: 0.8808\n",
      "Epoch 50/100\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2917 - accuracy: 0.8976 - val_loss: 0.3450 - val_accuracy: 0.8754\n",
      "Epoch 51/100\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2905 - accuracy: 0.8968 - val_loss: 0.3509 - val_accuracy: 0.8762\n",
      "Epoch 52/100\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2894 - accuracy: 0.8971 - val_loss: 0.3404 - val_accuracy: 0.8806\n",
      "Epoch 53/100\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2882 - accuracy: 0.8975 - val_loss: 0.3358 - val_accuracy: 0.8812\n",
      "Epoch 54/100\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2866 - accuracy: 0.8979 - val_loss: 0.3408 - val_accuracy: 0.8782\n",
      "Epoch 55/100\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2857 - accuracy: 0.8987 - val_loss: 0.3531 - val_accuracy: 0.8778\n",
      "Epoch 56/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2844 - accuracy: 0.8996 - val_loss: 0.3379 - val_accuracy: 0.8810\n",
      "Epoch 57/100\n",
      "1719/1719 [==============================] - 3s 1ms/step - loss: 0.2831 - accuracy: 0.8998 - val_loss: 0.3381 - val_accuracy: 0.8818\n",
      "Epoch 58/100\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2826 - accuracy: 0.8999 - val_loss: 0.3345 - val_accuracy: 0.8810\n",
      "Epoch 59/100\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2813 - accuracy: 0.8994 - val_loss: 0.3416 - val_accuracy: 0.8820\n",
      "Epoch 60/100\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2794 - accuracy: 0.9009 - val_loss: 0.3353 - val_accuracy: 0.8818\n",
      "Epoch 61/100\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2791 - accuracy: 0.9008 - val_loss: 0.3377 - val_accuracy: 0.8836\n",
      "Epoch 62/100\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2777 - accuracy: 0.9007 - val_loss: 0.3432 - val_accuracy: 0.8814\n",
      "Epoch 63/100\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2766 - accuracy: 0.9017 - val_loss: 0.3440 - val_accuracy: 0.8776\n",
      "Epoch 64/100\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2753 - accuracy: 0.9029 - val_loss: 0.3375 - val_accuracy: 0.8806\n",
      "Epoch 65/100\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2740 - accuracy: 0.9031 - val_loss: 0.3459 - val_accuracy: 0.8738\n",
      "Epoch 66/100\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2728 - accuracy: 0.9026 - val_loss: 0.3302 - val_accuracy: 0.8826\n",
      "Epoch 67/100\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2726 - accuracy: 0.9031 - val_loss: 0.3357 - val_accuracy: 0.8820\n",
      "Epoch 68/100\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2721 - accuracy: 0.9040 - val_loss: 0.3324 - val_accuracy: 0.8826\n",
      "Epoch 69/100\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2702 - accuracy: 0.9033 - val_loss: 0.3336 - val_accuracy: 0.8820\n",
      "Epoch 70/100\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2692 - accuracy: 0.9046 - val_loss: 0.3446 - val_accuracy: 0.8764\n",
      "Epoch 71/100\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2680 - accuracy: 0.9042 - val_loss: 0.3449 - val_accuracy: 0.8832\n",
      "Epoch 72/100\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2673 - accuracy: 0.9053 - val_loss: 0.3382 - val_accuracy: 0.8838\n",
      "Epoch 73/100\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2664 - accuracy: 0.9047 - val_loss: 0.3426 - val_accuracy: 0.8804\n",
      "Epoch 74/100\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2662 - accuracy: 0.9063 - val_loss: 0.3336 - val_accuracy: 0.8840\n",
      "Epoch 75/100\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2646 - accuracy: 0.9062 - val_loss: 0.3396 - val_accuracy: 0.8810\n",
      "Epoch 76/100\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2635 - accuracy: 0.9067 - val_loss: 0.3296 - val_accuracy: 0.8852\n",
      "Epoch 77/100\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2629 - accuracy: 0.9066 - val_loss: 0.3439 - val_accuracy: 0.8770\n",
      "Epoch 78/100\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2615 - accuracy: 0.9077 - val_loss: 0.3441 - val_accuracy: 0.8800\n",
      "Epoch 79/100\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2608 - accuracy: 0.9076 - val_loss: 0.3349 - val_accuracy: 0.8852\n",
      "Epoch 80/100\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2598 - accuracy: 0.9087 - val_loss: 0.3640 - val_accuracy: 0.8678\n",
      "Epoch 81/100\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2588 - accuracy: 0.9085 - val_loss: 0.3377 - val_accuracy: 0.8854\n",
      "Epoch 82/100\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2587 - accuracy: 0.9084 - val_loss: 0.3306 - val_accuracy: 0.8838\n",
      "Epoch 83/100\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2570 - accuracy: 0.9086 - val_loss: 0.3463 - val_accuracy: 0.8798\n",
      "Epoch 84/100\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2573 - accuracy: 0.9086 - val_loss: 0.3330 - val_accuracy: 0.8848\n",
      "Epoch 85/100\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2561 - accuracy: 0.9088 - val_loss: 0.3461 - val_accuracy: 0.8812\n",
      "Epoch 86/100\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2555 - accuracy: 0.9095 - val_loss: 0.3370 - val_accuracy: 0.8826\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 106.1182 - accuracy: 0.7996\n"
     ]
    }
   ],
   "source": [
    "keras_reg.fit(X_train, y_train, epochs=100, validation_data=(X_valid, y_valid), callbacks=[keras.callbacks.EarlyStopping(patience=10)])\n",
    "mse_test = keras_reg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 75ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = keras_reg.predict(X_test[:3])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note: any extra paramter passed to the fit() method will get passed to the underlying keras model. The score will also be the opposite of the MSE, as sklearn likes scores, not losses"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HOWEVER...\n",
    "\n",
    "We don't want to train a single model like this, we want to train hundreds of variants and see which performs best on the validation set. Since there's many hyperparameters, preferable to use a randomized search rather than grid search. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1146/1146 [==============================] - 2s 1ms/step - loss: 1.1609 - accuracy: 0.6030 - val_loss: 0.7294 - val_accuracy: 0.7542\n",
      "Epoch 2/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.6606 - accuracy: 0.7782 - val_loss: 0.6016 - val_accuracy: 0.7982\n",
      "Epoch 3/100\n",
      "1146/1146 [==============================] - 2s 1ms/step - loss: 0.5737 - accuracy: 0.8076 - val_loss: 0.5512 - val_accuracy: 0.8112\n",
      "Epoch 4/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.5306 - accuracy: 0.8187 - val_loss: 0.5091 - val_accuracy: 0.8246\n",
      "Epoch 5/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.5027 - accuracy: 0.8272 - val_loss: 0.4956 - val_accuracy: 0.8300\n",
      "Epoch 6/100\n",
      "1146/1146 [==============================] - 2s 1ms/step - loss: 0.4859 - accuracy: 0.8327 - val_loss: 0.4809 - val_accuracy: 0.8334\n",
      "Epoch 7/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4715 - accuracy: 0.8373 - val_loss: 0.4666 - val_accuracy: 0.8406\n",
      "Epoch 8/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4602 - accuracy: 0.8412 - val_loss: 0.4527 - val_accuracy: 0.8464\n",
      "Epoch 9/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4506 - accuracy: 0.8446 - val_loss: 0.4404 - val_accuracy: 0.8518\n",
      "Epoch 10/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4420 - accuracy: 0.8488 - val_loss: 0.4366 - val_accuracy: 0.8520\n",
      "Epoch 11/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4359 - accuracy: 0.8497 - val_loss: 0.4281 - val_accuracy: 0.8528\n",
      "Epoch 12/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4290 - accuracy: 0.8534 - val_loss: 0.4316 - val_accuracy: 0.8522\n",
      "Epoch 13/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4253 - accuracy: 0.8543 - val_loss: 0.4195 - val_accuracy: 0.8578\n",
      "Epoch 14/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4197 - accuracy: 0.8555 - val_loss: 0.4301 - val_accuracy: 0.8528\n",
      "Epoch 15/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4155 - accuracy: 0.8566 - val_loss: 0.4182 - val_accuracy: 0.8558\n",
      "Epoch 16/100\n",
      "1146/1146 [==============================] - 2s 1ms/step - loss: 0.4111 - accuracy: 0.8582 - val_loss: 0.4135 - val_accuracy: 0.8586\n",
      "Epoch 17/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4074 - accuracy: 0.8606 - val_loss: 0.4114 - val_accuracy: 0.8588\n",
      "Epoch 18/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4049 - accuracy: 0.8620 - val_loss: 0.4139 - val_accuracy: 0.8620\n",
      "Epoch 19/100\n",
      "1146/1146 [==============================] - 2s 1ms/step - loss: 0.4007 - accuracy: 0.8621 - val_loss: 0.4120 - val_accuracy: 0.8622\n",
      "Epoch 20/100\n",
      "1146/1146 [==============================] - 2s 1ms/step - loss: 0.3986 - accuracy: 0.8632 - val_loss: 0.4031 - val_accuracy: 0.8644\n",
      "Epoch 21/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3948 - accuracy: 0.8646 - val_loss: 0.4094 - val_accuracy: 0.8606\n",
      "Epoch 22/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3935 - accuracy: 0.8637 - val_loss: 0.4037 - val_accuracy: 0.8608\n",
      "Epoch 23/100\n",
      "1146/1146 [==============================] - 2s 1ms/step - loss: 0.3898 - accuracy: 0.8650 - val_loss: 0.3984 - val_accuracy: 0.8640\n",
      "Epoch 24/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3879 - accuracy: 0.8675 - val_loss: 0.4063 - val_accuracy: 0.8604\n",
      "Epoch 25/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3851 - accuracy: 0.8678 - val_loss: 0.4216 - val_accuracy: 0.8540\n",
      "Epoch 26/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3834 - accuracy: 0.8670 - val_loss: 0.4019 - val_accuracy: 0.8634\n",
      "Epoch 27/100\n",
      "1146/1146 [==============================] - 2s 1ms/step - loss: 0.3812 - accuracy: 0.8676 - val_loss: 0.3944 - val_accuracy: 0.8654\n",
      "Epoch 28/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3790 - accuracy: 0.8687 - val_loss: 0.4107 - val_accuracy: 0.8620\n",
      "Epoch 29/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3761 - accuracy: 0.8702 - val_loss: 0.3988 - val_accuracy: 0.8644\n",
      "Epoch 30/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3746 - accuracy: 0.8711 - val_loss: 0.3970 - val_accuracy: 0.8670\n",
      "Epoch 31/100\n",
      "1146/1146 [==============================] - 2s 1ms/step - loss: 0.3735 - accuracy: 0.8712 - val_loss: 0.3917 - val_accuracy: 0.8676\n",
      "Epoch 32/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3715 - accuracy: 0.8709 - val_loss: 0.4005 - val_accuracy: 0.8640\n",
      "Epoch 33/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3702 - accuracy: 0.8731 - val_loss: 0.3978 - val_accuracy: 0.8624\n",
      "Epoch 34/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3680 - accuracy: 0.8731 - val_loss: 0.4177 - val_accuracy: 0.8578\n",
      "Epoch 35/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3668 - accuracy: 0.8730 - val_loss: 0.3941 - val_accuracy: 0.8706\n",
      "Epoch 36/100\n",
      "1146/1146 [==============================] - 2s 1ms/step - loss: 0.3654 - accuracy: 0.8744 - val_loss: 0.3910 - val_accuracy: 0.8668\n",
      "Epoch 37/100\n",
      "1146/1146 [==============================] - 2s 1ms/step - loss: 0.3637 - accuracy: 0.8745 - val_loss: 0.3879 - val_accuracy: 0.8686\n",
      "Epoch 38/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3627 - accuracy: 0.8750 - val_loss: 0.3987 - val_accuracy: 0.8636\n",
      "Epoch 39/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3600 - accuracy: 0.8757 - val_loss: 0.4034 - val_accuracy: 0.8636\n",
      "Epoch 40/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3592 - accuracy: 0.8757 - val_loss: 0.3843 - val_accuracy: 0.8706\n",
      "Epoch 41/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3580 - accuracy: 0.8755 - val_loss: 0.3901 - val_accuracy: 0.8658\n",
      "Epoch 42/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3558 - accuracy: 0.8759 - val_loss: 0.4061 - val_accuracy: 0.8558\n",
      "Epoch 43/100\n",
      "1146/1146 [==============================] - 2s 1ms/step - loss: 0.3552 - accuracy: 0.8758 - val_loss: 0.3863 - val_accuracy: 0.8698\n",
      "Epoch 44/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3532 - accuracy: 0.8768 - val_loss: 0.4113 - val_accuracy: 0.8560\n",
      "Epoch 45/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3527 - accuracy: 0.8773 - val_loss: 0.3883 - val_accuracy: 0.8696\n",
      "Epoch 46/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3514 - accuracy: 0.8783 - val_loss: 0.3869 - val_accuracy: 0.8660\n",
      "Epoch 47/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3498 - accuracy: 0.8791 - val_loss: 0.3872 - val_accuracy: 0.8674\n",
      "Epoch 48/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3489 - accuracy: 0.8783 - val_loss: 0.3884 - val_accuracy: 0.8690\n",
      "Epoch 49/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3478 - accuracy: 0.8777 - val_loss: 0.3888 - val_accuracy: 0.8672\n",
      "Epoch 50/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3463 - accuracy: 0.8792 - val_loss: 0.3899 - val_accuracy: 0.8676\n",
      "573/573 [==============================] - 1s 1ms/step - loss: 0.4052 - accuracy: 0.8562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 1.0849 - accuracy: 0.6478 - val_loss: 0.6949 - val_accuracy: 0.7694\n",
      "Epoch 2/100\n",
      "1146/1146 [==============================] - 2s 1ms/step - loss: 0.6464 - accuracy: 0.7797 - val_loss: 0.5847 - val_accuracy: 0.8046\n",
      "Epoch 3/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.5683 - accuracy: 0.8027 - val_loss: 0.5305 - val_accuracy: 0.8240\n",
      "Epoch 4/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.5277 - accuracy: 0.8161 - val_loss: 0.5072 - val_accuracy: 0.8270\n",
      "Epoch 5/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.5007 - accuracy: 0.8249 - val_loss: 0.4956 - val_accuracy: 0.8352\n",
      "Epoch 6/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4830 - accuracy: 0.8304 - val_loss: 0.4795 - val_accuracy: 0.8368\n",
      "Epoch 7/100\n",
      "1146/1146 [==============================] - 2s 1ms/step - loss: 0.4687 - accuracy: 0.8362 - val_loss: 0.4664 - val_accuracy: 0.8390\n",
      "Epoch 8/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4586 - accuracy: 0.8393 - val_loss: 0.4601 - val_accuracy: 0.8448\n",
      "Epoch 9/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4498 - accuracy: 0.8406 - val_loss: 0.4519 - val_accuracy: 0.8474\n",
      "Epoch 10/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4424 - accuracy: 0.8445 - val_loss: 0.4401 - val_accuracy: 0.8460\n",
      "Epoch 11/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4365 - accuracy: 0.8458 - val_loss: 0.4416 - val_accuracy: 0.8504\n",
      "Epoch 12/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4308 - accuracy: 0.8496 - val_loss: 0.4310 - val_accuracy: 0.8532\n",
      "Epoch 13/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4252 - accuracy: 0.8494 - val_loss: 0.4379 - val_accuracy: 0.8478\n",
      "Epoch 14/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4218 - accuracy: 0.8520 - val_loss: 0.4234 - val_accuracy: 0.8568\n",
      "Epoch 15/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4178 - accuracy: 0.8545 - val_loss: 0.4295 - val_accuracy: 0.8524\n",
      "Epoch 16/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4132 - accuracy: 0.8545 - val_loss: 0.4184 - val_accuracy: 0.8552\n",
      "Epoch 17/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4092 - accuracy: 0.8560 - val_loss: 0.4401 - val_accuracy: 0.8414\n",
      "Epoch 18/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4065 - accuracy: 0.8570 - val_loss: 0.4401 - val_accuracy: 0.8426\n",
      "Epoch 19/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4043 - accuracy: 0.8568 - val_loss: 0.4119 - val_accuracy: 0.8584\n",
      "Epoch 20/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4012 - accuracy: 0.8597 - val_loss: 0.4159 - val_accuracy: 0.8500\n",
      "Epoch 21/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3977 - accuracy: 0.8610 - val_loss: 0.4176 - val_accuracy: 0.8550\n",
      "Epoch 22/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3960 - accuracy: 0.8606 - val_loss: 0.4212 - val_accuracy: 0.8524\n",
      "Epoch 23/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3922 - accuracy: 0.8607 - val_loss: 0.4068 - val_accuracy: 0.8594\n",
      "Epoch 24/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3892 - accuracy: 0.8622 - val_loss: 0.4125 - val_accuracy: 0.8542\n",
      "Epoch 25/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3878 - accuracy: 0.8627 - val_loss: 0.4027 - val_accuracy: 0.8566\n",
      "Epoch 26/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3843 - accuracy: 0.8653 - val_loss: 0.3976 - val_accuracy: 0.8604\n",
      "Epoch 27/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3815 - accuracy: 0.8663 - val_loss: 0.4055 - val_accuracy: 0.8602\n",
      "Epoch 28/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3787 - accuracy: 0.8654 - val_loss: 0.4230 - val_accuracy: 0.8522\n",
      "Epoch 29/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3773 - accuracy: 0.8665 - val_loss: 0.4023 - val_accuracy: 0.8628\n",
      "Epoch 30/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3736 - accuracy: 0.8674 - val_loss: 0.4044 - val_accuracy: 0.8592\n",
      "Epoch 31/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3714 - accuracy: 0.8682 - val_loss: 0.4271 - val_accuracy: 0.8464\n",
      "Epoch 32/100\n",
      "1146/1146 [==============================] - 2s 1ms/step - loss: 0.3701 - accuracy: 0.8686 - val_loss: 0.4043 - val_accuracy: 0.8564\n",
      "Epoch 33/100\n",
      "1146/1146 [==============================] - 2s 1ms/step - loss: 0.3669 - accuracy: 0.8697 - val_loss: 0.3905 - val_accuracy: 0.8634\n",
      "Epoch 34/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3654 - accuracy: 0.8697 - val_loss: 0.3909 - val_accuracy: 0.8644\n",
      "Epoch 35/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3630 - accuracy: 0.8708 - val_loss: 0.3882 - val_accuracy: 0.8646\n",
      "Epoch 36/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3604 - accuracy: 0.8718 - val_loss: 0.3919 - val_accuracy: 0.8628\n",
      "Epoch 37/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3594 - accuracy: 0.8730 - val_loss: 0.3916 - val_accuracy: 0.8644\n",
      "Epoch 38/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3573 - accuracy: 0.8736 - val_loss: 0.3942 - val_accuracy: 0.8606\n",
      "Epoch 39/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3559 - accuracy: 0.8732 - val_loss: 0.3863 - val_accuracy: 0.8666\n",
      "Epoch 40/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3536 - accuracy: 0.8746 - val_loss: 0.3994 - val_accuracy: 0.8576\n",
      "Epoch 41/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3515 - accuracy: 0.8736 - val_loss: 0.3976 - val_accuracy: 0.8572\n",
      "Epoch 42/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3493 - accuracy: 0.8751 - val_loss: 0.4144 - val_accuracy: 0.8522\n",
      "Epoch 43/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3488 - accuracy: 0.8766 - val_loss: 0.3887 - val_accuracy: 0.8642\n",
      "Epoch 44/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3472 - accuracy: 0.8760 - val_loss: 0.3924 - val_accuracy: 0.8656\n",
      "Epoch 45/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3450 - accuracy: 0.8778 - val_loss: 0.3982 - val_accuracy: 0.8620\n",
      "Epoch 46/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3438 - accuracy: 0.8777 - val_loss: 0.3824 - val_accuracy: 0.8654\n",
      "Epoch 47/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3431 - accuracy: 0.8786 - val_loss: 0.3878 - val_accuracy: 0.8668\n",
      "Epoch 48/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3407 - accuracy: 0.8790 - val_loss: 0.3879 - val_accuracy: 0.8664\n",
      "Epoch 49/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3400 - accuracy: 0.8796 - val_loss: 0.3931 - val_accuracy: 0.8624\n",
      "Epoch 50/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3387 - accuracy: 0.8789 - val_loss: 0.3935 - val_accuracy: 0.8640\n",
      "Epoch 51/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3379 - accuracy: 0.8795 - val_loss: 0.4044 - val_accuracy: 0.8628\n",
      "Epoch 52/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3362 - accuracy: 0.8807 - val_loss: 0.3859 - val_accuracy: 0.8626\n",
      "Epoch 53/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3348 - accuracy: 0.8800 - val_loss: 0.4031 - val_accuracy: 0.8594\n",
      "Epoch 54/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3339 - accuracy: 0.8817 - val_loss: 0.3870 - val_accuracy: 0.8666\n",
      "Epoch 55/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3334 - accuracy: 0.8816 - val_loss: 0.3960 - val_accuracy: 0.8590\n",
      "Epoch 56/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3326 - accuracy: 0.8810 - val_loss: 0.4008 - val_accuracy: 0.8584\n",
      "573/573 [==============================] - 1s 953us/step - loss: 0.3986 - accuracy: 0.8642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1146/1146 [==============================] - 2s 1ms/step - loss: 1.1055 - accuracy: 0.6283 - val_loss: 0.7125 - val_accuracy: 0.7596\n",
      "Epoch 2/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.6493 - accuracy: 0.7799 - val_loss: 0.5832 - val_accuracy: 0.7996\n",
      "Epoch 3/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.5652 - accuracy: 0.8063 - val_loss: 0.5344 - val_accuracy: 0.8192\n",
      "Epoch 4/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.5218 - accuracy: 0.8213 - val_loss: 0.4943 - val_accuracy: 0.8330\n",
      "Epoch 5/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4954 - accuracy: 0.8314 - val_loss: 0.4804 - val_accuracy: 0.8358\n",
      "Epoch 6/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4767 - accuracy: 0.8354 - val_loss: 0.4766 - val_accuracy: 0.8400\n",
      "Epoch 7/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4636 - accuracy: 0.8402 - val_loss: 0.4535 - val_accuracy: 0.8426\n",
      "Epoch 8/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4519 - accuracy: 0.8439 - val_loss: 0.4456 - val_accuracy: 0.8494\n",
      "Epoch 9/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4438 - accuracy: 0.8472 - val_loss: 0.4489 - val_accuracy: 0.8446\n",
      "Epoch 10/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4382 - accuracy: 0.8491 - val_loss: 0.4374 - val_accuracy: 0.8488\n",
      "Epoch 11/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4308 - accuracy: 0.8500 - val_loss: 0.4355 - val_accuracy: 0.8512\n",
      "Epoch 12/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4246 - accuracy: 0.8527 - val_loss: 0.4340 - val_accuracy: 0.8468\n",
      "Epoch 13/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4198 - accuracy: 0.8544 - val_loss: 0.4374 - val_accuracy: 0.8494\n",
      "Epoch 14/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4164 - accuracy: 0.8562 - val_loss: 0.4286 - val_accuracy: 0.8528\n",
      "Epoch 15/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4112 - accuracy: 0.8574 - val_loss: 0.4285 - val_accuracy: 0.8528\n",
      "Epoch 16/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4080 - accuracy: 0.8597 - val_loss: 0.4185 - val_accuracy: 0.8580\n",
      "Epoch 17/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4055 - accuracy: 0.8583 - val_loss: 0.4204 - val_accuracy: 0.8552\n",
      "Epoch 18/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4009 - accuracy: 0.8618 - val_loss: 0.4141 - val_accuracy: 0.8608\n",
      "Epoch 19/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3980 - accuracy: 0.8616 - val_loss: 0.4368 - val_accuracy: 0.8494\n",
      "Epoch 20/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3957 - accuracy: 0.8612 - val_loss: 0.4138 - val_accuracy: 0.8580\n",
      "Epoch 21/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3928 - accuracy: 0.8644 - val_loss: 0.4213 - val_accuracy: 0.8518\n",
      "Epoch 22/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3907 - accuracy: 0.8649 - val_loss: 0.4105 - val_accuracy: 0.8594\n",
      "Epoch 23/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3886 - accuracy: 0.8650 - val_loss: 0.4084 - val_accuracy: 0.8584\n",
      "Epoch 24/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3858 - accuracy: 0.8666 - val_loss: 0.4065 - val_accuracy: 0.8610\n",
      "Epoch 25/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3840 - accuracy: 0.8673 - val_loss: 0.4172 - val_accuracy: 0.8578\n",
      "Epoch 26/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3818 - accuracy: 0.8699 - val_loss: 0.4159 - val_accuracy: 0.8562\n",
      "Epoch 27/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3800 - accuracy: 0.8681 - val_loss: 0.4026 - val_accuracy: 0.8634\n",
      "Epoch 28/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3777 - accuracy: 0.8684 - val_loss: 0.4166 - val_accuracy: 0.8560\n",
      "Epoch 29/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3758 - accuracy: 0.8688 - val_loss: 0.4023 - val_accuracy: 0.8602\n",
      "Epoch 30/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3753 - accuracy: 0.8693 - val_loss: 0.4020 - val_accuracy: 0.8598\n",
      "Epoch 31/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3741 - accuracy: 0.8700 - val_loss: 0.4021 - val_accuracy: 0.8618\n",
      "Epoch 32/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3712 - accuracy: 0.8705 - val_loss: 0.4085 - val_accuracy: 0.8590\n",
      "Epoch 33/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3696 - accuracy: 0.8712 - val_loss: 0.4031 - val_accuracy: 0.8612\n",
      "Epoch 34/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3684 - accuracy: 0.8731 - val_loss: 0.4322 - val_accuracy: 0.8544\n",
      "Epoch 35/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3679 - accuracy: 0.8718 - val_loss: 0.4062 - val_accuracy: 0.8588\n",
      "Epoch 36/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3656 - accuracy: 0.8739 - val_loss: 0.4100 - val_accuracy: 0.8602\n",
      "Epoch 37/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3643 - accuracy: 0.8732 - val_loss: 0.4057 - val_accuracy: 0.8606\n",
      "Epoch 38/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3616 - accuracy: 0.8741 - val_loss: 0.3996 - val_accuracy: 0.8636\n",
      "Epoch 39/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3625 - accuracy: 0.8743 - val_loss: 0.4054 - val_accuracy: 0.8610\n",
      "Epoch 40/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3604 - accuracy: 0.8740 - val_loss: 0.4023 - val_accuracy: 0.8626\n",
      "Epoch 41/100\n",
      "1146/1146 [==============================] - 2s 1ms/step - loss: 0.3584 - accuracy: 0.8738 - val_loss: 0.4025 - val_accuracy: 0.8630\n",
      "Epoch 42/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3584 - accuracy: 0.8753 - val_loss: 0.3995 - val_accuracy: 0.8628\n",
      "Epoch 43/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3568 - accuracy: 0.8754 - val_loss: 0.4116 - val_accuracy: 0.8556\n",
      "Epoch 44/100\n",
      "1146/1146 [==============================] - 2s 1ms/step - loss: 0.3564 - accuracy: 0.8762 - val_loss: 0.3995 - val_accuracy: 0.8646\n",
      "Epoch 45/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3543 - accuracy: 0.8759 - val_loss: 0.4163 - val_accuracy: 0.8584\n",
      "Epoch 46/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3534 - accuracy: 0.8777 - val_loss: 0.4052 - val_accuracy: 0.8624\n",
      "Epoch 47/100\n",
      "1146/1146 [==============================] - 2s 1ms/step - loss: 0.3519 - accuracy: 0.8769 - val_loss: 0.4063 - val_accuracy: 0.8612\n",
      "Epoch 48/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3503 - accuracy: 0.8772 - val_loss: 0.3978 - val_accuracy: 0.8628\n",
      "Epoch 49/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.3510 - accuracy: 0.8775 - val_loss: 0.4034 - val_accuracy: 0.8590\n",
      "Epoch 50/100\n",
      "1146/1146 [==============================] - 2s 1ms/step - loss: 0.3497 - accuracy: 0.8763 - val_loss: 0.4030 - val_accuracy: 0.8624\n",
      "Epoch 51/100\n",
      "1146/1146 [==============================] - 2s 1ms/step - loss: 0.3481 - accuracy: 0.8797 - val_loss: 0.4088 - val_accuracy: 0.8596\n",
      "Epoch 52/100\n",
      "1146/1146 [==============================] - 2s 1ms/step - loss: 0.3467 - accuracy: 0.8783 - val_loss: 0.4005 - val_accuracy: 0.8610\n",
      "Epoch 53/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3461 - accuracy: 0.8799 - val_loss: 0.4269 - val_accuracy: 0.8520\n",
      "Epoch 54/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3453 - accuracy: 0.8803 - val_loss: 0.4063 - val_accuracy: 0.8620\n",
      "Epoch 55/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3432 - accuracy: 0.8798 - val_loss: 0.4071 - val_accuracy: 0.8582\n",
      "Epoch 56/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3437 - accuracy: 0.8804 - val_loss: 0.4129 - val_accuracy: 0.8558\n",
      "Epoch 57/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3427 - accuracy: 0.8810 - val_loss: 0.4011 - val_accuracy: 0.8598\n",
      "Epoch 58/100\n",
      "1146/1146 [==============================] - 2s 1ms/step - loss: 0.3425 - accuracy: 0.8792 - val_loss: 0.4042 - val_accuracy: 0.8614\n",
      "573/573 [==============================] - 1s 954us/step - loss: 0.4032 - accuracy: 0.8604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.9226 - accuracy: 0.7120 - val_loss: 0.6844 - val_accuracy: 0.7902\n",
      "Epoch 2/100\n",
      "1146/1146 [==============================] - 2s 1ms/step - loss: 0.6455 - accuracy: 0.7929 - val_loss: 0.6002 - val_accuracy: 0.8104\n",
      "Epoch 3/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.5855 - accuracy: 0.8117 - val_loss: 0.5582 - val_accuracy: 0.8222\n",
      "Epoch 4/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.5529 - accuracy: 0.8202 - val_loss: 0.5358 - val_accuracy: 0.8268\n",
      "Epoch 5/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.5314 - accuracy: 0.8250 - val_loss: 0.5219 - val_accuracy: 0.8280\n",
      "Epoch 6/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.5152 - accuracy: 0.8297 - val_loss: 0.5064 - val_accuracy: 0.8364\n",
      "Epoch 7/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.5032 - accuracy: 0.8331 - val_loss: 0.4957 - val_accuracy: 0.8396\n",
      "Epoch 8/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4932 - accuracy: 0.8361 - val_loss: 0.4861 - val_accuracy: 0.8428\n",
      "Epoch 9/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4848 - accuracy: 0.8392 - val_loss: 0.4786 - val_accuracy: 0.8436\n",
      "Epoch 10/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4782 - accuracy: 0.8397 - val_loss: 0.4795 - val_accuracy: 0.8438\n",
      "Epoch 11/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4721 - accuracy: 0.8423 - val_loss: 0.4699 - val_accuracy: 0.8490\n",
      "Epoch 12/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4666 - accuracy: 0.8440 - val_loss: 0.4712 - val_accuracy: 0.8474\n",
      "Epoch 13/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4619 - accuracy: 0.8461 - val_loss: 0.4618 - val_accuracy: 0.8486\n",
      "Epoch 14/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4581 - accuracy: 0.8475 - val_loss: 0.4672 - val_accuracy: 0.8466\n",
      "Epoch 15/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4542 - accuracy: 0.8472 - val_loss: 0.4553 - val_accuracy: 0.8548\n",
      "Epoch 16/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4506 - accuracy: 0.8487 - val_loss: 0.4526 - val_accuracy: 0.8522\n",
      "Epoch 17/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4472 - accuracy: 0.8496 - val_loss: 0.4523 - val_accuracy: 0.8532\n",
      "Epoch 18/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4441 - accuracy: 0.8504 - val_loss: 0.4517 - val_accuracy: 0.8514\n",
      "Epoch 19/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4421 - accuracy: 0.8510 - val_loss: 0.4481 - val_accuracy: 0.8558\n",
      "Epoch 20/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4391 - accuracy: 0.8516 - val_loss: 0.4427 - val_accuracy: 0.8550\n",
      "Epoch 21/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4372 - accuracy: 0.8518 - val_loss: 0.4421 - val_accuracy: 0.8562\n",
      "Epoch 22/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4346 - accuracy: 0.8536 - val_loss: 0.4429 - val_accuracy: 0.8550\n",
      "Epoch 23/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4327 - accuracy: 0.8542 - val_loss: 0.4394 - val_accuracy: 0.8574\n",
      "Epoch 24/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4310 - accuracy: 0.8547 - val_loss: 0.4422 - val_accuracy: 0.8564\n",
      "Epoch 25/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4291 - accuracy: 0.8562 - val_loss: 0.4357 - val_accuracy: 0.8580\n",
      "Epoch 26/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4270 - accuracy: 0.8564 - val_loss: 0.4380 - val_accuracy: 0.8576\n",
      "Epoch 27/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4256 - accuracy: 0.8564 - val_loss: 0.4330 - val_accuracy: 0.8584\n",
      "Epoch 28/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4242 - accuracy: 0.8574 - val_loss: 0.4326 - val_accuracy: 0.8592\n",
      "Epoch 29/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4228 - accuracy: 0.8576 - val_loss: 0.4391 - val_accuracy: 0.8584\n",
      "Epoch 30/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4213 - accuracy: 0.8585 - val_loss: 0.4319 - val_accuracy: 0.8614\n",
      "Epoch 31/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4199 - accuracy: 0.8596 - val_loss: 0.4330 - val_accuracy: 0.8602\n",
      "Epoch 32/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4185 - accuracy: 0.8587 - val_loss: 0.4293 - val_accuracy: 0.8578\n",
      "Epoch 33/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4174 - accuracy: 0.8591 - val_loss: 0.4304 - val_accuracy: 0.8602\n",
      "Epoch 34/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4164 - accuracy: 0.8600 - val_loss: 0.4283 - val_accuracy: 0.8604\n",
      "Epoch 35/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4151 - accuracy: 0.8607 - val_loss: 0.4302 - val_accuracy: 0.8598\n",
      "Epoch 36/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4142 - accuracy: 0.8613 - val_loss: 0.4282 - val_accuracy: 0.8600\n",
      "Epoch 37/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4129 - accuracy: 0.8602 - val_loss: 0.4276 - val_accuracy: 0.8592\n",
      "Epoch 38/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4121 - accuracy: 0.8616 - val_loss: 0.4301 - val_accuracy: 0.8584\n",
      "Epoch 39/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4111 - accuracy: 0.8610 - val_loss: 0.4267 - val_accuracy: 0.8622\n",
      "Epoch 40/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4101 - accuracy: 0.8620 - val_loss: 0.4253 - val_accuracy: 0.8614\n",
      "Epoch 41/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4093 - accuracy: 0.8621 - val_loss: 0.4281 - val_accuracy: 0.8602\n",
      "Epoch 42/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4082 - accuracy: 0.8622 - val_loss: 0.4242 - val_accuracy: 0.8604\n",
      "Epoch 43/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4074 - accuracy: 0.8627 - val_loss: 0.4230 - val_accuracy: 0.8616\n",
      "Epoch 44/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4065 - accuracy: 0.8632 - val_loss: 0.4233 - val_accuracy: 0.8586\n",
      "Epoch 45/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4057 - accuracy: 0.8634 - val_loss: 0.4267 - val_accuracy: 0.8618\n",
      "Epoch 46/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4051 - accuracy: 0.8632 - val_loss: 0.4220 - val_accuracy: 0.8610\n",
      "Epoch 47/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4039 - accuracy: 0.8635 - val_loss: 0.4242 - val_accuracy: 0.8574\n",
      "Epoch 48/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4034 - accuracy: 0.8648 - val_loss: 0.4258 - val_accuracy: 0.8616\n",
      "Epoch 49/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4030 - accuracy: 0.8637 - val_loss: 0.4225 - val_accuracy: 0.8604\n",
      "Epoch 50/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4021 - accuracy: 0.8644 - val_loss: 0.4189 - val_accuracy: 0.8622\n",
      "Epoch 51/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4016 - accuracy: 0.8652 - val_loss: 0.4207 - val_accuracy: 0.8630\n",
      "Epoch 52/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4007 - accuracy: 0.8649 - val_loss: 0.4190 - val_accuracy: 0.8632\n",
      "Epoch 53/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4000 - accuracy: 0.8653 - val_loss: 0.4208 - val_accuracy: 0.8614\n",
      "Epoch 54/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3995 - accuracy: 0.8652 - val_loss: 0.4234 - val_accuracy: 0.8550\n",
      "Epoch 55/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3985 - accuracy: 0.8653 - val_loss: 0.4185 - val_accuracy: 0.8614\n",
      "Epoch 56/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3983 - accuracy: 0.8651 - val_loss: 0.4187 - val_accuracy: 0.8624\n",
      "Epoch 57/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3975 - accuracy: 0.8657 - val_loss: 0.4198 - val_accuracy: 0.8620\n",
      "Epoch 58/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3971 - accuracy: 0.8656 - val_loss: 0.4182 - val_accuracy: 0.8616\n",
      "Epoch 59/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3962 - accuracy: 0.8666 - val_loss: 0.4212 - val_accuracy: 0.8620\n",
      "Epoch 60/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3961 - accuracy: 0.8653 - val_loss: 0.4182 - val_accuracy: 0.8630\n",
      "Epoch 61/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3955 - accuracy: 0.8668 - val_loss: 0.4165 - val_accuracy: 0.8634\n",
      "Epoch 62/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3948 - accuracy: 0.8675 - val_loss: 0.4193 - val_accuracy: 0.8608\n",
      "Epoch 63/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3941 - accuracy: 0.8665 - val_loss: 0.4195 - val_accuracy: 0.8582\n",
      "Epoch 64/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3939 - accuracy: 0.8667 - val_loss: 0.4177 - val_accuracy: 0.8614\n",
      "Epoch 65/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3931 - accuracy: 0.8680 - val_loss: 0.4172 - val_accuracy: 0.8616\n",
      "Epoch 66/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3929 - accuracy: 0.8674 - val_loss: 0.4160 - val_accuracy: 0.8612\n",
      "Epoch 67/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3925 - accuracy: 0.8664 - val_loss: 0.4185 - val_accuracy: 0.8616\n",
      "Epoch 68/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3920 - accuracy: 0.8679 - val_loss: 0.4178 - val_accuracy: 0.8640\n",
      "Epoch 69/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3917 - accuracy: 0.8681 - val_loss: 0.4154 - val_accuracy: 0.8626\n",
      "Epoch 70/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3908 - accuracy: 0.8682 - val_loss: 0.4179 - val_accuracy: 0.8638\n",
      "Epoch 71/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3905 - accuracy: 0.8688 - val_loss: 0.4171 - val_accuracy: 0.8618\n",
      "Epoch 72/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3903 - accuracy: 0.8675 - val_loss: 0.4178 - val_accuracy: 0.8616\n",
      "Epoch 73/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3898 - accuracy: 0.8684 - val_loss: 0.4168 - val_accuracy: 0.8606\n",
      "Epoch 74/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3894 - accuracy: 0.8687 - val_loss: 0.4156 - val_accuracy: 0.8580\n",
      "Epoch 75/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3889 - accuracy: 0.8682 - val_loss: 0.4151 - val_accuracy: 0.8612\n",
      "Epoch 76/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3881 - accuracy: 0.8689 - val_loss: 0.4159 - val_accuracy: 0.8604\n",
      "Epoch 77/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3882 - accuracy: 0.8691 - val_loss: 0.4162 - val_accuracy: 0.8644\n",
      "Epoch 78/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3876 - accuracy: 0.8684 - val_loss: 0.4180 - val_accuracy: 0.8652\n",
      "Epoch 79/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3873 - accuracy: 0.8692 - val_loss: 0.4150 - val_accuracy: 0.8620\n",
      "Epoch 80/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3868 - accuracy: 0.8696 - val_loss: 0.4152 - val_accuracy: 0.8628\n",
      "Epoch 81/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3863 - accuracy: 0.8694 - val_loss: 0.4191 - val_accuracy: 0.8624\n",
      "Epoch 82/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3859 - accuracy: 0.8691 - val_loss: 0.4154 - val_accuracy: 0.8622\n",
      "Epoch 83/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3855 - accuracy: 0.8700 - val_loss: 0.4156 - val_accuracy: 0.8626\n",
      "Epoch 84/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3855 - accuracy: 0.8693 - val_loss: 0.4140 - val_accuracy: 0.8594\n",
      "Epoch 85/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3850 - accuracy: 0.8688 - val_loss: 0.4130 - val_accuracy: 0.8626\n",
      "Epoch 86/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3845 - accuracy: 0.8703 - val_loss: 0.4133 - val_accuracy: 0.8624\n",
      "Epoch 87/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3844 - accuracy: 0.8695 - val_loss: 0.4146 - val_accuracy: 0.8618\n",
      "Epoch 88/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3841 - accuracy: 0.8700 - val_loss: 0.4175 - val_accuracy: 0.8630\n",
      "Epoch 89/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3839 - accuracy: 0.8700 - val_loss: 0.4164 - val_accuracy: 0.8618\n",
      "Epoch 90/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3834 - accuracy: 0.8702 - val_loss: 0.4147 - val_accuracy: 0.8576\n",
      "Epoch 91/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3828 - accuracy: 0.8707 - val_loss: 0.4145 - val_accuracy: 0.8608\n",
      "Epoch 92/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3826 - accuracy: 0.8699 - val_loss: 0.4144 - val_accuracy: 0.8618\n",
      "Epoch 93/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3819 - accuracy: 0.8710 - val_loss: 0.4167 - val_accuracy: 0.8630\n",
      "Epoch 94/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3818 - accuracy: 0.8711 - val_loss: 0.4132 - val_accuracy: 0.8628\n",
      "Epoch 95/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3814 - accuracy: 0.8706 - val_loss: 0.4146 - val_accuracy: 0.8628\n",
      "573/573 [==============================] - 1s 922us/step - loss: 0.4283 - accuracy: 0.8487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1146/1146 [==============================] - 2s 1ms/step - loss: 0.9356 - accuracy: 0.7050 - val_loss: 0.6976 - val_accuracy: 0.7770\n",
      "Epoch 2/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.6504 - accuracy: 0.7877 - val_loss: 0.6043 - val_accuracy: 0.8046\n",
      "Epoch 3/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.5877 - accuracy: 0.8086 - val_loss: 0.5657 - val_accuracy: 0.8184\n",
      "Epoch 4/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.5548 - accuracy: 0.8169 - val_loss: 0.5381 - val_accuracy: 0.8272\n",
      "Epoch 5/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.5333 - accuracy: 0.8231 - val_loss: 0.5211 - val_accuracy: 0.8308\n",
      "Epoch 6/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.5171 - accuracy: 0.8268 - val_loss: 0.5139 - val_accuracy: 0.8326\n",
      "Epoch 7/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.5051 - accuracy: 0.8297 - val_loss: 0.4988 - val_accuracy: 0.8360\n",
      "Epoch 8/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4954 - accuracy: 0.8325 - val_loss: 0.4916 - val_accuracy: 0.8382\n",
      "Epoch 9/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4876 - accuracy: 0.8356 - val_loss: 0.4841 - val_accuracy: 0.8414\n",
      "Epoch 10/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4807 - accuracy: 0.8368 - val_loss: 0.4798 - val_accuracy: 0.8400\n",
      "Epoch 11/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4751 - accuracy: 0.8388 - val_loss: 0.4730 - val_accuracy: 0.8424\n",
      "Epoch 12/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4695 - accuracy: 0.8412 - val_loss: 0.4770 - val_accuracy: 0.8360\n",
      "Epoch 13/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4654 - accuracy: 0.8418 - val_loss: 0.4660 - val_accuracy: 0.8456\n",
      "Epoch 14/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4604 - accuracy: 0.8428 - val_loss: 0.4631 - val_accuracy: 0.8470\n",
      "Epoch 15/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4570 - accuracy: 0.8445 - val_loss: 0.4597 - val_accuracy: 0.8474\n",
      "Epoch 16/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4541 - accuracy: 0.8455 - val_loss: 0.4583 - val_accuracy: 0.8480\n",
      "Epoch 17/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4507 - accuracy: 0.8465 - val_loss: 0.4578 - val_accuracy: 0.8502\n",
      "Epoch 18/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4479 - accuracy: 0.8476 - val_loss: 0.4581 - val_accuracy: 0.8520\n",
      "Epoch 19/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4452 - accuracy: 0.8466 - val_loss: 0.4504 - val_accuracy: 0.8482\n",
      "Epoch 20/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4427 - accuracy: 0.8485 - val_loss: 0.4495 - val_accuracy: 0.8492\n",
      "Epoch 21/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4403 - accuracy: 0.8496 - val_loss: 0.4467 - val_accuracy: 0.8498\n",
      "Epoch 22/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4385 - accuracy: 0.8497 - val_loss: 0.4462 - val_accuracy: 0.8516\n",
      "Epoch 23/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4363 - accuracy: 0.8512 - val_loss: 0.4427 - val_accuracy: 0.8510\n",
      "Epoch 24/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4343 - accuracy: 0.8520 - val_loss: 0.4428 - val_accuracy: 0.8500\n",
      "Epoch 25/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4327 - accuracy: 0.8520 - val_loss: 0.4425 - val_accuracy: 0.8498\n",
      "Epoch 26/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4308 - accuracy: 0.8531 - val_loss: 0.4402 - val_accuracy: 0.8554\n",
      "Epoch 27/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4292 - accuracy: 0.8521 - val_loss: 0.4389 - val_accuracy: 0.8518\n",
      "Epoch 28/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4278 - accuracy: 0.8531 - val_loss: 0.4382 - val_accuracy: 0.8538\n",
      "Epoch 29/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4266 - accuracy: 0.8550 - val_loss: 0.4368 - val_accuracy: 0.8532\n",
      "Epoch 30/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4251 - accuracy: 0.8541 - val_loss: 0.4360 - val_accuracy: 0.8552\n",
      "Epoch 31/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4239 - accuracy: 0.8549 - val_loss: 0.4369 - val_accuracy: 0.8504\n",
      "Epoch 32/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4225 - accuracy: 0.8552 - val_loss: 0.4341 - val_accuracy: 0.8546\n",
      "Epoch 33/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4210 - accuracy: 0.8557 - val_loss: 0.4336 - val_accuracy: 0.8538\n",
      "Epoch 34/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4203 - accuracy: 0.8553 - val_loss: 0.4363 - val_accuracy: 0.8572\n",
      "Epoch 35/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4189 - accuracy: 0.8572 - val_loss: 0.4336 - val_accuracy: 0.8526\n",
      "Epoch 36/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4179 - accuracy: 0.8570 - val_loss: 0.4315 - val_accuracy: 0.8566\n",
      "Epoch 37/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4169 - accuracy: 0.8566 - val_loss: 0.4322 - val_accuracy: 0.8542\n",
      "Epoch 38/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4160 - accuracy: 0.8569 - val_loss: 0.4298 - val_accuracy: 0.8562\n",
      "Epoch 39/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4148 - accuracy: 0.8573 - val_loss: 0.4300 - val_accuracy: 0.8558\n",
      "Epoch 40/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4139 - accuracy: 0.8579 - val_loss: 0.4282 - val_accuracy: 0.8556\n",
      "Epoch 41/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4131 - accuracy: 0.8577 - val_loss: 0.4283 - val_accuracy: 0.8562\n",
      "Epoch 42/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4119 - accuracy: 0.8581 - val_loss: 0.4337 - val_accuracy: 0.8508\n",
      "Epoch 43/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4115 - accuracy: 0.8585 - val_loss: 0.4288 - val_accuracy: 0.8556\n",
      "Epoch 44/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4102 - accuracy: 0.8588 - val_loss: 0.4293 - val_accuracy: 0.8576\n",
      "Epoch 45/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4095 - accuracy: 0.8595 - val_loss: 0.4272 - val_accuracy: 0.8548\n",
      "Epoch 46/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4089 - accuracy: 0.8597 - val_loss: 0.4277 - val_accuracy: 0.8556\n",
      "Epoch 47/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4078 - accuracy: 0.8590 - val_loss: 0.4272 - val_accuracy: 0.8574\n",
      "Epoch 48/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4070 - accuracy: 0.8595 - val_loss: 0.4316 - val_accuracy: 0.8572\n",
      "Epoch 49/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4068 - accuracy: 0.8596 - val_loss: 0.4250 - val_accuracy: 0.8556\n",
      "Epoch 50/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4061 - accuracy: 0.8605 - val_loss: 0.4246 - val_accuracy: 0.8552\n",
      "Epoch 51/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4054 - accuracy: 0.8606 - val_loss: 0.4288 - val_accuracy: 0.8570\n",
      "Epoch 52/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4048 - accuracy: 0.8607 - val_loss: 0.4232 - val_accuracy: 0.8558\n",
      "Epoch 53/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4038 - accuracy: 0.8604 - val_loss: 0.4257 - val_accuracy: 0.8568\n",
      "Epoch 54/100\n",
      "1146/1146 [==============================] - 2s 1ms/step - loss: 0.4034 - accuracy: 0.8595 - val_loss: 0.4254 - val_accuracy: 0.8578\n",
      "Epoch 55/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4030 - accuracy: 0.8613 - val_loss: 0.4252 - val_accuracy: 0.8538\n",
      "Epoch 56/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4018 - accuracy: 0.8611 - val_loss: 0.4238 - val_accuracy: 0.8560\n",
      "Epoch 57/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4013 - accuracy: 0.8610 - val_loss: 0.4217 - val_accuracy: 0.8570\n",
      "Epoch 58/100\n",
      "1146/1146 [==============================] - 2s 1ms/step - loss: 0.4013 - accuracy: 0.8625 - val_loss: 0.4226 - val_accuracy: 0.8566\n",
      "Epoch 59/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4002 - accuracy: 0.8616 - val_loss: 0.4237 - val_accuracy: 0.8538\n",
      "Epoch 60/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3998 - accuracy: 0.8634 - val_loss: 0.4212 - val_accuracy: 0.8542\n",
      "Epoch 61/100\n",
      "1146/1146 [==============================] - 2s 1ms/step - loss: 0.3990 - accuracy: 0.8621 - val_loss: 0.4213 - val_accuracy: 0.8552\n",
      "Epoch 62/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3993 - accuracy: 0.8622 - val_loss: 0.4203 - val_accuracy: 0.8562\n",
      "Epoch 63/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3982 - accuracy: 0.8622 - val_loss: 0.4197 - val_accuracy: 0.8568\n",
      "Epoch 64/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3972 - accuracy: 0.8627 - val_loss: 0.4218 - val_accuracy: 0.8546\n",
      "Epoch 65/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3975 - accuracy: 0.8631 - val_loss: 0.4212 - val_accuracy: 0.8570\n",
      "Epoch 66/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3972 - accuracy: 0.8624 - val_loss: 0.4213 - val_accuracy: 0.8556\n",
      "Epoch 67/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3966 - accuracy: 0.8631 - val_loss: 0.4205 - val_accuracy: 0.8572\n",
      "Epoch 68/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3958 - accuracy: 0.8635 - val_loss: 0.4200 - val_accuracy: 0.8566\n",
      "Epoch 69/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3957 - accuracy: 0.8634 - val_loss: 0.4218 - val_accuracy: 0.8564\n",
      "Epoch 70/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3951 - accuracy: 0.8634 - val_loss: 0.4196 - val_accuracy: 0.8550\n",
      "Epoch 71/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3945 - accuracy: 0.8644 - val_loss: 0.4199 - val_accuracy: 0.8564\n",
      "Epoch 72/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3939 - accuracy: 0.8626 - val_loss: 0.4219 - val_accuracy: 0.8574\n",
      "Epoch 73/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3937 - accuracy: 0.8631 - val_loss: 0.4193 - val_accuracy: 0.8568\n",
      "Epoch 74/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3934 - accuracy: 0.8637 - val_loss: 0.4193 - val_accuracy: 0.8562\n",
      "Epoch 75/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3927 - accuracy: 0.8651 - val_loss: 0.4199 - val_accuracy: 0.8578\n",
      "Epoch 76/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3924 - accuracy: 0.8647 - val_loss: 0.4190 - val_accuracy: 0.8540\n",
      "Epoch 77/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3917 - accuracy: 0.8649 - val_loss: 0.4217 - val_accuracy: 0.8582\n",
      "Epoch 78/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3917 - accuracy: 0.8650 - val_loss: 0.4204 - val_accuracy: 0.8540\n",
      "Epoch 79/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3912 - accuracy: 0.8648 - val_loss: 0.4199 - val_accuracy: 0.8600\n",
      "Epoch 80/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3910 - accuracy: 0.8651 - val_loss: 0.4171 - val_accuracy: 0.8574\n",
      "Epoch 81/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3904 - accuracy: 0.8653 - val_loss: 0.4206 - val_accuracy: 0.8566\n",
      "Epoch 82/100\n",
      "1146/1146 [==============================] - 2s 1ms/step - loss: 0.3901 - accuracy: 0.8652 - val_loss: 0.4168 - val_accuracy: 0.8566\n",
      "Epoch 83/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3894 - accuracy: 0.8657 - val_loss: 0.4166 - val_accuracy: 0.8568\n",
      "Epoch 84/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3892 - accuracy: 0.8649 - val_loss: 0.4188 - val_accuracy: 0.8556\n",
      "Epoch 85/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3888 - accuracy: 0.8648 - val_loss: 0.4166 - val_accuracy: 0.8562\n",
      "Epoch 86/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3887 - accuracy: 0.8660 - val_loss: 0.4161 - val_accuracy: 0.8574\n",
      "Epoch 87/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3882 - accuracy: 0.8660 - val_loss: 0.4200 - val_accuracy: 0.8552\n",
      "Epoch 88/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3880 - accuracy: 0.8649 - val_loss: 0.4176 - val_accuracy: 0.8570\n",
      "Epoch 89/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3876 - accuracy: 0.8661 - val_loss: 0.4174 - val_accuracy: 0.8564\n",
      "Epoch 90/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3873 - accuracy: 0.8658 - val_loss: 0.4172 - val_accuracy: 0.8554\n",
      "Epoch 91/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3869 - accuracy: 0.8664 - val_loss: 0.4179 - val_accuracy: 0.8576\n",
      "Epoch 92/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3867 - accuracy: 0.8655 - val_loss: 0.4171 - val_accuracy: 0.8556\n",
      "Epoch 93/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3865 - accuracy: 0.8661 - val_loss: 0.4177 - val_accuracy: 0.8568\n",
      "Epoch 94/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3860 - accuracy: 0.8661 - val_loss: 0.4170 - val_accuracy: 0.8584\n",
      "Epoch 95/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3857 - accuracy: 0.8664 - val_loss: 0.4168 - val_accuracy: 0.8570\n",
      "Epoch 96/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3853 - accuracy: 0.8666 - val_loss: 0.4176 - val_accuracy: 0.8550\n",
      "573/573 [==============================] - 1s 931us/step - loss: 0.4213 - accuracy: 0.8579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1146/1146 [==============================] - 2s 1ms/step - loss: 0.9257 - accuracy: 0.7120 - val_loss: 0.6885 - val_accuracy: 0.7804\n",
      "Epoch 2/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.6516 - accuracy: 0.7893 - val_loss: 0.6030 - val_accuracy: 0.8104\n",
      "Epoch 3/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.5901 - accuracy: 0.8078 - val_loss: 0.5631 - val_accuracy: 0.8222\n",
      "Epoch 4/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.5566 - accuracy: 0.8170 - val_loss: 0.5362 - val_accuracy: 0.8274\n",
      "Epoch 5/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.5342 - accuracy: 0.8236 - val_loss: 0.5214 - val_accuracy: 0.8350\n",
      "Epoch 6/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.5186 - accuracy: 0.8269 - val_loss: 0.5063 - val_accuracy: 0.8372\n",
      "Epoch 7/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.5062 - accuracy: 0.8318 - val_loss: 0.4994 - val_accuracy: 0.8376\n",
      "Epoch 8/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4966 - accuracy: 0.8337 - val_loss: 0.4915 - val_accuracy: 0.8406\n",
      "Epoch 9/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4879 - accuracy: 0.8360 - val_loss: 0.4843 - val_accuracy: 0.8408\n",
      "Epoch 10/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4809 - accuracy: 0.8376 - val_loss: 0.4756 - val_accuracy: 0.8436\n",
      "Epoch 11/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4753 - accuracy: 0.8397 - val_loss: 0.4734 - val_accuracy: 0.8438\n",
      "Epoch 12/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4698 - accuracy: 0.8426 - val_loss: 0.4671 - val_accuracy: 0.8466\n",
      "Epoch 13/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4655 - accuracy: 0.8420 - val_loss: 0.4716 - val_accuracy: 0.8452\n",
      "Epoch 14/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4608 - accuracy: 0.8447 - val_loss: 0.4646 - val_accuracy: 0.8464\n",
      "Epoch 15/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4571 - accuracy: 0.8451 - val_loss: 0.4649 - val_accuracy: 0.8438\n",
      "Epoch 16/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4538 - accuracy: 0.8466 - val_loss: 0.4540 - val_accuracy: 0.8518\n",
      "Epoch 17/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4502 - accuracy: 0.8466 - val_loss: 0.4535 - val_accuracy: 0.8516\n",
      "Epoch 18/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4478 - accuracy: 0.8485 - val_loss: 0.4490 - val_accuracy: 0.8520\n",
      "Epoch 19/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4448 - accuracy: 0.8484 - val_loss: 0.4532 - val_accuracy: 0.8532\n",
      "Epoch 20/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4423 - accuracy: 0.8495 - val_loss: 0.4486 - val_accuracy: 0.8526\n",
      "Epoch 21/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4405 - accuracy: 0.8494 - val_loss: 0.4462 - val_accuracy: 0.8530\n",
      "Epoch 22/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4382 - accuracy: 0.8507 - val_loss: 0.4451 - val_accuracy: 0.8510\n",
      "Epoch 23/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4364 - accuracy: 0.8508 - val_loss: 0.4445 - val_accuracy: 0.8546\n",
      "Epoch 24/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4342 - accuracy: 0.8516 - val_loss: 0.4400 - val_accuracy: 0.8546\n",
      "Epoch 25/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4323 - accuracy: 0.8522 - val_loss: 0.4413 - val_accuracy: 0.8558\n",
      "Epoch 26/100\n",
      "1146/1146 [==============================] - 2s 1ms/step - loss: 0.4307 - accuracy: 0.8522 - val_loss: 0.4390 - val_accuracy: 0.8534\n",
      "Epoch 27/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4292 - accuracy: 0.8538 - val_loss: 0.4363 - val_accuracy: 0.8566\n",
      "Epoch 28/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4272 - accuracy: 0.8533 - val_loss: 0.4368 - val_accuracy: 0.8546\n",
      "Epoch 29/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4260 - accuracy: 0.8534 - val_loss: 0.4360 - val_accuracy: 0.8556\n",
      "Epoch 30/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4247 - accuracy: 0.8552 - val_loss: 0.4384 - val_accuracy: 0.8542\n",
      "Epoch 31/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4231 - accuracy: 0.8558 - val_loss: 0.4358 - val_accuracy: 0.8566\n",
      "Epoch 32/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4222 - accuracy: 0.8560 - val_loss: 0.4347 - val_accuracy: 0.8562\n",
      "Epoch 33/100\n",
      "1146/1146 [==============================] - 2s 1ms/step - loss: 0.4209 - accuracy: 0.8559 - val_loss: 0.4369 - val_accuracy: 0.8552\n",
      "Epoch 34/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4201 - accuracy: 0.8562 - val_loss: 0.4303 - val_accuracy: 0.8590\n",
      "Epoch 35/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4189 - accuracy: 0.8571 - val_loss: 0.4303 - val_accuracy: 0.8576\n",
      "Epoch 36/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4173 - accuracy: 0.8581 - val_loss: 0.4365 - val_accuracy: 0.8544\n",
      "Epoch 37/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4166 - accuracy: 0.8571 - val_loss: 0.4291 - val_accuracy: 0.8578\n",
      "Epoch 38/100\n",
      "1146/1146 [==============================] - 2s 1ms/step - loss: 0.4154 - accuracy: 0.8579 - val_loss: 0.4296 - val_accuracy: 0.8562\n",
      "Epoch 39/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4143 - accuracy: 0.8583 - val_loss: 0.4343 - val_accuracy: 0.8552\n",
      "Epoch 40/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4139 - accuracy: 0.8586 - val_loss: 0.4281 - val_accuracy: 0.8572\n",
      "Epoch 41/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4125 - accuracy: 0.8590 - val_loss: 0.4341 - val_accuracy: 0.8520\n",
      "Epoch 42/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4119 - accuracy: 0.8597 - val_loss: 0.4255 - val_accuracy: 0.8568\n",
      "Epoch 43/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4110 - accuracy: 0.8606 - val_loss: 0.4318 - val_accuracy: 0.8560\n",
      "Epoch 44/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4099 - accuracy: 0.8608 - val_loss: 0.4248 - val_accuracy: 0.8566\n",
      "Epoch 45/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4089 - accuracy: 0.8600 - val_loss: 0.4260 - val_accuracy: 0.8570\n",
      "Epoch 46/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4085 - accuracy: 0.8607 - val_loss: 0.4253 - val_accuracy: 0.8546\n",
      "Epoch 47/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4077 - accuracy: 0.8606 - val_loss: 0.4267 - val_accuracy: 0.8574\n",
      "Epoch 48/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4071 - accuracy: 0.8611 - val_loss: 0.4317 - val_accuracy: 0.8548\n",
      "Epoch 49/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4062 - accuracy: 0.8610 - val_loss: 0.4241 - val_accuracy: 0.8576\n",
      "Epoch 50/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4053 - accuracy: 0.8609 - val_loss: 0.4230 - val_accuracy: 0.8560\n",
      "Epoch 51/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4051 - accuracy: 0.8608 - val_loss: 0.4231 - val_accuracy: 0.8568\n",
      "Epoch 52/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4041 - accuracy: 0.8619 - val_loss: 0.4286 - val_accuracy: 0.8552\n",
      "Epoch 53/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4041 - accuracy: 0.8624 - val_loss: 0.4215 - val_accuracy: 0.8582\n",
      "Epoch 54/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4031 - accuracy: 0.8627 - val_loss: 0.4237 - val_accuracy: 0.8568\n",
      "Epoch 55/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4026 - accuracy: 0.8624 - val_loss: 0.4210 - val_accuracy: 0.8590\n",
      "Epoch 56/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4018 - accuracy: 0.8621 - val_loss: 0.4229 - val_accuracy: 0.8580\n",
      "Epoch 57/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4015 - accuracy: 0.8624 - val_loss: 0.4230 - val_accuracy: 0.8554\n",
      "Epoch 58/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4008 - accuracy: 0.8626 - val_loss: 0.4227 - val_accuracy: 0.8578\n",
      "Epoch 59/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4002 - accuracy: 0.8631 - val_loss: 0.4230 - val_accuracy: 0.8548\n",
      "Epoch 60/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3997 - accuracy: 0.8628 - val_loss: 0.4213 - val_accuracy: 0.8582\n",
      "Epoch 61/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3985 - accuracy: 0.8638 - val_loss: 0.4216 - val_accuracy: 0.8552\n",
      "Epoch 62/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3983 - accuracy: 0.8643 - val_loss: 0.4202 - val_accuracy: 0.8558\n",
      "Epoch 63/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3976 - accuracy: 0.8642 - val_loss: 0.4193 - val_accuracy: 0.8586\n",
      "Epoch 64/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3975 - accuracy: 0.8638 - val_loss: 0.4202 - val_accuracy: 0.8552\n",
      "Epoch 65/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3967 - accuracy: 0.8641 - val_loss: 0.4229 - val_accuracy: 0.8520\n",
      "Epoch 66/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3965 - accuracy: 0.8645 - val_loss: 0.4254 - val_accuracy: 0.8582\n",
      "Epoch 67/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3958 - accuracy: 0.8653 - val_loss: 0.4209 - val_accuracy: 0.8560\n",
      "Epoch 68/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3955 - accuracy: 0.8641 - val_loss: 0.4263 - val_accuracy: 0.8576\n",
      "Epoch 69/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3950 - accuracy: 0.8641 - val_loss: 0.4213 - val_accuracy: 0.8568\n",
      "Epoch 70/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3946 - accuracy: 0.8634 - val_loss: 0.4234 - val_accuracy: 0.8534\n",
      "Epoch 71/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3941 - accuracy: 0.8646 - val_loss: 0.4190 - val_accuracy: 0.8568\n",
      "Epoch 72/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3936 - accuracy: 0.8648 - val_loss: 0.4188 - val_accuracy: 0.8582\n",
      "Epoch 73/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3933 - accuracy: 0.8640 - val_loss: 0.4208 - val_accuracy: 0.8556\n",
      "Epoch 74/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3930 - accuracy: 0.8655 - val_loss: 0.4197 - val_accuracy: 0.8572\n",
      "Epoch 75/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3925 - accuracy: 0.8652 - val_loss: 0.4180 - val_accuracy: 0.8586\n",
      "Epoch 76/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3918 - accuracy: 0.8661 - val_loss: 0.4213 - val_accuracy: 0.8542\n",
      "Epoch 77/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3915 - accuracy: 0.8650 - val_loss: 0.4177 - val_accuracy: 0.8582\n",
      "Epoch 78/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3911 - accuracy: 0.8657 - val_loss: 0.4194 - val_accuracy: 0.8592\n",
      "Epoch 79/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3910 - accuracy: 0.8658 - val_loss: 0.4174 - val_accuracy: 0.8588\n",
      "Epoch 80/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3902 - accuracy: 0.8657 - val_loss: 0.4202 - val_accuracy: 0.8528\n",
      "Epoch 81/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3899 - accuracy: 0.8651 - val_loss: 0.4205 - val_accuracy: 0.8560\n",
      "Epoch 82/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3899 - accuracy: 0.8663 - val_loss: 0.4173 - val_accuracy: 0.8578\n",
      "Epoch 83/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3895 - accuracy: 0.8663 - val_loss: 0.4172 - val_accuracy: 0.8588\n",
      "Epoch 84/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3887 - accuracy: 0.8666 - val_loss: 0.4192 - val_accuracy: 0.8588\n",
      "Epoch 85/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3886 - accuracy: 0.8666 - val_loss: 0.4187 - val_accuracy: 0.8570\n",
      "Epoch 86/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3885 - accuracy: 0.8662 - val_loss: 0.4174 - val_accuracy: 0.8592\n",
      "Epoch 87/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3880 - accuracy: 0.8675 - val_loss: 0.4185 - val_accuracy: 0.8572\n",
      "Epoch 88/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3876 - accuracy: 0.8676 - val_loss: 0.4173 - val_accuracy: 0.8590\n",
      "Epoch 89/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3873 - accuracy: 0.8673 - val_loss: 0.4171 - val_accuracy: 0.8576\n",
      "Epoch 90/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3868 - accuracy: 0.8675 - val_loss: 0.4183 - val_accuracy: 0.8582\n",
      "Epoch 91/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3868 - accuracy: 0.8663 - val_loss: 0.4151 - val_accuracy: 0.8588\n",
      "Epoch 92/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3859 - accuracy: 0.8677 - val_loss: 0.4150 - val_accuracy: 0.8584\n",
      "Epoch 93/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3857 - accuracy: 0.8676 - val_loss: 0.4192 - val_accuracy: 0.8592\n",
      "Epoch 94/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3859 - accuracy: 0.8678 - val_loss: 0.4156 - val_accuracy: 0.8582\n",
      "Epoch 95/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3851 - accuracy: 0.8670 - val_loss: 0.4167 - val_accuracy: 0.8588\n",
      "Epoch 96/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3853 - accuracy: 0.8678 - val_loss: 0.4164 - val_accuracy: 0.8560\n",
      "Epoch 97/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3849 - accuracy: 0.8675 - val_loss: 0.4162 - val_accuracy: 0.8554\n",
      "Epoch 98/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3838 - accuracy: 0.8682 - val_loss: 0.4182 - val_accuracy: 0.8580\n",
      "Epoch 99/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3838 - accuracy: 0.8681 - val_loss: 0.4184 - val_accuracy: 0.8554\n",
      "Epoch 100/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3839 - accuracy: 0.8675 - val_loss: 0.4155 - val_accuracy: 0.8590\n",
      "573/573 [==============================] - 1s 998us/step - loss: 0.4188 - accuracy: 0.8556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.8892 - accuracy: 0.6937 - val_loss: 0.5849 - val_accuracy: 0.8022\n",
      "Epoch 2/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.5432 - accuracy: 0.8091 - val_loss: 0.4894 - val_accuracy: 0.8288\n",
      "Epoch 3/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4872 - accuracy: 0.8298 - val_loss: 0.4518 - val_accuracy: 0.8448\n",
      "Epoch 4/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4554 - accuracy: 0.8410 - val_loss: 0.4459 - val_accuracy: 0.8476\n",
      "Epoch 5/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4343 - accuracy: 0.8472 - val_loss: 0.4309 - val_accuracy: 0.8496\n",
      "Epoch 6/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4180 - accuracy: 0.8542 - val_loss: 0.4029 - val_accuracy: 0.8630\n",
      "Epoch 7/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4030 - accuracy: 0.8566 - val_loss: 0.4038 - val_accuracy: 0.8600\n",
      "Epoch 8/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.3904 - accuracy: 0.8651 - val_loss: 0.3817 - val_accuracy: 0.8646\n",
      "Epoch 9/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.3802 - accuracy: 0.8658 - val_loss: 0.3744 - val_accuracy: 0.8682\n",
      "Epoch 10/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.3698 - accuracy: 0.8682 - val_loss: 0.4127 - val_accuracy: 0.8532\n",
      "Epoch 11/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.3621 - accuracy: 0.8711 - val_loss: 0.3874 - val_accuracy: 0.8596\n",
      "Epoch 12/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.3533 - accuracy: 0.8737 - val_loss: 0.3673 - val_accuracy: 0.8742\n",
      "Epoch 13/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.3457 - accuracy: 0.8759 - val_loss: 0.3651 - val_accuracy: 0.8642\n",
      "Epoch 14/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.3388 - accuracy: 0.8786 - val_loss: 0.3647 - val_accuracy: 0.8688\n",
      "Epoch 15/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.3321 - accuracy: 0.8801 - val_loss: 0.3548 - val_accuracy: 0.8764\n",
      "Epoch 16/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.3258 - accuracy: 0.8842 - val_loss: 0.3557 - val_accuracy: 0.8722\n",
      "Epoch 17/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.3202 - accuracy: 0.8855 - val_loss: 0.3437 - val_accuracy: 0.8806\n",
      "Epoch 18/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.3146 - accuracy: 0.8879 - val_loss: 0.3435 - val_accuracy: 0.8772\n",
      "Epoch 19/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.3095 - accuracy: 0.8877 - val_loss: 0.3417 - val_accuracy: 0.8786\n",
      "Epoch 20/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.3041 - accuracy: 0.8903 - val_loss: 0.3401 - val_accuracy: 0.8830\n",
      "Epoch 21/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.2979 - accuracy: 0.8929 - val_loss: 0.3504 - val_accuracy: 0.8736\n",
      "Epoch 22/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.2945 - accuracy: 0.8928 - val_loss: 0.3372 - val_accuracy: 0.8772\n",
      "Epoch 23/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.2896 - accuracy: 0.8942 - val_loss: 0.3332 - val_accuracy: 0.8814\n",
      "Epoch 24/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.2848 - accuracy: 0.8966 - val_loss: 0.3242 - val_accuracy: 0.8806\n",
      "Epoch 25/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.2811 - accuracy: 0.8983 - val_loss: 0.3498 - val_accuracy: 0.8806\n",
      "Epoch 26/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.2767 - accuracy: 0.8985 - val_loss: 0.3753 - val_accuracy: 0.8666\n",
      "Epoch 27/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.2734 - accuracy: 0.9008 - val_loss: 0.3337 - val_accuracy: 0.8816\n",
      "Epoch 28/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.2691 - accuracy: 0.9018 - val_loss: 0.3382 - val_accuracy: 0.8820\n",
      "Epoch 29/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.2648 - accuracy: 0.9035 - val_loss: 0.3333 - val_accuracy: 0.8790\n",
      "Epoch 30/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.2624 - accuracy: 0.9039 - val_loss: 0.3366 - val_accuracy: 0.8790\n",
      "Epoch 31/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.2594 - accuracy: 0.9051 - val_loss: 0.3420 - val_accuracy: 0.8778\n",
      "Epoch 32/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.2555 - accuracy: 0.9070 - val_loss: 0.3284 - val_accuracy: 0.8842\n",
      "Epoch 33/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.2516 - accuracy: 0.9090 - val_loss: 0.3614 - val_accuracy: 0.8714\n",
      "Epoch 34/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.2485 - accuracy: 0.9091 - val_loss: 0.3222 - val_accuracy: 0.8884\n",
      "Epoch 35/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.2449 - accuracy: 0.9111 - val_loss: 0.3413 - val_accuracy: 0.8798\n",
      "Epoch 36/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.2420 - accuracy: 0.9110 - val_loss: 0.3345 - val_accuracy: 0.8804\n",
      "Epoch 37/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.2382 - accuracy: 0.9117 - val_loss: 0.3269 - val_accuracy: 0.8840\n",
      "Epoch 38/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.2356 - accuracy: 0.9138 - val_loss: 0.3258 - val_accuracy: 0.8840\n",
      "Epoch 39/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.2339 - accuracy: 0.9133 - val_loss: 0.3317 - val_accuracy: 0.8806\n",
      "Epoch 40/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.2287 - accuracy: 0.9174 - val_loss: 0.3302 - val_accuracy: 0.8816\n",
      "Epoch 41/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.2265 - accuracy: 0.9158 - val_loss: 0.3229 - val_accuracy: 0.8836\n",
      "Epoch 42/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.2236 - accuracy: 0.9187 - val_loss: 0.3358 - val_accuracy: 0.8824\n",
      "Epoch 43/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.2210 - accuracy: 0.9182 - val_loss: 0.3220 - val_accuracy: 0.8874\n",
      "Epoch 44/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.2169 - accuracy: 0.9195 - val_loss: 0.3244 - val_accuracy: 0.8902\n",
      "Epoch 45/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.2159 - accuracy: 0.9199 - val_loss: 0.3527 - val_accuracy: 0.8760\n",
      "Epoch 46/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.2124 - accuracy: 0.9217 - val_loss: 0.3515 - val_accuracy: 0.8838\n",
      "Epoch 47/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.2114 - accuracy: 0.9222 - val_loss: 0.3359 - val_accuracy: 0.8840\n",
      "Epoch 48/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.2079 - accuracy: 0.9241 - val_loss: 0.3212 - val_accuracy: 0.8876\n",
      "Epoch 49/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.2059 - accuracy: 0.9233 - val_loss: 0.3302 - val_accuracy: 0.8888\n",
      "Epoch 50/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.2022 - accuracy: 0.9259 - val_loss: 0.3469 - val_accuracy: 0.8810\n",
      "Epoch 51/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.1985 - accuracy: 0.9266 - val_loss: 0.3409 - val_accuracy: 0.8886\n",
      "Epoch 52/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.1977 - accuracy: 0.9262 - val_loss: 0.3332 - val_accuracy: 0.8862\n",
      "Epoch 53/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.1959 - accuracy: 0.9278 - val_loss: 0.3323 - val_accuracy: 0.8908\n",
      "Epoch 54/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.1936 - accuracy: 0.9288 - val_loss: 0.3499 - val_accuracy: 0.8770\n",
      "Epoch 55/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.1917 - accuracy: 0.9296 - val_loss: 0.3328 - val_accuracy: 0.8882\n",
      "Epoch 56/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.1861 - accuracy: 0.9317 - val_loss: 0.3459 - val_accuracy: 0.8840\n",
      "Epoch 57/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.1855 - accuracy: 0.9319 - val_loss: 0.3630 - val_accuracy: 0.8804\n",
      "Epoch 58/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.1844 - accuracy: 0.9311 - val_loss: 0.3294 - val_accuracy: 0.8848\n",
      "573/573 [==============================] - 1s 1ms/step - loss: 0.3502 - accuracy: 0.8791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.9848 - accuracy: 0.6684 - val_loss: 0.6222 - val_accuracy: 0.7850\n",
      "Epoch 2/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.5700 - accuracy: 0.7991 - val_loss: 0.5287 - val_accuracy: 0.8192\n",
      "Epoch 3/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.5009 - accuracy: 0.8203 - val_loss: 0.4728 - val_accuracy: 0.8306\n",
      "Epoch 4/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4678 - accuracy: 0.8331 - val_loss: 0.4601 - val_accuracy: 0.8444\n",
      "Epoch 5/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4432 - accuracy: 0.8439 - val_loss: 0.4375 - val_accuracy: 0.8498\n",
      "Epoch 6/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4256 - accuracy: 0.8481 - val_loss: 0.4359 - val_accuracy: 0.8528\n",
      "Epoch 7/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4089 - accuracy: 0.8540 - val_loss: 0.4170 - val_accuracy: 0.8552\n",
      "Epoch 8/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.3955 - accuracy: 0.8594 - val_loss: 0.3941 - val_accuracy: 0.8644\n",
      "Epoch 9/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.3854 - accuracy: 0.8611 - val_loss: 0.3908 - val_accuracy: 0.8638\n",
      "Epoch 10/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.3738 - accuracy: 0.8661 - val_loss: 0.3842 - val_accuracy: 0.8676\n",
      "Epoch 11/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.3638 - accuracy: 0.8697 - val_loss: 0.3807 - val_accuracy: 0.8690\n",
      "Epoch 12/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.3558 - accuracy: 0.8721 - val_loss: 0.3772 - val_accuracy: 0.8700\n",
      "Epoch 13/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.3483 - accuracy: 0.8736 - val_loss: 0.3756 - val_accuracy: 0.8640\n",
      "Epoch 14/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.3404 - accuracy: 0.8756 - val_loss: 0.3687 - val_accuracy: 0.8700\n",
      "Epoch 15/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.3330 - accuracy: 0.8792 - val_loss: 0.3730 - val_accuracy: 0.8702\n",
      "Epoch 16/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.3278 - accuracy: 0.8813 - val_loss: 0.3520 - val_accuracy: 0.8788\n",
      "Epoch 17/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.3205 - accuracy: 0.8838 - val_loss: 0.3529 - val_accuracy: 0.8740\n",
      "Epoch 18/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.3155 - accuracy: 0.8851 - val_loss: 0.3456 - val_accuracy: 0.8760\n",
      "Epoch 19/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.3084 - accuracy: 0.8874 - val_loss: 0.3612 - val_accuracy: 0.8696\n",
      "Epoch 20/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.3044 - accuracy: 0.8893 - val_loss: 0.3678 - val_accuracy: 0.8700\n",
      "Epoch 21/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.3008 - accuracy: 0.8905 - val_loss: 0.3403 - val_accuracy: 0.8776\n",
      "Epoch 22/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.2947 - accuracy: 0.8926 - val_loss: 0.3470 - val_accuracy: 0.8764\n",
      "Epoch 23/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.2905 - accuracy: 0.8946 - val_loss: 0.3374 - val_accuracy: 0.8806\n",
      "Epoch 24/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.2863 - accuracy: 0.8953 - val_loss: 0.3481 - val_accuracy: 0.8766\n",
      "Epoch 25/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.2821 - accuracy: 0.8967 - val_loss: 0.3494 - val_accuracy: 0.8738\n",
      "Epoch 26/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.2784 - accuracy: 0.8973 - val_loss: 0.3488 - val_accuracy: 0.8772\n",
      "Epoch 27/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.2748 - accuracy: 0.8988 - val_loss: 0.3472 - val_accuracy: 0.8790\n",
      "Epoch 28/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.2707 - accuracy: 0.9013 - val_loss: 0.3434 - val_accuracy: 0.8812\n",
      "Epoch 29/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.2655 - accuracy: 0.9026 - val_loss: 0.3393 - val_accuracy: 0.8800\n",
      "Epoch 30/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.2632 - accuracy: 0.9023 - val_loss: 0.3409 - val_accuracy: 0.8772\n",
      "Epoch 31/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.2588 - accuracy: 0.9055 - val_loss: 0.3297 - val_accuracy: 0.8828\n",
      "Epoch 32/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.2560 - accuracy: 0.9068 - val_loss: 0.3374 - val_accuracy: 0.8832\n",
      "Epoch 33/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.2543 - accuracy: 0.9077 - val_loss: 0.3283 - val_accuracy: 0.8842\n",
      "Epoch 34/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.2494 - accuracy: 0.9090 - val_loss: 0.3310 - val_accuracy: 0.8816\n",
      "Epoch 35/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.2455 - accuracy: 0.9099 - val_loss: 0.3406 - val_accuracy: 0.8804\n",
      "Epoch 36/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.2428 - accuracy: 0.9108 - val_loss: 0.3508 - val_accuracy: 0.8808\n",
      "Epoch 37/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.2398 - accuracy: 0.9122 - val_loss: 0.3309 - val_accuracy: 0.8844\n",
      "Epoch 38/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.2381 - accuracy: 0.9126 - val_loss: 0.3433 - val_accuracy: 0.8748\n",
      "Epoch 39/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.2340 - accuracy: 0.9123 - val_loss: 0.3392 - val_accuracy: 0.8828\n",
      "Epoch 40/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.2289 - accuracy: 0.9158 - val_loss: 0.3516 - val_accuracy: 0.8742\n",
      "Epoch 41/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.2280 - accuracy: 0.9156 - val_loss: 0.3344 - val_accuracy: 0.8862\n",
      "Epoch 42/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.2253 - accuracy: 0.9168 - val_loss: 0.3518 - val_accuracy: 0.8770\n",
      "Epoch 43/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.2224 - accuracy: 0.9182 - val_loss: 0.3374 - val_accuracy: 0.8816\n",
      "573/573 [==============================] - 1s 1ms/step - loss: 0.3482 - accuracy: 0.8835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.9563 - accuracy: 0.6769 - val_loss: 0.6217 - val_accuracy: 0.7776\n",
      "Epoch 2/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.5621 - accuracy: 0.8051 - val_loss: 0.4942 - val_accuracy: 0.8332\n",
      "Epoch 3/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4945 - accuracy: 0.8259 - val_loss: 0.4836 - val_accuracy: 0.8240\n",
      "Epoch 4/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4601 - accuracy: 0.8376 - val_loss: 0.4481 - val_accuracy: 0.8470\n",
      "Epoch 5/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4360 - accuracy: 0.8447 - val_loss: 0.4223 - val_accuracy: 0.8560\n",
      "Epoch 6/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4175 - accuracy: 0.8521 - val_loss: 0.4136 - val_accuracy: 0.8546\n",
      "Epoch 7/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4032 - accuracy: 0.8560 - val_loss: 0.4091 - val_accuracy: 0.8574\n",
      "Epoch 8/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.3906 - accuracy: 0.8600 - val_loss: 0.4021 - val_accuracy: 0.8608\n",
      "Epoch 9/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.3769 - accuracy: 0.8644 - val_loss: 0.3814 - val_accuracy: 0.8678\n",
      "Epoch 10/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.3653 - accuracy: 0.8685 - val_loss: 0.3762 - val_accuracy: 0.8672\n",
      "Epoch 11/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.3587 - accuracy: 0.8703 - val_loss: 0.3789 - val_accuracy: 0.8714\n",
      "Epoch 12/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.3511 - accuracy: 0.8744 - val_loss: 0.3824 - val_accuracy: 0.8662\n",
      "Epoch 13/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.3422 - accuracy: 0.8771 - val_loss: 0.3579 - val_accuracy: 0.8738\n",
      "Epoch 14/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.3356 - accuracy: 0.8784 - val_loss: 0.3610 - val_accuracy: 0.8718\n",
      "Epoch 15/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.3286 - accuracy: 0.8809 - val_loss: 0.3745 - val_accuracy: 0.8668\n",
      "Epoch 16/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.3228 - accuracy: 0.8823 - val_loss: 0.3448 - val_accuracy: 0.8798\n",
      "Epoch 17/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.3171 - accuracy: 0.8834 - val_loss: 0.3456 - val_accuracy: 0.8744\n",
      "Epoch 18/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.3113 - accuracy: 0.8864 - val_loss: 0.3456 - val_accuracy: 0.8750\n",
      "Epoch 19/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.3057 - accuracy: 0.8882 - val_loss: 0.3369 - val_accuracy: 0.8806\n",
      "Epoch 20/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.3020 - accuracy: 0.8897 - val_loss: 0.4021 - val_accuracy: 0.8574\n",
      "Epoch 21/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.2971 - accuracy: 0.8922 - val_loss: 0.3373 - val_accuracy: 0.8806\n",
      "Epoch 22/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.2923 - accuracy: 0.8929 - val_loss: 0.3399 - val_accuracy: 0.8786\n",
      "Epoch 23/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.2870 - accuracy: 0.8948 - val_loss: 0.3319 - val_accuracy: 0.8778\n",
      "Epoch 24/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.2848 - accuracy: 0.8947 - val_loss: 0.3358 - val_accuracy: 0.8822\n",
      "Epoch 25/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.2784 - accuracy: 0.8973 - val_loss: 0.3653 - val_accuracy: 0.8716\n",
      "Epoch 26/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.2755 - accuracy: 0.8988 - val_loss: 0.3282 - val_accuracy: 0.8792\n",
      "Epoch 27/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.2718 - accuracy: 0.9011 - val_loss: 0.3316 - val_accuracy: 0.8826\n",
      "Epoch 28/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.2671 - accuracy: 0.9015 - val_loss: 0.3334 - val_accuracy: 0.8832\n",
      "Epoch 29/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.2634 - accuracy: 0.9035 - val_loss: 0.3294 - val_accuracy: 0.8824\n",
      "Epoch 30/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.2598 - accuracy: 0.9052 - val_loss: 0.3570 - val_accuracy: 0.8760\n",
      "Epoch 31/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.2576 - accuracy: 0.9063 - val_loss: 0.3353 - val_accuracy: 0.8844\n",
      "Epoch 32/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.2545 - accuracy: 0.9062 - val_loss: 0.3338 - val_accuracy: 0.8850\n",
      "Epoch 33/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.2504 - accuracy: 0.9066 - val_loss: 0.3388 - val_accuracy: 0.8810\n",
      "Epoch 34/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.2461 - accuracy: 0.9102 - val_loss: 0.3304 - val_accuracy: 0.8848\n",
      "Epoch 35/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.2441 - accuracy: 0.9124 - val_loss: 0.3234 - val_accuracy: 0.8844\n",
      "Epoch 36/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.2402 - accuracy: 0.9124 - val_loss: 0.3608 - val_accuracy: 0.8736\n",
      "Epoch 37/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.2369 - accuracy: 0.9140 - val_loss: 0.3252 - val_accuracy: 0.8892\n",
      "Epoch 38/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.2342 - accuracy: 0.9150 - val_loss: 0.3309 - val_accuracy: 0.8850\n",
      "Epoch 39/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.2307 - accuracy: 0.9145 - val_loss: 0.3212 - val_accuracy: 0.8886\n",
      "Epoch 40/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.2302 - accuracy: 0.9170 - val_loss: 0.3610 - val_accuracy: 0.8750\n",
      "Epoch 41/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.2255 - accuracy: 0.9170 - val_loss: 0.3343 - val_accuracy: 0.8842\n",
      "Epoch 42/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.2231 - accuracy: 0.9192 - val_loss: 0.3254 - val_accuracy: 0.8808\n",
      "Epoch 43/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.2194 - accuracy: 0.9204 - val_loss: 0.3445 - val_accuracy: 0.8770\n",
      "Epoch 44/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.2168 - accuracy: 0.9218 - val_loss: 0.3189 - val_accuracy: 0.8888\n",
      "Epoch 45/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.2129 - accuracy: 0.9230 - val_loss: 0.3270 - val_accuracy: 0.8834\n",
      "Epoch 46/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.2112 - accuracy: 0.9226 - val_loss: 0.3191 - val_accuracy: 0.8892\n",
      "Epoch 47/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.2089 - accuracy: 0.9237 - val_loss: 0.3251 - val_accuracy: 0.8846\n",
      "Epoch 48/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.2057 - accuracy: 0.9259 - val_loss: 0.3422 - val_accuracy: 0.8848\n",
      "Epoch 49/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.2040 - accuracy: 0.9246 - val_loss: 0.3284 - val_accuracy: 0.8880\n",
      "Epoch 50/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.2022 - accuracy: 0.9264 - val_loss: 0.3390 - val_accuracy: 0.8810\n",
      "Epoch 51/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.1982 - accuracy: 0.9280 - val_loss: 0.3224 - val_accuracy: 0.8864\n",
      "Epoch 52/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.1961 - accuracy: 0.9294 - val_loss: 0.3408 - val_accuracy: 0.8806\n",
      "Epoch 53/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.1957 - accuracy: 0.9279 - val_loss: 0.3346 - val_accuracy: 0.8866\n",
      "Epoch 54/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.1904 - accuracy: 0.9301 - val_loss: 0.3698 - val_accuracy: 0.8768\n",
      "573/573 [==============================] - 1s 1ms/step - loss: 0.3914 - accuracy: 0.8729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1146/1146 [==============================] - 2s 1ms/step - loss: 0.9290 - accuracy: 0.7089 - val_loss: 0.6922 - val_accuracy: 0.7830\n",
      "Epoch 2/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.6485 - accuracy: 0.7938 - val_loss: 0.6034 - val_accuracy: 0.8098\n",
      "Epoch 3/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.5879 - accuracy: 0.8109 - val_loss: 0.5611 - val_accuracy: 0.8200\n",
      "Epoch 4/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.5547 - accuracy: 0.8204 - val_loss: 0.5360 - val_accuracy: 0.8250\n",
      "Epoch 5/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.5324 - accuracy: 0.8255 - val_loss: 0.5199 - val_accuracy: 0.8328\n",
      "Epoch 6/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.5167 - accuracy: 0.8291 - val_loss: 0.5045 - val_accuracy: 0.8362\n",
      "Epoch 7/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.5044 - accuracy: 0.8330 - val_loss: 0.4948 - val_accuracy: 0.8404\n",
      "Epoch 8/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4944 - accuracy: 0.8355 - val_loss: 0.4892 - val_accuracy: 0.8404\n",
      "Epoch 9/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4861 - accuracy: 0.8374 - val_loss: 0.4873 - val_accuracy: 0.8370\n",
      "Epoch 10/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4792 - accuracy: 0.8404 - val_loss: 0.4757 - val_accuracy: 0.8460\n",
      "Epoch 11/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4727 - accuracy: 0.8432 - val_loss: 0.4689 - val_accuracy: 0.8484\n",
      "Epoch 12/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4675 - accuracy: 0.8435 - val_loss: 0.4654 - val_accuracy: 0.8482\n",
      "Epoch 13/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4630 - accuracy: 0.8448 - val_loss: 0.4633 - val_accuracy: 0.8486\n",
      "Epoch 14/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4588 - accuracy: 0.8464 - val_loss: 0.4640 - val_accuracy: 0.8454\n",
      "Epoch 15/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4549 - accuracy: 0.8472 - val_loss: 0.4601 - val_accuracy: 0.8466\n",
      "Epoch 16/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4517 - accuracy: 0.8489 - val_loss: 0.4541 - val_accuracy: 0.8524\n",
      "Epoch 17/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4485 - accuracy: 0.8503 - val_loss: 0.4505 - val_accuracy: 0.8536\n",
      "Epoch 18/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4454 - accuracy: 0.8502 - val_loss: 0.4487 - val_accuracy: 0.8526\n",
      "Epoch 19/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4428 - accuracy: 0.8512 - val_loss: 0.4510 - val_accuracy: 0.8540\n",
      "Epoch 20/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4402 - accuracy: 0.8517 - val_loss: 0.4438 - val_accuracy: 0.8568\n",
      "Epoch 21/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4380 - accuracy: 0.8519 - val_loss: 0.4444 - val_accuracy: 0.8530\n",
      "Epoch 22/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4357 - accuracy: 0.8544 - val_loss: 0.4405 - val_accuracy: 0.8542\n",
      "Epoch 23/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4337 - accuracy: 0.8533 - val_loss: 0.4394 - val_accuracy: 0.8546\n",
      "Epoch 24/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4318 - accuracy: 0.8546 - val_loss: 0.4390 - val_accuracy: 0.8528\n",
      "Epoch 25/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4301 - accuracy: 0.8548 - val_loss: 0.4399 - val_accuracy: 0.8562\n",
      "Epoch 26/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4283 - accuracy: 0.8553 - val_loss: 0.4352 - val_accuracy: 0.8544\n",
      "Epoch 27/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4267 - accuracy: 0.8569 - val_loss: 0.4378 - val_accuracy: 0.8574\n",
      "Epoch 28/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4250 - accuracy: 0.8564 - val_loss: 0.4371 - val_accuracy: 0.8558\n",
      "Epoch 29/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4239 - accuracy: 0.8572 - val_loss: 0.4310 - val_accuracy: 0.8562\n",
      "Epoch 30/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4217 - accuracy: 0.8581 - val_loss: 0.4360 - val_accuracy: 0.8576\n",
      "Epoch 31/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4205 - accuracy: 0.8579 - val_loss: 0.4382 - val_accuracy: 0.8546\n",
      "Epoch 32/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4196 - accuracy: 0.8576 - val_loss: 0.4308 - val_accuracy: 0.8572\n",
      "Epoch 33/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4184 - accuracy: 0.8586 - val_loss: 0.4329 - val_accuracy: 0.8584\n",
      "Epoch 34/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4173 - accuracy: 0.8598 - val_loss: 0.4275 - val_accuracy: 0.8584\n",
      "Epoch 35/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4157 - accuracy: 0.8600 - val_loss: 0.4295 - val_accuracy: 0.8582\n",
      "Epoch 36/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4151 - accuracy: 0.8606 - val_loss: 0.4267 - val_accuracy: 0.8572\n",
      "Epoch 37/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4137 - accuracy: 0.8601 - val_loss: 0.4280 - val_accuracy: 0.8558\n",
      "Epoch 38/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4126 - accuracy: 0.8601 - val_loss: 0.4257 - val_accuracy: 0.8574\n",
      "Epoch 39/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4115 - accuracy: 0.8610 - val_loss: 0.4284 - val_accuracy: 0.8566\n",
      "Epoch 40/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4108 - accuracy: 0.8611 - val_loss: 0.4308 - val_accuracy: 0.8594\n",
      "Epoch 41/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4098 - accuracy: 0.8615 - val_loss: 0.4258 - val_accuracy: 0.8606\n",
      "Epoch 42/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4087 - accuracy: 0.8617 - val_loss: 0.4257 - val_accuracy: 0.8590\n",
      "Epoch 43/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4081 - accuracy: 0.8618 - val_loss: 0.4265 - val_accuracy: 0.8580\n",
      "Epoch 44/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4072 - accuracy: 0.8619 - val_loss: 0.4226 - val_accuracy: 0.8590\n",
      "Epoch 45/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4067 - accuracy: 0.8629 - val_loss: 0.4221 - val_accuracy: 0.8582\n",
      "Epoch 46/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4060 - accuracy: 0.8629 - val_loss: 0.4234 - val_accuracy: 0.8608\n",
      "Epoch 47/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4048 - accuracy: 0.8635 - val_loss: 0.4227 - val_accuracy: 0.8616\n",
      "Epoch 48/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4042 - accuracy: 0.8647 - val_loss: 0.4229 - val_accuracy: 0.8578\n",
      "Epoch 49/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4035 - accuracy: 0.8633 - val_loss: 0.4252 - val_accuracy: 0.8592\n",
      "Epoch 50/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4027 - accuracy: 0.8640 - val_loss: 0.4229 - val_accuracy: 0.8608\n",
      "Epoch 51/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4021 - accuracy: 0.8639 - val_loss: 0.4228 - val_accuracy: 0.8606\n",
      "Epoch 52/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4013 - accuracy: 0.8649 - val_loss: 0.4200 - val_accuracy: 0.8596\n",
      "Epoch 53/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4007 - accuracy: 0.8637 - val_loss: 0.4213 - val_accuracy: 0.8564\n",
      "Epoch 54/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4002 - accuracy: 0.8657 - val_loss: 0.4191 - val_accuracy: 0.8608\n",
      "Epoch 55/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3993 - accuracy: 0.8650 - val_loss: 0.4243 - val_accuracy: 0.8600\n",
      "Epoch 56/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3989 - accuracy: 0.8653 - val_loss: 0.4191 - val_accuracy: 0.8622\n",
      "Epoch 57/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3985 - accuracy: 0.8652 - val_loss: 0.4234 - val_accuracy: 0.8594\n",
      "Epoch 58/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3974 - accuracy: 0.8659 - val_loss: 0.4188 - val_accuracy: 0.8622\n",
      "Epoch 59/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3974 - accuracy: 0.8654 - val_loss: 0.4220 - val_accuracy: 0.8598\n",
      "Epoch 60/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3965 - accuracy: 0.8664 - val_loss: 0.4193 - val_accuracy: 0.8616\n",
      "Epoch 61/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3956 - accuracy: 0.8657 - val_loss: 0.4166 - val_accuracy: 0.8612\n",
      "Epoch 62/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3954 - accuracy: 0.8662 - val_loss: 0.4236 - val_accuracy: 0.8612\n",
      "Epoch 63/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3948 - accuracy: 0.8671 - val_loss: 0.4163 - val_accuracy: 0.8616\n",
      "Epoch 64/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3945 - accuracy: 0.8661 - val_loss: 0.4180 - val_accuracy: 0.8588\n",
      "Epoch 65/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3945 - accuracy: 0.8678 - val_loss: 0.4167 - val_accuracy: 0.8634\n",
      "Epoch 66/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3932 - accuracy: 0.8670 - val_loss: 0.4191 - val_accuracy: 0.8598\n",
      "Epoch 67/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3928 - accuracy: 0.8673 - val_loss: 0.4205 - val_accuracy: 0.8622\n",
      "Epoch 68/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3926 - accuracy: 0.8677 - val_loss: 0.4164 - val_accuracy: 0.8620\n",
      "Epoch 69/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3920 - accuracy: 0.8668 - val_loss: 0.4149 - val_accuracy: 0.8612\n",
      "Epoch 70/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3912 - accuracy: 0.8680 - val_loss: 0.4151 - val_accuracy: 0.8612\n",
      "Epoch 71/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3914 - accuracy: 0.8669 - val_loss: 0.4160 - val_accuracy: 0.8608\n",
      "Epoch 72/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3908 - accuracy: 0.8681 - val_loss: 0.4166 - val_accuracy: 0.8636\n",
      "Epoch 73/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3901 - accuracy: 0.8683 - val_loss: 0.4194 - val_accuracy: 0.8592\n",
      "Epoch 74/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3897 - accuracy: 0.8684 - val_loss: 0.4157 - val_accuracy: 0.8612\n",
      "Epoch 75/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3894 - accuracy: 0.8681 - val_loss: 0.4178 - val_accuracy: 0.8612\n",
      "Epoch 76/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3888 - accuracy: 0.8686 - val_loss: 0.4226 - val_accuracy: 0.8578\n",
      "Epoch 77/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3884 - accuracy: 0.8684 - val_loss: 0.4181 - val_accuracy: 0.8598\n",
      "Epoch 78/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3879 - accuracy: 0.8686 - val_loss: 0.4203 - val_accuracy: 0.8608\n",
      "Epoch 79/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3878 - accuracy: 0.8693 - val_loss: 0.4131 - val_accuracy: 0.8626\n",
      "Epoch 80/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3874 - accuracy: 0.8687 - val_loss: 0.4129 - val_accuracy: 0.8624\n",
      "Epoch 81/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3869 - accuracy: 0.8684 - val_loss: 0.4230 - val_accuracy: 0.8552\n",
      "Epoch 82/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3867 - accuracy: 0.8688 - val_loss: 0.4128 - val_accuracy: 0.8616\n",
      "Epoch 83/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3867 - accuracy: 0.8699 - val_loss: 0.4150 - val_accuracy: 0.8602\n",
      "Epoch 84/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3857 - accuracy: 0.8687 - val_loss: 0.4198 - val_accuracy: 0.8560\n",
      "Epoch 85/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3856 - accuracy: 0.8700 - val_loss: 0.4158 - val_accuracy: 0.8630\n",
      "Epoch 86/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3851 - accuracy: 0.8698 - val_loss: 0.4132 - val_accuracy: 0.8610\n",
      "Epoch 87/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3852 - accuracy: 0.8691 - val_loss: 0.4153 - val_accuracy: 0.8602\n",
      "Epoch 88/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3845 - accuracy: 0.8698 - val_loss: 0.4124 - val_accuracy: 0.8620\n",
      "Epoch 89/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3844 - accuracy: 0.8697 - val_loss: 0.4163 - val_accuracy: 0.8568\n",
      "Epoch 90/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3838 - accuracy: 0.8697 - val_loss: 0.4138 - val_accuracy: 0.8614\n",
      "Epoch 91/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3831 - accuracy: 0.8698 - val_loss: 0.4120 - val_accuracy: 0.8618\n",
      "Epoch 92/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3831 - accuracy: 0.8712 - val_loss: 0.4124 - val_accuracy: 0.8642\n",
      "Epoch 93/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3829 - accuracy: 0.8702 - val_loss: 0.4162 - val_accuracy: 0.8604\n",
      "Epoch 94/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3824 - accuracy: 0.8704 - val_loss: 0.4136 - val_accuracy: 0.8608\n",
      "Epoch 95/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3820 - accuracy: 0.8706 - val_loss: 0.4145 - val_accuracy: 0.8640\n",
      "Epoch 96/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3818 - accuracy: 0.8714 - val_loss: 0.4135 - val_accuracy: 0.8628\n",
      "Epoch 97/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3816 - accuracy: 0.8702 - val_loss: 0.4133 - val_accuracy: 0.8622\n",
      "Epoch 98/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3812 - accuracy: 0.8706 - val_loss: 0.4124 - val_accuracy: 0.8610\n",
      "Epoch 99/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3808 - accuracy: 0.8712 - val_loss: 0.4132 - val_accuracy: 0.8616\n",
      "Epoch 100/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3805 - accuracy: 0.8703 - val_loss: 0.4164 - val_accuracy: 0.8590\n",
      "573/573 [==============================] - 1s 983us/step - loss: 0.4301 - accuracy: 0.8495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1146/1146 [==============================] - 2s 1ms/step - loss: 0.9353 - accuracy: 0.7070 - val_loss: 0.6952 - val_accuracy: 0.7788\n",
      "Epoch 2/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.6514 - accuracy: 0.7893 - val_loss: 0.6029 - val_accuracy: 0.8066\n",
      "Epoch 3/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.5899 - accuracy: 0.8073 - val_loss: 0.5635 - val_accuracy: 0.8198\n",
      "Epoch 4/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.5563 - accuracy: 0.8183 - val_loss: 0.5358 - val_accuracy: 0.8270\n",
      "Epoch 5/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.5347 - accuracy: 0.8225 - val_loss: 0.5189 - val_accuracy: 0.8312\n",
      "Epoch 6/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.5192 - accuracy: 0.8267 - val_loss: 0.5041 - val_accuracy: 0.8364\n",
      "Epoch 7/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.5068 - accuracy: 0.8310 - val_loss: 0.5005 - val_accuracy: 0.8352\n",
      "Epoch 8/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4971 - accuracy: 0.8322 - val_loss: 0.4929 - val_accuracy: 0.8396\n",
      "Epoch 9/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4890 - accuracy: 0.8357 - val_loss: 0.4810 - val_accuracy: 0.8436\n",
      "Epoch 10/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4820 - accuracy: 0.8371 - val_loss: 0.4758 - val_accuracy: 0.8468\n",
      "Epoch 11/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4761 - accuracy: 0.8379 - val_loss: 0.4707 - val_accuracy: 0.8456\n",
      "Epoch 12/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4705 - accuracy: 0.8405 - val_loss: 0.4667 - val_accuracy: 0.8452\n",
      "Epoch 13/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4661 - accuracy: 0.8424 - val_loss: 0.4679 - val_accuracy: 0.8424\n",
      "Epoch 14/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4619 - accuracy: 0.8424 - val_loss: 0.4595 - val_accuracy: 0.8484\n",
      "Epoch 15/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4583 - accuracy: 0.8434 - val_loss: 0.4560 - val_accuracy: 0.8498\n",
      "Epoch 16/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4551 - accuracy: 0.8443 - val_loss: 0.4564 - val_accuracy: 0.8524\n",
      "Epoch 17/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4518 - accuracy: 0.8447 - val_loss: 0.4524 - val_accuracy: 0.8500\n",
      "Epoch 18/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4490 - accuracy: 0.8459 - val_loss: 0.4510 - val_accuracy: 0.8498\n",
      "Epoch 19/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4464 - accuracy: 0.8476 - val_loss: 0.4487 - val_accuracy: 0.8530\n",
      "Epoch 20/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4438 - accuracy: 0.8475 - val_loss: 0.4484 - val_accuracy: 0.8526\n",
      "Epoch 21/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4412 - accuracy: 0.8499 - val_loss: 0.4445 - val_accuracy: 0.8550\n",
      "Epoch 22/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4392 - accuracy: 0.8494 - val_loss: 0.4428 - val_accuracy: 0.8530\n",
      "Epoch 23/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4372 - accuracy: 0.8503 - val_loss: 0.4435 - val_accuracy: 0.8538\n",
      "Epoch 24/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4355 - accuracy: 0.8507 - val_loss: 0.4427 - val_accuracy: 0.8516\n",
      "Epoch 25/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4335 - accuracy: 0.8514 - val_loss: 0.4394 - val_accuracy: 0.8526\n",
      "Epoch 26/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4319 - accuracy: 0.8513 - val_loss: 0.4382 - val_accuracy: 0.8540\n",
      "Epoch 27/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4302 - accuracy: 0.8519 - val_loss: 0.4362 - val_accuracy: 0.8548\n",
      "Epoch 28/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4283 - accuracy: 0.8530 - val_loss: 0.4349 - val_accuracy: 0.8530\n",
      "Epoch 29/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4271 - accuracy: 0.8542 - val_loss: 0.4359 - val_accuracy: 0.8510\n",
      "Epoch 30/100\n",
      "1146/1146 [==============================] - 2s 1ms/step - loss: 0.4256 - accuracy: 0.8549 - val_loss: 0.4401 - val_accuracy: 0.8556\n",
      "Epoch 31/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4244 - accuracy: 0.8548 - val_loss: 0.4313 - val_accuracy: 0.8552\n",
      "Epoch 32/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4229 - accuracy: 0.8536 - val_loss: 0.4332 - val_accuracy: 0.8512\n",
      "Epoch 33/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4219 - accuracy: 0.8556 - val_loss: 0.4312 - val_accuracy: 0.8532\n",
      "Epoch 34/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4207 - accuracy: 0.8563 - val_loss: 0.4303 - val_accuracy: 0.8552\n",
      "Epoch 35/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4195 - accuracy: 0.8561 - val_loss: 0.4296 - val_accuracy: 0.8560\n",
      "Epoch 36/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4185 - accuracy: 0.8570 - val_loss: 0.4283 - val_accuracy: 0.8548\n",
      "Epoch 37/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4176 - accuracy: 0.8562 - val_loss: 0.4292 - val_accuracy: 0.8536\n",
      "Epoch 38/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4169 - accuracy: 0.8569 - val_loss: 0.4287 - val_accuracy: 0.8568\n",
      "Epoch 39/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4155 - accuracy: 0.8568 - val_loss: 0.4290 - val_accuracy: 0.8542\n",
      "Epoch 40/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4145 - accuracy: 0.8577 - val_loss: 0.4285 - val_accuracy: 0.8558\n",
      "Epoch 41/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4133 - accuracy: 0.8578 - val_loss: 0.4288 - val_accuracy: 0.8530\n",
      "Epoch 42/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4127 - accuracy: 0.8585 - val_loss: 0.4260 - val_accuracy: 0.8560\n",
      "Epoch 43/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4117 - accuracy: 0.8591 - val_loss: 0.4247 - val_accuracy: 0.8558\n",
      "Epoch 44/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4108 - accuracy: 0.8579 - val_loss: 0.4243 - val_accuracy: 0.8564\n",
      "Epoch 45/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4105 - accuracy: 0.8589 - val_loss: 0.4284 - val_accuracy: 0.8518\n",
      "Epoch 46/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4095 - accuracy: 0.8584 - val_loss: 0.4268 - val_accuracy: 0.8522\n",
      "Epoch 47/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4086 - accuracy: 0.8593 - val_loss: 0.4255 - val_accuracy: 0.8560\n",
      "Epoch 48/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4081 - accuracy: 0.8596 - val_loss: 0.4269 - val_accuracy: 0.8560\n",
      "Epoch 49/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4073 - accuracy: 0.8600 - val_loss: 0.4237 - val_accuracy: 0.8554\n",
      "Epoch 50/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4066 - accuracy: 0.8597 - val_loss: 0.4246 - val_accuracy: 0.8576\n",
      "Epoch 51/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4058 - accuracy: 0.8606 - val_loss: 0.4213 - val_accuracy: 0.8562\n",
      "Epoch 52/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4052 - accuracy: 0.8600 - val_loss: 0.4226 - val_accuracy: 0.8564\n",
      "Epoch 53/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4047 - accuracy: 0.8602 - val_loss: 0.4218 - val_accuracy: 0.8592\n",
      "Epoch 54/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4038 - accuracy: 0.8598 - val_loss: 0.4221 - val_accuracy: 0.8550\n",
      "Epoch 55/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4032 - accuracy: 0.8608 - val_loss: 0.4203 - val_accuracy: 0.8556\n",
      "Epoch 56/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4024 - accuracy: 0.8608 - val_loss: 0.4233 - val_accuracy: 0.8550\n",
      "Epoch 57/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4021 - accuracy: 0.8616 - val_loss: 0.4207 - val_accuracy: 0.8542\n",
      "Epoch 58/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4016 - accuracy: 0.8618 - val_loss: 0.4202 - val_accuracy: 0.8574\n",
      "Epoch 59/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4006 - accuracy: 0.8616 - val_loss: 0.4193 - val_accuracy: 0.8576\n",
      "Epoch 60/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4003 - accuracy: 0.8621 - val_loss: 0.4219 - val_accuracy: 0.8540\n",
      "Epoch 61/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3996 - accuracy: 0.8628 - val_loss: 0.4213 - val_accuracy: 0.8554\n",
      "Epoch 62/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3992 - accuracy: 0.8623 - val_loss: 0.4227 - val_accuracy: 0.8510\n",
      "Epoch 63/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3985 - accuracy: 0.8630 - val_loss: 0.4192 - val_accuracy: 0.8548\n",
      "Epoch 64/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3981 - accuracy: 0.8632 - val_loss: 0.4186 - val_accuracy: 0.8578\n",
      "Epoch 65/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3978 - accuracy: 0.8622 - val_loss: 0.4192 - val_accuracy: 0.8560\n",
      "Epoch 66/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3973 - accuracy: 0.8634 - val_loss: 0.4185 - val_accuracy: 0.8564\n",
      "Epoch 67/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3969 - accuracy: 0.8624 - val_loss: 0.4197 - val_accuracy: 0.8556\n",
      "Epoch 68/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3963 - accuracy: 0.8636 - val_loss: 0.4178 - val_accuracy: 0.8572\n",
      "Epoch 69/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3957 - accuracy: 0.8633 - val_loss: 0.4178 - val_accuracy: 0.8576\n",
      "Epoch 70/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3950 - accuracy: 0.8634 - val_loss: 0.4182 - val_accuracy: 0.8576\n",
      "Epoch 71/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3948 - accuracy: 0.8633 - val_loss: 0.4189 - val_accuracy: 0.8574\n",
      "Epoch 72/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3943 - accuracy: 0.8636 - val_loss: 0.4192 - val_accuracy: 0.8558\n",
      "Epoch 73/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3938 - accuracy: 0.8634 - val_loss: 0.4155 - val_accuracy: 0.8582\n",
      "Epoch 74/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3933 - accuracy: 0.8645 - val_loss: 0.4179 - val_accuracy: 0.8556\n",
      "Epoch 75/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3930 - accuracy: 0.8644 - val_loss: 0.4179 - val_accuracy: 0.8566\n",
      "Epoch 76/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3926 - accuracy: 0.8643 - val_loss: 0.4208 - val_accuracy: 0.8582\n",
      "Epoch 77/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3924 - accuracy: 0.8649 - val_loss: 0.4162 - val_accuracy: 0.8562\n",
      "Epoch 78/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3916 - accuracy: 0.8645 - val_loss: 0.4180 - val_accuracy: 0.8580\n",
      "Epoch 79/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3917 - accuracy: 0.8642 - val_loss: 0.4158 - val_accuracy: 0.8556\n",
      "Epoch 80/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3911 - accuracy: 0.8646 - val_loss: 0.4152 - val_accuracy: 0.8578\n",
      "Epoch 81/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3909 - accuracy: 0.8645 - val_loss: 0.4226 - val_accuracy: 0.8540\n",
      "Epoch 82/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3903 - accuracy: 0.8649 - val_loss: 0.4163 - val_accuracy: 0.8566\n",
      "Epoch 83/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3901 - accuracy: 0.8651 - val_loss: 0.4182 - val_accuracy: 0.8572\n",
      "Epoch 84/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3897 - accuracy: 0.8648 - val_loss: 0.4155 - val_accuracy: 0.8578\n",
      "Epoch 85/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3891 - accuracy: 0.8649 - val_loss: 0.4163 - val_accuracy: 0.8568\n",
      "Epoch 86/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3886 - accuracy: 0.8661 - val_loss: 0.4163 - val_accuracy: 0.8568\n",
      "Epoch 87/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3885 - accuracy: 0.8657 - val_loss: 0.4171 - val_accuracy: 0.8600\n",
      "Epoch 88/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3882 - accuracy: 0.8655 - val_loss: 0.4140 - val_accuracy: 0.8588\n",
      "Epoch 89/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3879 - accuracy: 0.8655 - val_loss: 0.4167 - val_accuracy: 0.8582\n",
      "Epoch 90/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3874 - accuracy: 0.8657 - val_loss: 0.4160 - val_accuracy: 0.8566\n",
      "Epoch 91/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3873 - accuracy: 0.8649 - val_loss: 0.4160 - val_accuracy: 0.8562\n",
      "Epoch 92/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3868 - accuracy: 0.8669 - val_loss: 0.4146 - val_accuracy: 0.8588\n",
      "Epoch 93/100\n",
      "1146/1146 [==============================] - 2s 1ms/step - loss: 0.3865 - accuracy: 0.8661 - val_loss: 0.4144 - val_accuracy: 0.8584\n",
      "Epoch 94/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3859 - accuracy: 0.8667 - val_loss: 0.4166 - val_accuracy: 0.8558\n",
      "Epoch 95/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3857 - accuracy: 0.8654 - val_loss: 0.4147 - val_accuracy: 0.8562\n",
      "Epoch 96/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3859 - accuracy: 0.8662 - val_loss: 0.4139 - val_accuracy: 0.8580\n",
      "Epoch 97/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3853 - accuracy: 0.8658 - val_loss: 0.4183 - val_accuracy: 0.8590\n",
      "Epoch 98/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3848 - accuracy: 0.8668 - val_loss: 0.4243 - val_accuracy: 0.8562\n",
      "Epoch 99/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3844 - accuracy: 0.8658 - val_loss: 0.4154 - val_accuracy: 0.8580\n",
      "Epoch 100/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3847 - accuracy: 0.8665 - val_loss: 0.4141 - val_accuracy: 0.8572\n",
      "573/573 [==============================] - 1s 1ms/step - loss: 0.4188 - accuracy: 0.8597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1146/1146 [==============================] - 2s 1ms/step - loss: 0.9328 - accuracy: 0.7077 - val_loss: 0.6891 - val_accuracy: 0.7802\n",
      "Epoch 2/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.6497 - accuracy: 0.7901 - val_loss: 0.6037 - val_accuracy: 0.8052\n",
      "Epoch 3/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.5877 - accuracy: 0.8083 - val_loss: 0.5615 - val_accuracy: 0.8208\n",
      "Epoch 4/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.5547 - accuracy: 0.8171 - val_loss: 0.5342 - val_accuracy: 0.8284\n",
      "Epoch 5/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.5328 - accuracy: 0.8232 - val_loss: 0.5187 - val_accuracy: 0.8334\n",
      "Epoch 6/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.5175 - accuracy: 0.8257 - val_loss: 0.5081 - val_accuracy: 0.8344\n",
      "Epoch 7/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.5049 - accuracy: 0.8307 - val_loss: 0.4949 - val_accuracy: 0.8414\n",
      "Epoch 8/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4952 - accuracy: 0.8340 - val_loss: 0.4897 - val_accuracy: 0.8400\n",
      "Epoch 9/100\n",
      "1146/1146 [==============================] - 2s 1ms/step - loss: 0.4874 - accuracy: 0.8346 - val_loss: 0.4816 - val_accuracy: 0.8414\n",
      "Epoch 10/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4805 - accuracy: 0.8380 - val_loss: 0.4751 - val_accuracy: 0.8426\n",
      "Epoch 11/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4743 - accuracy: 0.8397 - val_loss: 0.4733 - val_accuracy: 0.8468\n",
      "Epoch 12/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4694 - accuracy: 0.8418 - val_loss: 0.4668 - val_accuracy: 0.8466\n",
      "Epoch 13/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4645 - accuracy: 0.8435 - val_loss: 0.4670 - val_accuracy: 0.8460\n",
      "Epoch 14/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4606 - accuracy: 0.8443 - val_loss: 0.4630 - val_accuracy: 0.8446\n",
      "Epoch 15/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4569 - accuracy: 0.8450 - val_loss: 0.4556 - val_accuracy: 0.8478\n",
      "Epoch 16/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4535 - accuracy: 0.8456 - val_loss: 0.4557 - val_accuracy: 0.8486\n",
      "Epoch 17/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4502 - accuracy: 0.8477 - val_loss: 0.4558 - val_accuracy: 0.8462\n",
      "Epoch 18/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4476 - accuracy: 0.8479 - val_loss: 0.4500 - val_accuracy: 0.8502\n",
      "Epoch 19/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4448 - accuracy: 0.8470 - val_loss: 0.4470 - val_accuracy: 0.8512\n",
      "Epoch 20/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4425 - accuracy: 0.8496 - val_loss: 0.4453 - val_accuracy: 0.8526\n",
      "Epoch 21/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4402 - accuracy: 0.8498 - val_loss: 0.4472 - val_accuracy: 0.8524\n",
      "Epoch 22/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4384 - accuracy: 0.8507 - val_loss: 0.4427 - val_accuracy: 0.8522\n",
      "Epoch 23/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4356 - accuracy: 0.8503 - val_loss: 0.4460 - val_accuracy: 0.8502\n",
      "Epoch 24/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4341 - accuracy: 0.8523 - val_loss: 0.4438 - val_accuracy: 0.8530\n",
      "Epoch 25/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4321 - accuracy: 0.8526 - val_loss: 0.4390 - val_accuracy: 0.8528\n",
      "Epoch 26/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4307 - accuracy: 0.8534 - val_loss: 0.4396 - val_accuracy: 0.8520\n",
      "Epoch 27/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4293 - accuracy: 0.8535 - val_loss: 0.4372 - val_accuracy: 0.8536\n",
      "Epoch 28/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4277 - accuracy: 0.8530 - val_loss: 0.4346 - val_accuracy: 0.8574\n",
      "Epoch 29/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4260 - accuracy: 0.8543 - val_loss: 0.4405 - val_accuracy: 0.8552\n",
      "Epoch 30/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4249 - accuracy: 0.8545 - val_loss: 0.4355 - val_accuracy: 0.8536\n",
      "Epoch 31/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4234 - accuracy: 0.8544 - val_loss: 0.4369 - val_accuracy: 0.8558\n",
      "Epoch 32/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4223 - accuracy: 0.8554 - val_loss: 0.4326 - val_accuracy: 0.8556\n",
      "Epoch 33/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4208 - accuracy: 0.8552 - val_loss: 0.4305 - val_accuracy: 0.8574\n",
      "Epoch 34/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4198 - accuracy: 0.8560 - val_loss: 0.4308 - val_accuracy: 0.8560\n",
      "Epoch 35/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4186 - accuracy: 0.8562 - val_loss: 0.4313 - val_accuracy: 0.8556\n",
      "Epoch 36/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4176 - accuracy: 0.8570 - val_loss: 0.4298 - val_accuracy: 0.8534\n",
      "Epoch 37/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4165 - accuracy: 0.8564 - val_loss: 0.4293 - val_accuracy: 0.8558\n",
      "Epoch 38/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4155 - accuracy: 0.8576 - val_loss: 0.4279 - val_accuracy: 0.8566\n",
      "Epoch 39/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4143 - accuracy: 0.8581 - val_loss: 0.4311 - val_accuracy: 0.8540\n",
      "Epoch 40/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4135 - accuracy: 0.8577 - val_loss: 0.4292 - val_accuracy: 0.8546\n",
      "Epoch 41/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4126 - accuracy: 0.8585 - val_loss: 0.4277 - val_accuracy: 0.8544\n",
      "Epoch 42/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4118 - accuracy: 0.8585 - val_loss: 0.4282 - val_accuracy: 0.8524\n",
      "Epoch 43/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4108 - accuracy: 0.8583 - val_loss: 0.4328 - val_accuracy: 0.8514\n",
      "Epoch 44/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4103 - accuracy: 0.8587 - val_loss: 0.4275 - val_accuracy: 0.8542\n",
      "Epoch 45/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4095 - accuracy: 0.8588 - val_loss: 0.4280 - val_accuracy: 0.8546\n",
      "Epoch 46/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4085 - accuracy: 0.8598 - val_loss: 0.4263 - val_accuracy: 0.8566\n",
      "Epoch 47/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4077 - accuracy: 0.8607 - val_loss: 0.4287 - val_accuracy: 0.8552\n",
      "Epoch 48/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4071 - accuracy: 0.8607 - val_loss: 0.4256 - val_accuracy: 0.8530\n",
      "Epoch 49/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4065 - accuracy: 0.8603 - val_loss: 0.4273 - val_accuracy: 0.8534\n",
      "Epoch 50/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4055 - accuracy: 0.8607 - val_loss: 0.4263 - val_accuracy: 0.8550\n",
      "Epoch 51/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4051 - accuracy: 0.8607 - val_loss: 0.4254 - val_accuracy: 0.8538\n",
      "Epoch 52/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4041 - accuracy: 0.8617 - val_loss: 0.4260 - val_accuracy: 0.8558\n",
      "Epoch 53/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4039 - accuracy: 0.8613 - val_loss: 0.4250 - val_accuracy: 0.8530\n",
      "Epoch 54/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4028 - accuracy: 0.8613 - val_loss: 0.4215 - val_accuracy: 0.8570\n",
      "Epoch 55/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4025 - accuracy: 0.8610 - val_loss: 0.4224 - val_accuracy: 0.8550\n",
      "Epoch 56/100\n",
      "1146/1146 [==============================] - 2s 1ms/step - loss: 0.4021 - accuracy: 0.8617 - val_loss: 0.4211 - val_accuracy: 0.8564\n",
      "Epoch 57/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4012 - accuracy: 0.8627 - val_loss: 0.4235 - val_accuracy: 0.8560\n",
      "Epoch 58/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4006 - accuracy: 0.8625 - val_loss: 0.4218 - val_accuracy: 0.8552\n",
      "Epoch 59/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.4001 - accuracy: 0.8621 - val_loss: 0.4222 - val_accuracy: 0.8548\n",
      "Epoch 60/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3996 - accuracy: 0.8622 - val_loss: 0.4232 - val_accuracy: 0.8556\n",
      "Epoch 61/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3990 - accuracy: 0.8634 - val_loss: 0.4213 - val_accuracy: 0.8584\n",
      "Epoch 62/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3983 - accuracy: 0.8637 - val_loss: 0.4225 - val_accuracy: 0.8600\n",
      "Epoch 63/100\n",
      "1146/1146 [==============================] - 2s 1ms/step - loss: 0.3978 - accuracy: 0.8625 - val_loss: 0.4205 - val_accuracy: 0.8536\n",
      "Epoch 64/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3976 - accuracy: 0.8634 - val_loss: 0.4201 - val_accuracy: 0.8568\n",
      "Epoch 65/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3967 - accuracy: 0.8639 - val_loss: 0.4195 - val_accuracy: 0.8558\n",
      "Epoch 66/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3967 - accuracy: 0.8638 - val_loss: 0.4180 - val_accuracy: 0.8556\n",
      "Epoch 67/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3959 - accuracy: 0.8648 - val_loss: 0.4206 - val_accuracy: 0.8542\n",
      "Epoch 68/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3955 - accuracy: 0.8642 - val_loss: 0.4201 - val_accuracy: 0.8544\n",
      "Epoch 69/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3952 - accuracy: 0.8641 - val_loss: 0.4228 - val_accuracy: 0.8564\n",
      "Epoch 70/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3946 - accuracy: 0.8640 - val_loss: 0.4196 - val_accuracy: 0.8586\n",
      "Epoch 71/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3942 - accuracy: 0.8649 - val_loss: 0.4183 - val_accuracy: 0.8560\n",
      "Epoch 72/100\n",
      "1146/1146 [==============================] - 2s 1ms/step - loss: 0.3938 - accuracy: 0.8648 - val_loss: 0.4212 - val_accuracy: 0.8570\n",
      "Epoch 73/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3931 - accuracy: 0.8643 - val_loss: 0.4187 - val_accuracy: 0.8556\n",
      "Epoch 74/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3933 - accuracy: 0.8637 - val_loss: 0.4197 - val_accuracy: 0.8538\n",
      "Epoch 75/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3925 - accuracy: 0.8645 - val_loss: 0.4239 - val_accuracy: 0.8554\n",
      "Epoch 76/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 0.3920 - accuracy: 0.8653 - val_loss: 0.4184 - val_accuracy: 0.8576\n",
      "573/573 [==============================] - 1s 998us/step - loss: 0.4228 - accuracy: 0.8549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.9273 - accuracy: 0.6972 - val_loss: 0.6285 - val_accuracy: 0.7878\n",
      "Epoch 2/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.5660 - accuracy: 0.8079 - val_loss: 0.5123 - val_accuracy: 0.8260\n",
      "Epoch 3/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4999 - accuracy: 0.8291 - val_loss: 0.4769 - val_accuracy: 0.8400\n",
      "Epoch 4/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4685 - accuracy: 0.8359 - val_loss: 0.4715 - val_accuracy: 0.8396\n",
      "Epoch 5/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4456 - accuracy: 0.8435 - val_loss: 0.4256 - val_accuracy: 0.8566\n",
      "Epoch 6/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4301 - accuracy: 0.8510 - val_loss: 0.4565 - val_accuracy: 0.8452\n",
      "Epoch 7/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4168 - accuracy: 0.8550 - val_loss: 0.4261 - val_accuracy: 0.8528\n",
      "Epoch 8/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4052 - accuracy: 0.8593 - val_loss: 0.4009 - val_accuracy: 0.8636\n",
      "Epoch 9/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.3942 - accuracy: 0.8623 - val_loss: 0.3999 - val_accuracy: 0.8638\n",
      "Epoch 10/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.3873 - accuracy: 0.8648 - val_loss: 0.4138 - val_accuracy: 0.8550\n",
      "Epoch 11/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.3782 - accuracy: 0.8674 - val_loss: 0.4238 - val_accuracy: 0.8558\n",
      "Epoch 12/100\n",
      " 539/1146 [=============>................] - ETA: 0s - loss: 0.3681 - accuracy: 0.8709"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_56088\\50421083.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mrnd_search_cv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRandomizedSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeras_reg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_distribs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mrnd_search_cv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEarlyStopping\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpatience\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\David\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    708\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    709\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 710\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    711\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    712\u001b[0m         \u001b[1;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\David\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1482\u001b[0m         evaluate_candidates(ParameterSampler(\n\u001b[0;32m   1483\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_distributions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1484\u001b[1;33m             random_state=self.random_state))\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\David\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params)\u001b[0m\n\u001b[0;32m    687\u001b[0m                                \u001b[1;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    688\u001b[0m                                in product(candidate_params,\n\u001b[1;32m--> 689\u001b[1;33m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[0;32m    690\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    691\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\David\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1005\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1006\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1007\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1008\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1009\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\David\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    833\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    834\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 835\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    836\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    837\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\David\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    752\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    753\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 754\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    755\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    756\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\David\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    207\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 209\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    210\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\David\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    588\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    589\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 590\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    591\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    592\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\David\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    254\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 256\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\David\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    254\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 256\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\David\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    513\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    514\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 515\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    516\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    517\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\wrappers\\scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[0;32m    173\u001b[0m         \u001b[0mfit_args\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    174\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 175\u001b[1;33m         \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    176\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1639\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_epoch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1640\u001b[0m                 \u001b[1;32mwith\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcatch_stop_iteration\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1641\u001b[1;33m                     \u001b[1;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1642\u001b[0m                         with tf.profiler.experimental.Trace(\n\u001b[0;32m   1643\u001b[0m                             \u001b[1;34m\"train\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36msteps\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1369\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_insufficient_data\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Set by `catch_stop_iteration`.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1370\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1371\u001b[1;33m             \u001b[0moriginal_spe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_steps_per_execution\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1372\u001b[0m             can_run_full_execution = (\n\u001b[0;32m   1373\u001b[0m                 \u001b[0moriginal_spe\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    637\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    638\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 639\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    640\u001b[0m     raise NotImplementedError(\n\u001b[0;32m    641\u001b[0m         \"numpy() is only available when eager execution is enabled.\")\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py\u001b[0m in \u001b[0;36mread_value\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    728\u001b[0m     \u001b[1;31m# Return an identity so it can get placed on whatever device the context\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    729\u001b[0m     \u001b[1;31m# specifies instead of the device where the variable is.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 730\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0midentity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    731\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    732\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mread_value_no_copy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mop_dispatch_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1174\u001b[0m       \u001b[1;31m# Fallback dispatch system (dispatch v1):\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1175\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1176\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mdispatch_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1177\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1178\u001b[0m         \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\ops\\array_ops.py\u001b[0m in \u001b[0;36midentity\u001b[1;34m(input, name)\u001b[0m\n\u001b[0;32m    292\u001b[0m     \u001b[1;31m# variables. Variables have correct handle data when graph building.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    293\u001b[0m     \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 294\u001b[1;33m   \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0midentity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    295\u001b[0m   \u001b[1;31m# Propagate handle data for happier shape inference for resource variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    296\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"_handle_data\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\u001b[0m in \u001b[0;36midentity\u001b[1;34m(input, name)\u001b[0m\n\u001b[0;32m   4834\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4835\u001b[0m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[1;32m-> 4836\u001b[1;33m         _ctx, \"Identity\", name, input)\n\u001b[0m\u001b[0;32m   4837\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4838\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from scipy.stats import reciprocal\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "param_distribs = {\"n_hidden\": [0, 1, 2, 3],\n",
    "                    \"n_neurons\": np.arange(1, 100),\n",
    "                    \"learning_rate\": reciprocal(3e-4, 3e-2),}\n",
    "\n",
    "rnd_search_cv = RandomizedSearchCV(keras_reg, param_distribs, n_iter=10, cv=3)\n",
    "rnd_search_cv.fit(X_train, y_train, epochs=100, validation_data=(X_valid, y_valid), callbacks=[keras.callbacks.EarlyStopping(patience=10)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'RandomizedSearchCV' object has no attribute 'best_params_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_56088\\1946474928.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# you can now access the best training parameters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mrnd_search_cv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mrnd_search_cv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'RandomizedSearchCV' object has no attribute 'best_params_'"
     ]
    }
   ],
   "source": [
    "# you can now access the best training parameters\n",
    "rnd_search_cv.best_params_\n",
    "rnd_search_cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the best model  \n",
    "model = rnd_search_cv.best_estimator_.model\n",
    "model.save(\"my_keras_fashion_model_rnd_tuned.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mind you, there may be more EFFICIENT methods of optimization than going through parameters randomly and hoping for the best. \n",
    "Keras Tuner is one such tool. \n",
    "\n",
    "(414, Manning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
