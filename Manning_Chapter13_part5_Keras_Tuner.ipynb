{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\david\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\david\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\david\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\david\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install keras-tuner -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper Parameter Optimization\n",
    "Keras Tuner allows you to replace hardcoded hyper-parameters with a *search space;* a range of possible hyperparameter choices.  \n",
    "\n",
    "To specify a *search space*, you'll define a model building function that takes hyperparameter (hp) ranges of values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    units = hp.Int('units', min_value=16, max_value=64, step=32)\n",
    "    model = keras.Sequential([\n",
    "        layers.Dense(units, activation='relu'),\n",
    "        layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "    optimizer = hp.Choice('optimizer', values=['rmsprop','adam', 'sgd'])\n",
    "    model.compile(optimizer=optimizer, loss = 'sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you wish to adopt a more modular and configurable approach, you can also extend the HyperModle class and override the build method. This is useful if you want to use the same model architecture for different problems, or if you want to use the same model architecture with different hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\David\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: `import kerastuner` is deprecated, please use `import keras_tuner`.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "import kerastuner as kt\n",
    "\n",
    "class SimpleMLP(kt.HyperModel):\n",
    "    def __init__(self, input_shape, num_classes):\n",
    "        self.input_shape = input_shape\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "    def build(self, hp):\n",
    "        units = hp.Int('units', min_value=16, max_value=64, step=32)\n",
    "        model = keras.Sequential([\n",
    "            layers.Dense(units, activation='relu'),\n",
    "            layers.Dense(self.num_classes, activation='softmax')\n",
    "        ])\n",
    "        optimizer = hp.Choice('optimizer', values=['rmsprop','adam', 'sgd'])\n",
    "        model.compile(optimizer=optimizer, loss = 'sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "        return model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuner\n",
    "Next step is to define a *tuner* which is a for loop that will repeatedly...\n",
    "> Pick a set of hyperparameter values\n",
    "> Call the model-building function with these values to create a model\n",
    "> Train the model and record its metrics\n",
    "\n",
    "Several tuners are pre-built into kt such as *RandomSearch, BayesianOptimization, Hyperband.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build the tuner\n",
    "tuner = kt.BayesianOptimization(build_model, objective='val_accuracy', max_trials=5, directory='mnist_kt_test', project_name='intro_to_kt_mnist', overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search space summary\n",
      "Default search space size: 2\n",
      "units (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 16, 'max_value': 64, 'step': 32, 'sampling': 'linear'}\n",
      "optimizer (Choice)\n",
      "{'default': 'rmsprop', 'conditions': [], 'values': ['rmsprop', 'adam', 'sgd'], 'ordered': False}\n"
     ]
    }
   ],
   "source": [
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "x_train = x_train.reshape(-1, 28*28).astype('float32') / 255.0\n",
    "x_test = x_test.reshape(-1, 28*28).astype('float32') / 255.0\n",
    "x_train_full = x_train\n",
    "y_train_full = y_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_val_samples = 10000\n",
    "x_train, x_val = x_train_full[:-num_val_samples], x_train_full[-num_val_samples:]\n",
    "y_train, y_val = y_train_full[:-num_val_samples], y_train_full[-num_val_samples:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 Complete [00h 00m 37s]\n",
      "val_accuracy: 0.9538000226020813\n",
      "\n",
      "Best val_accuracy So Far: 0.9740999937057495\n",
      "Total elapsed time: 00h 03m 40s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "callbacks = [keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)]\n",
    "\n",
    "tuner.search(x_train, y_train, epochs=50, validation_data=(x_val, y_val), callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_n = 3\n",
    "top_params = tuner.get_best_hyperparameters(num_trials=top_n)\n",
    "top_models = tuner.get_best_models(num_models=top_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_epoch(hp):\n",
    "    model=build_model(hp)\n",
    "    callbacks = [keras.callbacks.EarlyStopping(monitor='val_loss', mode=\"min\", patience=10)]\n",
    "    history = model.fit(x_train, y_train, epochs=50, validation_data=(x_val, y_val), batch_size=128, callbacks=callbacks)\n",
    "    val_loss_per_epoch = history.history['val_loss']\n",
    "    best_epoch = val_loss_per_epoch.index(min(val_loss_per_epoch)) + 1\n",
    "    print(f\"Best epoch: {best_epoch}\" )\n",
    "    return best_epoch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_trained_model(hp):\n",
    "    best_epoch = get_best_epoch(hp)\n",
    "    #model = build_model(hp)\n",
    "    model.fit(x_train, y_train, epochs=int(best_epoch*1.2), validation_data=(x_val, y_val), batch_size=128)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.4942 - accuracy: 0.8667 - val_loss: 0.2473 - val_accuracy: 0.9317\n",
      "Epoch 2/50\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.2264 - accuracy: 0.9355 - val_loss: 0.1845 - val_accuracy: 0.9481\n",
      "Epoch 3/50\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.1771 - accuracy: 0.9491 - val_loss: 0.1571 - val_accuracy: 0.9560\n",
      "Epoch 4/50\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.1468 - accuracy: 0.9578 - val_loss: 0.1381 - val_accuracy: 0.9636\n",
      "Epoch 5/50\n",
      "391/391 [==============================] - 1s 1ms/step - loss: 0.1260 - accuracy: 0.9640 - val_loss: 0.1270 - val_accuracy: 0.9646\n",
      "Epoch 6/50\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.1106 - accuracy: 0.9679 - val_loss: 0.1210 - val_accuracy: 0.9648\n",
      "Epoch 7/50\n",
      "391/391 [==============================] - 1s 1ms/step - loss: 0.0982 - accuracy: 0.9718 - val_loss: 0.1137 - val_accuracy: 0.9669\n",
      "Epoch 8/50\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.0873 - accuracy: 0.9751 - val_loss: 0.1074 - val_accuracy: 0.9684\n",
      "Epoch 9/50\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.0803 - accuracy: 0.9767 - val_loss: 0.1053 - val_accuracy: 0.9694\n",
      "Epoch 10/50\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.0725 - accuracy: 0.9787 - val_loss: 0.1010 - val_accuracy: 0.9702\n",
      "Epoch 11/50\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.0660 - accuracy: 0.9813 - val_loss: 0.0987 - val_accuracy: 0.9703\n",
      "Epoch 12/50\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.0611 - accuracy: 0.9825 - val_loss: 0.1004 - val_accuracy: 0.9676\n",
      "Epoch 13/50\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.0557 - accuracy: 0.9843 - val_loss: 0.0923 - val_accuracy: 0.9712\n",
      "Epoch 14/50\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.0518 - accuracy: 0.9856 - val_loss: 0.0938 - val_accuracy: 0.9704\n",
      "Epoch 15/50\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.0475 - accuracy: 0.9867 - val_loss: 0.0952 - val_accuracy: 0.9706\n",
      "Epoch 16/50\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.0443 - accuracy: 0.9875 - val_loss: 0.0946 - val_accuracy: 0.9712\n",
      "Epoch 17/50\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.0408 - accuracy: 0.9890 - val_loss: 0.0921 - val_accuracy: 0.9726\n",
      "Epoch 18/50\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.0378 - accuracy: 0.9898 - val_loss: 0.0911 - val_accuracy: 0.9738\n",
      "Epoch 19/50\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.0348 - accuracy: 0.9913 - val_loss: 0.0951 - val_accuracy: 0.9723\n",
      "Epoch 20/50\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.0326 - accuracy: 0.9911 - val_loss: 0.0992 - val_accuracy: 0.9715\n",
      "Epoch 21/50\n",
      "391/391 [==============================] - 1s 1ms/step - loss: 0.0301 - accuracy: 0.9925 - val_loss: 0.0922 - val_accuracy: 0.9739\n",
      "Epoch 22/50\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.0276 - accuracy: 0.9929 - val_loss: 0.0990 - val_accuracy: 0.9721\n",
      "Epoch 23/50\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.0253 - accuracy: 0.9939 - val_loss: 0.0949 - val_accuracy: 0.9730\n",
      "Epoch 24/50\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.0239 - accuracy: 0.9943 - val_loss: 0.0960 - val_accuracy: 0.9732\n",
      "Epoch 25/50\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.0224 - accuracy: 0.9944 - val_loss: 0.0981 - val_accuracy: 0.9732\n",
      "Epoch 26/50\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.0197 - accuracy: 0.9957 - val_loss: 0.0979 - val_accuracy: 0.9736\n",
      "Epoch 27/50\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.0190 - accuracy: 0.9956 - val_loss: 0.1006 - val_accuracy: 0.9722\n",
      "Epoch 28/50\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.0177 - accuracy: 0.9962 - val_loss: 0.1043 - val_accuracy: 0.9723\n",
      "Best epoch: 18\n",
      "Epoch 1/21\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.4806 - accuracy: 0.8711 - val_loss: 0.2441 - val_accuracy: 0.9343\n",
      "Epoch 2/21\n",
      "391/391 [==============================] - 1s 1ms/step - loss: 0.2318 - accuracy: 0.9346 - val_loss: 0.1937 - val_accuracy: 0.9465\n",
      "Epoch 3/21\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.1824 - accuracy: 0.9477 - val_loss: 0.1649 - val_accuracy: 0.9544\n",
      "Epoch 4/21\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.1515 - accuracy: 0.9562 - val_loss: 0.1441 - val_accuracy: 0.9598\n",
      "Epoch 5/21\n",
      "391/391 [==============================] - 1s 1ms/step - loss: 0.1307 - accuracy: 0.9618 - val_loss: 0.1340 - val_accuracy: 0.9604\n",
      "Epoch 6/21\n",
      "391/391 [==============================] - 1s 1ms/step - loss: 0.1152 - accuracy: 0.9662 - val_loss: 0.1220 - val_accuracy: 0.9661\n",
      "Epoch 7/21\n",
      "391/391 [==============================] - 1s 1ms/step - loss: 0.1031 - accuracy: 0.9699 - val_loss: 0.1165 - val_accuracy: 0.9656\n",
      "Epoch 8/21\n",
      "391/391 [==============================] - 1s 1ms/step - loss: 0.0933 - accuracy: 0.9723 - val_loss: 0.1112 - val_accuracy: 0.9699\n",
      "Epoch 9/21\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.0847 - accuracy: 0.9747 - val_loss: 0.1078 - val_accuracy: 0.9696\n",
      "Epoch 10/21\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.0772 - accuracy: 0.9771 - val_loss: 0.1090 - val_accuracy: 0.9676\n",
      "Epoch 11/21\n",
      "391/391 [==============================] - 1s 1ms/step - loss: 0.0700 - accuracy: 0.9795 - val_loss: 0.1085 - val_accuracy: 0.9678\n",
      "Epoch 12/21\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.0652 - accuracy: 0.9810 - val_loss: 0.1032 - val_accuracy: 0.9693\n",
      "Epoch 13/21\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.0599 - accuracy: 0.9825 - val_loss: 0.1051 - val_accuracy: 0.9691\n",
      "Epoch 14/21\n",
      "391/391 [==============================] - 1s 1ms/step - loss: 0.0557 - accuracy: 0.9843 - val_loss: 0.1021 - val_accuracy: 0.9703\n",
      "Epoch 15/21\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.0508 - accuracy: 0.9854 - val_loss: 0.1012 - val_accuracy: 0.9700\n",
      "Epoch 16/21\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.0479 - accuracy: 0.9864 - val_loss: 0.1055 - val_accuracy: 0.9709\n",
      "Epoch 17/21\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.0448 - accuracy: 0.9871 - val_loss: 0.0994 - val_accuracy: 0.9704\n",
      "Epoch 18/21\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.0410 - accuracy: 0.9889 - val_loss: 0.1038 - val_accuracy: 0.9692\n",
      "Epoch 19/21\n",
      "391/391 [==============================] - 1s 1ms/step - loss: 0.0383 - accuracy: 0.9894 - val_loss: 0.1089 - val_accuracy: 0.9702\n",
      "Epoch 20/21\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.0353 - accuracy: 0.9903 - val_loss: 0.1012 - val_accuracy: 0.9704\n",
      "Epoch 21/21\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.0339 - accuracy: 0.9906 - val_loss: 0.1099 - val_accuracy: 0.9704\n",
      "313/313 [==============================] - 0s 869us/step - loss: 0.0968 - accuracy: 0.9709\n",
      "Epoch 1/50\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.4615 - accuracy: 0.8788 - val_loss: 0.2560 - val_accuracy: 0.9287\n",
      "Epoch 2/50\n",
      "391/391 [==============================] - 1s 1ms/step - loss: 0.2467 - accuracy: 0.9306 - val_loss: 0.2111 - val_accuracy: 0.9395\n",
      "Epoch 3/50\n",
      "391/391 [==============================] - 1s 1ms/step - loss: 0.1974 - accuracy: 0.9441 - val_loss: 0.1764 - val_accuracy: 0.9513\n",
      "Epoch 4/50\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.1663 - accuracy: 0.9528 - val_loss: 0.1491 - val_accuracy: 0.9582\n",
      "Epoch 5/50\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.1441 - accuracy: 0.9589 - val_loss: 0.1367 - val_accuracy: 0.9621\n",
      "Epoch 6/50\n",
      "391/391 [==============================] - 1s 1ms/step - loss: 0.1281 - accuracy: 0.9630 - val_loss: 0.1295 - val_accuracy: 0.9631\n",
      "Epoch 7/50\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.1143 - accuracy: 0.9678 - val_loss: 0.1250 - val_accuracy: 0.9639\n",
      "Epoch 8/50\n",
      "391/391 [==============================] - 1s 1ms/step - loss: 0.1040 - accuracy: 0.9701 - val_loss: 0.1164 - val_accuracy: 0.9668\n",
      "Epoch 9/50\n",
      "391/391 [==============================] - 1s 1ms/step - loss: 0.0948 - accuracy: 0.9731 - val_loss: 0.1129 - val_accuracy: 0.9666\n",
      "Epoch 10/50\n",
      "391/391 [==============================] - 1s 1ms/step - loss: 0.0869 - accuracy: 0.9748 - val_loss: 0.1099 - val_accuracy: 0.9683\n",
      "Epoch 11/50\n",
      "391/391 [==============================] - 1s 1ms/step - loss: 0.0804 - accuracy: 0.9767 - val_loss: 0.1121 - val_accuracy: 0.9689\n",
      "Epoch 12/50\n",
      "391/391 [==============================] - 1s 1ms/step - loss: 0.0752 - accuracy: 0.9785 - val_loss: 0.1056 - val_accuracy: 0.9692\n",
      "Epoch 13/50\n",
      "391/391 [==============================] - 1s 1ms/step - loss: 0.0696 - accuracy: 0.9798 - val_loss: 0.1064 - val_accuracy: 0.9699\n",
      "Epoch 14/50\n",
      "391/391 [==============================] - 1s 1ms/step - loss: 0.0650 - accuracy: 0.9814 - val_loss: 0.1044 - val_accuracy: 0.9707\n",
      "Epoch 15/50\n",
      "391/391 [==============================] - 1s 1ms/step - loss: 0.0611 - accuracy: 0.9827 - val_loss: 0.1098 - val_accuracy: 0.9684\n",
      "Epoch 16/50\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.0569 - accuracy: 0.9838 - val_loss: 0.1043 - val_accuracy: 0.9700\n",
      "Epoch 17/50\n",
      "391/391 [==============================] - 1s 1ms/step - loss: 0.0534 - accuracy: 0.9854 - val_loss: 0.1050 - val_accuracy: 0.9712\n",
      "Epoch 18/50\n",
      "391/391 [==============================] - 1s 1ms/step - loss: 0.0502 - accuracy: 0.9858 - val_loss: 0.1029 - val_accuracy: 0.9710\n",
      "Epoch 19/50\n",
      "391/391 [==============================] - 1s 1ms/step - loss: 0.0471 - accuracy: 0.9864 - val_loss: 0.1056 - val_accuracy: 0.9712\n",
      "Epoch 20/50\n",
      "391/391 [==============================] - 1s 1ms/step - loss: 0.0445 - accuracy: 0.9875 - val_loss: 0.1102 - val_accuracy: 0.9705\n",
      "Epoch 21/50\n",
      "391/391 [==============================] - 1s 1ms/step - loss: 0.0423 - accuracy: 0.9879 - val_loss: 0.1059 - val_accuracy: 0.9701\n",
      "Epoch 22/50\n",
      "391/391 [==============================] - 1s 1ms/step - loss: 0.0399 - accuracy: 0.9890 - val_loss: 0.1080 - val_accuracy: 0.9708\n",
      "Epoch 23/50\n",
      "391/391 [==============================] - 1s 1ms/step - loss: 0.0377 - accuracy: 0.9898 - val_loss: 0.1084 - val_accuracy: 0.9695\n",
      "Epoch 24/50\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.0356 - accuracy: 0.9902 - val_loss: 0.1065 - val_accuracy: 0.9710\n",
      "Epoch 25/50\n",
      "391/391 [==============================] - 1s 1ms/step - loss: 0.0333 - accuracy: 0.9914 - val_loss: 0.1068 - val_accuracy: 0.9709\n",
      "Epoch 26/50\n",
      "391/391 [==============================] - 1s 1ms/step - loss: 0.0319 - accuracy: 0.9916 - val_loss: 0.1113 - val_accuracy: 0.9714\n",
      "Epoch 27/50\n",
      "391/391 [==============================] - 1s 1ms/step - loss: 0.0298 - accuracy: 0.9921 - val_loss: 0.1133 - val_accuracy: 0.9705\n",
      "Epoch 28/50\n",
      "391/391 [==============================] - 1s 1ms/step - loss: 0.0281 - accuracy: 0.9926 - val_loss: 0.1177 - val_accuracy: 0.9700\n",
      "Best epoch: 18\n",
      "Epoch 1/21\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.4573 - accuracy: 0.8767 - val_loss: 0.2536 - val_accuracy: 0.9280\n",
      "Epoch 2/21\n",
      "391/391 [==============================] - 1s 1ms/step - loss: 0.2359 - accuracy: 0.9330 - val_loss: 0.2036 - val_accuracy: 0.9425\n",
      "Epoch 3/21\n",
      "391/391 [==============================] - 1s 1ms/step - loss: 0.1841 - accuracy: 0.9471 - val_loss: 0.1677 - val_accuracy: 0.9522\n",
      "Epoch 4/21\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.1527 - accuracy: 0.9562 - val_loss: 0.1444 - val_accuracy: 0.9600\n",
      "Epoch 5/21\n",
      "391/391 [==============================] - 1s 1ms/step - loss: 0.1291 - accuracy: 0.9622 - val_loss: 0.1287 - val_accuracy: 0.9634\n",
      "Epoch 6/21\n",
      "391/391 [==============================] - 1s 1ms/step - loss: 0.1138 - accuracy: 0.9671 - val_loss: 0.1235 - val_accuracy: 0.9638\n",
      "Epoch 7/21\n",
      "391/391 [==============================] - 1s 1ms/step - loss: 0.1013 - accuracy: 0.9709 - val_loss: 0.1170 - val_accuracy: 0.9663\n",
      "Epoch 8/21\n",
      "391/391 [==============================] - 1s 1ms/step - loss: 0.0910 - accuracy: 0.9740 - val_loss: 0.1089 - val_accuracy: 0.9690\n",
      "Epoch 9/21\n",
      "391/391 [==============================] - 1s 1ms/step - loss: 0.0831 - accuracy: 0.9763 - val_loss: 0.1080 - val_accuracy: 0.9685\n",
      "Epoch 10/21\n",
      "391/391 [==============================] - 1s 1ms/step - loss: 0.0761 - accuracy: 0.9784 - val_loss: 0.1018 - val_accuracy: 0.9693\n",
      "Epoch 11/21\n",
      "391/391 [==============================] - 1s 1ms/step - loss: 0.0703 - accuracy: 0.9798 - val_loss: 0.1063 - val_accuracy: 0.9694\n",
      "Epoch 12/21\n",
      "391/391 [==============================] - 1s 1ms/step - loss: 0.0649 - accuracy: 0.9813 - val_loss: 0.0978 - val_accuracy: 0.9709\n",
      "Epoch 13/21\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.0603 - accuracy: 0.9828 - val_loss: 0.0972 - val_accuracy: 0.9712\n",
      "Epoch 14/21\n",
      "391/391 [==============================] - 1s 1ms/step - loss: 0.0563 - accuracy: 0.9841 - val_loss: 0.0961 - val_accuracy: 0.9720\n",
      "Epoch 15/21\n",
      "391/391 [==============================] - 1s 1ms/step - loss: 0.0530 - accuracy: 0.9853 - val_loss: 0.0977 - val_accuracy: 0.9726\n",
      "Epoch 16/21\n",
      "391/391 [==============================] - 1s 1ms/step - loss: 0.0496 - accuracy: 0.9857 - val_loss: 0.0958 - val_accuracy: 0.9724\n",
      "Epoch 17/21\n",
      "391/391 [==============================] - 1s 1ms/step - loss: 0.0460 - accuracy: 0.9874 - val_loss: 0.0942 - val_accuracy: 0.9729\n",
      "Epoch 18/21\n",
      "391/391 [==============================] - 1s 1ms/step - loss: 0.0440 - accuracy: 0.9880 - val_loss: 0.0988 - val_accuracy: 0.9724\n",
      "Epoch 19/21\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.0413 - accuracy: 0.9887 - val_loss: 0.0990 - val_accuracy: 0.9714\n",
      "Epoch 20/21\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.0389 - accuracy: 0.9891 - val_loss: 0.0950 - val_accuracy: 0.9724\n",
      "Epoch 21/21\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.0363 - accuracy: 0.9898 - val_loss: 0.0957 - val_accuracy: 0.9726\n",
      "313/313 [==============================] - 0s 879us/step - loss: 0.0907 - accuracy: 0.9739\n",
      "Epoch 1/50\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 1.3849 - accuracy: 0.6472 - val_loss: 0.7846 - val_accuracy: 0.8364\n",
      "Epoch 2/50\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.6625 - accuracy: 0.8454 - val_loss: 0.5143 - val_accuracy: 0.8739\n",
      "Epoch 3/50\n",
      "391/391 [==============================] - 1s 1ms/step - loss: 0.5049 - accuracy: 0.8717 - val_loss: 0.4260 - val_accuracy: 0.8886\n",
      "Epoch 4/50\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.4387 - accuracy: 0.8834 - val_loss: 0.3806 - val_accuracy: 0.8984\n",
      "Epoch 5/50\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.4008 - accuracy: 0.8910 - val_loss: 0.3540 - val_accuracy: 0.9032\n",
      "Epoch 6/50\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.3756 - accuracy: 0.8969 - val_loss: 0.3358 - val_accuracy: 0.9059\n",
      "Epoch 7/50\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.3568 - accuracy: 0.9009 - val_loss: 0.3216 - val_accuracy: 0.9084\n",
      "Epoch 8/50\n",
      "391/391 [==============================] - 1s 1ms/step - loss: 0.3425 - accuracy: 0.9046 - val_loss: 0.3098 - val_accuracy: 0.9104\n",
      "Epoch 9/50\n",
      "391/391 [==============================] - 1s 1ms/step - loss: 0.3305 - accuracy: 0.9068 - val_loss: 0.3004 - val_accuracy: 0.9151\n",
      "Epoch 10/50\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.3203 - accuracy: 0.9094 - val_loss: 0.2928 - val_accuracy: 0.9170\n",
      "Epoch 11/50\n",
      "391/391 [==============================] - 1s 1ms/step - loss: 0.3116 - accuracy: 0.9113 - val_loss: 0.2850 - val_accuracy: 0.9199\n",
      "Epoch 12/50\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.3038 - accuracy: 0.9139 - val_loss: 0.2787 - val_accuracy: 0.9207\n",
      "Epoch 13/50\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.2968 - accuracy: 0.9157 - val_loss: 0.2735 - val_accuracy: 0.9227\n",
      "Epoch 14/50\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.2904 - accuracy: 0.9174 - val_loss: 0.2683 - val_accuracy: 0.9241\n",
      "Epoch 15/50\n",
      "391/391 [==============================] - 1s 1ms/step - loss: 0.2843 - accuracy: 0.9195 - val_loss: 0.2640 - val_accuracy: 0.9252\n",
      "Epoch 16/50\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.2790 - accuracy: 0.9207 - val_loss: 0.2585 - val_accuracy: 0.9264\n",
      "Epoch 17/50\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.2740 - accuracy: 0.9222 - val_loss: 0.2552 - val_accuracy: 0.9275\n",
      "Epoch 18/50\n",
      "391/391 [==============================] - 1s 1ms/step - loss: 0.2691 - accuracy: 0.9237 - val_loss: 0.2511 - val_accuracy: 0.9286\n",
      "Epoch 19/50\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.2646 - accuracy: 0.9250 - val_loss: 0.2469 - val_accuracy: 0.9296\n",
      "Epoch 20/50\n",
      "391/391 [==============================] - 1s 1ms/step - loss: 0.2602 - accuracy: 0.9264 - val_loss: 0.2436 - val_accuracy: 0.9300\n",
      "Epoch 21/50\n",
      "391/391 [==============================] - 1s 1ms/step - loss: 0.2561 - accuracy: 0.9272 - val_loss: 0.2404 - val_accuracy: 0.9313\n",
      "Epoch 22/50\n",
      "391/391 [==============================] - 1s 1ms/step - loss: 0.2523 - accuracy: 0.9286 - val_loss: 0.2370 - val_accuracy: 0.9328\n",
      "Epoch 23/50\n",
      "391/391 [==============================] - 1s 1ms/step - loss: 0.2485 - accuracy: 0.9292 - val_loss: 0.2339 - val_accuracy: 0.9335\n",
      "Epoch 24/50\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.2450 - accuracy: 0.9308 - val_loss: 0.2307 - val_accuracy: 0.9341\n",
      "Epoch 25/50\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.2415 - accuracy: 0.9312 - val_loss: 0.2290 - val_accuracy: 0.9355\n",
      "Epoch 26/50\n",
      "391/391 [==============================] - 1s 1ms/step - loss: 0.2382 - accuracy: 0.9323 - val_loss: 0.2264 - val_accuracy: 0.9352\n",
      "Epoch 27/50\n",
      "391/391 [==============================] - 1s 1ms/step - loss: 0.2351 - accuracy: 0.9330 - val_loss: 0.2230 - val_accuracy: 0.9365\n",
      "Epoch 28/50\n",
      "391/391 [==============================] - 1s 1ms/step - loss: 0.2320 - accuracy: 0.9343 - val_loss: 0.2206 - val_accuracy: 0.9372\n",
      "Epoch 29/50\n",
      "391/391 [==============================] - 1s 1ms/step - loss: 0.2291 - accuracy: 0.9351 - val_loss: 0.2178 - val_accuracy: 0.9380\n",
      "Epoch 30/50\n",
      "391/391 [==============================] - 1s 1ms/step - loss: 0.2262 - accuracy: 0.9358 - val_loss: 0.2157 - val_accuracy: 0.9390\n",
      "Epoch 31/50\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.2235 - accuracy: 0.9368 - val_loss: 0.2136 - val_accuracy: 0.9396\n",
      "Epoch 32/50\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.2208 - accuracy: 0.9376 - val_loss: 0.2115 - val_accuracy: 0.9404\n",
      "Epoch 33/50\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.2182 - accuracy: 0.9380 - val_loss: 0.2093 - val_accuracy: 0.9403\n",
      "Epoch 34/50\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.2157 - accuracy: 0.9387 - val_loss: 0.2073 - val_accuracy: 0.9424\n",
      "Epoch 35/50\n",
      "391/391 [==============================] - 1s 1ms/step - loss: 0.2134 - accuracy: 0.9395 - val_loss: 0.2051 - val_accuracy: 0.9427\n",
      "Epoch 36/50\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.2109 - accuracy: 0.9404 - val_loss: 0.2031 - val_accuracy: 0.9439\n",
      "Epoch 37/50\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.2086 - accuracy: 0.9404 - val_loss: 0.2015 - val_accuracy: 0.9445\n",
      "Epoch 38/50\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.2064 - accuracy: 0.9414 - val_loss: 0.1996 - val_accuracy: 0.9457\n",
      "Epoch 39/50\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.2043 - accuracy: 0.9419 - val_loss: 0.1983 - val_accuracy: 0.9452\n",
      "Epoch 40/50\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.2021 - accuracy: 0.9427 - val_loss: 0.1964 - val_accuracy: 0.9465\n",
      "Epoch 41/50\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.2000 - accuracy: 0.9428 - val_loss: 0.1947 - val_accuracy: 0.9466\n",
      "Epoch 42/50\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.1978 - accuracy: 0.9436 - val_loss: 0.1929 - val_accuracy: 0.9469\n",
      "Epoch 43/50\n",
      "391/391 [==============================] - 1s 1ms/step - loss: 0.1957 - accuracy: 0.9442 - val_loss: 0.1919 - val_accuracy: 0.9474\n",
      "Epoch 44/50\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.1940 - accuracy: 0.9450 - val_loss: 0.1897 - val_accuracy: 0.9482\n",
      "Epoch 45/50\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.1921 - accuracy: 0.9456 - val_loss: 0.1885 - val_accuracy: 0.9489\n",
      "Epoch 46/50\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.1902 - accuracy: 0.9467 - val_loss: 0.1868 - val_accuracy: 0.9486\n",
      "Epoch 47/50\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.1883 - accuracy: 0.9465 - val_loss: 0.1857 - val_accuracy: 0.9499\n",
      "Epoch 48/50\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.1864 - accuracy: 0.9476 - val_loss: 0.1845 - val_accuracy: 0.9493\n",
      "Epoch 49/50\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.1847 - accuracy: 0.9480 - val_loss: 0.1830 - val_accuracy: 0.9499\n",
      "Epoch 50/50\n",
      "391/391 [==============================] - 1s 1ms/step - loss: 0.1830 - accuracy: 0.9485 - val_loss: 0.1814 - val_accuracy: 0.9506\n",
      "Best epoch: 50\n",
      "Epoch 1/60\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 1.4506 - accuracy: 0.6062 - val_loss: 0.8463 - val_accuracy: 0.8223\n",
      "Epoch 2/60\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.7085 - accuracy: 0.8280 - val_loss: 0.5425 - val_accuracy: 0.8728\n",
      "Epoch 3/60\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.5310 - accuracy: 0.8631 - val_loss: 0.4413 - val_accuracy: 0.8883\n",
      "Epoch 4/60\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.4554 - accuracy: 0.8782 - val_loss: 0.3907 - val_accuracy: 0.8973\n",
      "Epoch 5/60\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.4127 - accuracy: 0.8877 - val_loss: 0.3609 - val_accuracy: 0.9040\n",
      "Epoch 6/60\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.3847 - accuracy: 0.8934 - val_loss: 0.3403 - val_accuracy: 0.9076\n",
      "Epoch 7/60\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.3642 - accuracy: 0.8983 - val_loss: 0.3256 - val_accuracy: 0.9097\n",
      "Epoch 8/60\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.3484 - accuracy: 0.9025 - val_loss: 0.3140 - val_accuracy: 0.9125\n",
      "Epoch 9/60\n",
      "391/391 [==============================] - 1s 1ms/step - loss: 0.3355 - accuracy: 0.9059 - val_loss: 0.3029 - val_accuracy: 0.9154\n",
      "Epoch 10/60\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.3244 - accuracy: 0.9087 - val_loss: 0.2945 - val_accuracy: 0.9170\n",
      "Epoch 11/60\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.3149 - accuracy: 0.9117 - val_loss: 0.2872 - val_accuracy: 0.9188\n",
      "Epoch 12/60\n",
      "391/391 [==============================] - 1s 1ms/step - loss: 0.3062 - accuracy: 0.9137 - val_loss: 0.2798 - val_accuracy: 0.9202\n",
      "Epoch 13/60\n",
      "391/391 [==============================] - 1s 1ms/step - loss: 0.2984 - accuracy: 0.9160 - val_loss: 0.2733 - val_accuracy: 0.9227\n",
      "Epoch 14/60\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.2912 - accuracy: 0.9180 - val_loss: 0.2673 - val_accuracy: 0.9233\n",
      "Epoch 15/60\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.2847 - accuracy: 0.9203 - val_loss: 0.2626 - val_accuracy: 0.9253\n",
      "Epoch 16/60\n",
      "391/391 [==============================] - 1s 1ms/step - loss: 0.2786 - accuracy: 0.9214 - val_loss: 0.2575 - val_accuracy: 0.9262\n",
      "Epoch 17/60\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.2730 - accuracy: 0.9230 - val_loss: 0.2523 - val_accuracy: 0.9283\n",
      "Epoch 18/60\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.2676 - accuracy: 0.9249 - val_loss: 0.2479 - val_accuracy: 0.9293\n",
      "Epoch 19/60\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.2627 - accuracy: 0.9263 - val_loss: 0.2436 - val_accuracy: 0.9304\n",
      "Epoch 20/60\n",
      "391/391 [==============================] - 1s 1ms/step - loss: 0.2579 - accuracy: 0.9271 - val_loss: 0.2398 - val_accuracy: 0.9319\n",
      "Epoch 21/60\n",
      "391/391 [==============================] - 1s 1ms/step - loss: 0.2536 - accuracy: 0.9288 - val_loss: 0.2365 - val_accuracy: 0.9341\n",
      "Epoch 22/60\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.2492 - accuracy: 0.9299 - val_loss: 0.2340 - val_accuracy: 0.9342\n",
      "Epoch 23/60\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.2454 - accuracy: 0.9312 - val_loss: 0.2298 - val_accuracy: 0.9357\n",
      "Epoch 24/60\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.2416 - accuracy: 0.9320 - val_loss: 0.2272 - val_accuracy: 0.9355\n",
      "Epoch 25/60\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.2379 - accuracy: 0.9328 - val_loss: 0.2236 - val_accuracy: 0.9364\n",
      "Epoch 26/60\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.2343 - accuracy: 0.9339 - val_loss: 0.2208 - val_accuracy: 0.9376\n",
      "Epoch 27/60\n",
      "391/391 [==============================] - 1s 1ms/step - loss: 0.2310 - accuracy: 0.9347 - val_loss: 0.2184 - val_accuracy: 0.9387\n",
      "Epoch 28/60\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.2277 - accuracy: 0.9360 - val_loss: 0.2157 - val_accuracy: 0.9395\n",
      "Epoch 29/60\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.2248 - accuracy: 0.9367 - val_loss: 0.2132 - val_accuracy: 0.9402\n",
      "Epoch 30/60\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.2216 - accuracy: 0.9375 - val_loss: 0.2114 - val_accuracy: 0.9410\n",
      "Epoch 31/60\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.2186 - accuracy: 0.9385 - val_loss: 0.2084 - val_accuracy: 0.9417\n",
      "Epoch 32/60\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.2158 - accuracy: 0.9397 - val_loss: 0.2058 - val_accuracy: 0.9428\n",
      "Epoch 33/60\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.2132 - accuracy: 0.9399 - val_loss: 0.2037 - val_accuracy: 0.9435\n",
      "Epoch 34/60\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.2106 - accuracy: 0.9409 - val_loss: 0.2014 - val_accuracy: 0.9440\n",
      "Epoch 35/60\n",
      "391/391 [==============================] - 1s 1ms/step - loss: 0.2080 - accuracy: 0.9418 - val_loss: 0.1998 - val_accuracy: 0.9440\n",
      "Epoch 36/60\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.2054 - accuracy: 0.9424 - val_loss: 0.1975 - val_accuracy: 0.9444\n",
      "Epoch 37/60\n",
      "391/391 [==============================] - 1s 1ms/step - loss: 0.2031 - accuracy: 0.9428 - val_loss: 0.1957 - val_accuracy: 0.9450\n",
      "Epoch 38/60\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.2007 - accuracy: 0.9438 - val_loss: 0.1936 - val_accuracy: 0.9456\n",
      "Epoch 39/60\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.1983 - accuracy: 0.9443 - val_loss: 0.1922 - val_accuracy: 0.9474\n",
      "Epoch 40/60\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.1960 - accuracy: 0.9450 - val_loss: 0.1900 - val_accuracy: 0.9468\n",
      "Epoch 41/60\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.1940 - accuracy: 0.9457 - val_loss: 0.1883 - val_accuracy: 0.9477\n",
      "Epoch 42/60\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.1918 - accuracy: 0.9462 - val_loss: 0.1867 - val_accuracy: 0.9484\n",
      "Epoch 43/60\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.1897 - accuracy: 0.9467 - val_loss: 0.1851 - val_accuracy: 0.9488\n",
      "Epoch 44/60\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.1876 - accuracy: 0.9473 - val_loss: 0.1835 - val_accuracy: 0.9486\n",
      "Epoch 45/60\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.1855 - accuracy: 0.9483 - val_loss: 0.1823 - val_accuracy: 0.9491\n",
      "Epoch 46/60\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.1837 - accuracy: 0.9485 - val_loss: 0.1804 - val_accuracy: 0.9490\n",
      "Epoch 47/60\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.1818 - accuracy: 0.9488 - val_loss: 0.1792 - val_accuracy: 0.9503\n",
      "Epoch 48/60\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.1799 - accuracy: 0.9493 - val_loss: 0.1770 - val_accuracy: 0.9506\n",
      "Epoch 49/60\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.1780 - accuracy: 0.9502 - val_loss: 0.1766 - val_accuracy: 0.9512\n",
      "Epoch 50/60\n",
      "391/391 [==============================] - 1s 1ms/step - loss: 0.1763 - accuracy: 0.9506 - val_loss: 0.1748 - val_accuracy: 0.9519\n",
      "Epoch 51/60\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.1746 - accuracy: 0.9511 - val_loss: 0.1731 - val_accuracy: 0.9528\n",
      "Epoch 52/60\n",
      "391/391 [==============================] - 1s 1ms/step - loss: 0.1727 - accuracy: 0.9519 - val_loss: 0.1719 - val_accuracy: 0.9525\n",
      "Epoch 53/60\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.1710 - accuracy: 0.9524 - val_loss: 0.1709 - val_accuracy: 0.9528\n",
      "Epoch 54/60\n",
      "391/391 [==============================] - 1s 1ms/step - loss: 0.1695 - accuracy: 0.9524 - val_loss: 0.1698 - val_accuracy: 0.9531\n",
      "Epoch 55/60\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.1678 - accuracy: 0.9533 - val_loss: 0.1680 - val_accuracy: 0.9541\n",
      "Epoch 56/60\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.1661 - accuracy: 0.9539 - val_loss: 0.1667 - val_accuracy: 0.9538\n",
      "Epoch 57/60\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.1646 - accuracy: 0.9542 - val_loss: 0.1664 - val_accuracy: 0.9539\n",
      "Epoch 58/60\n",
      "391/391 [==============================] - 1s 1ms/step - loss: 0.1631 - accuracy: 0.9549 - val_loss: 0.1647 - val_accuracy: 0.9543\n",
      "Epoch 59/60\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.1616 - accuracy: 0.9551 - val_loss: 0.1633 - val_accuracy: 0.9549\n",
      "Epoch 60/60\n",
      "391/391 [==============================] - 1s 1ms/step - loss: 0.1602 - accuracy: 0.9554 - val_loss: 0.1622 - val_accuracy: 0.9551\n",
      "313/313 [==============================] - 0s 931us/step - loss: 0.1658 - accuracy: 0.9537\n"
     ]
    }
   ],
   "source": [
    "best_models=[]\n",
    "for hp in top_params:\n",
    "    model=get_best_trained_model(hp)\n",
    "    model.evaluate(x_test, y_test)\n",
    "    best_models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_models = tuner.get_best_models(top_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
