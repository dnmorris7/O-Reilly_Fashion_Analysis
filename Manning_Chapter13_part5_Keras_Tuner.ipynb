{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\david\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\david\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\david\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\david\\anaconda3\\lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 23.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install keras-tuner -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper Parameter Optimization\n",
    "Keras Tuner allows you to replace hardcoded hyper-parameters with a *search space;* a range of possible hyperparameter choices.  \n",
    "\n",
    "To specify a *search space*, you'll define a model building function that takes hyperparameter (hp) ranges of values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    units = hp.Int('units', min_value=16, max_value=64, step=32)\n",
    "    model = keras.Sequential([\n",
    "        layers.Dense(units, activation='relu'),\n",
    "        layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "    optimizer = hp.Choice('optimizer', values=['rmsprop','adam', 'sgd'])\n",
    "    model.compile(optimizer=optimizer, loss = 'sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you wish to adopt a more modular and configurable approach, you can also extend the HyperModle class and override the build method. This is useful if you want to use the same model architecture for different problems, or if you want to use the same model architecture with different hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_tuner as kt\n",
    "\n",
    "class SimpleMLP(kt.HyperModel):\n",
    "    def __init__(self, input_shape, num_classes):\n",
    "        self.input_shape = input_shape\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "    def build(self, hp):\n",
    "        units = hp.Int('units', min_value=16, max_value=64, step=32)\n",
    "        model = keras.Sequential([\n",
    "            layers.Dense(units, activation='relu'),\n",
    "            layers.Dense(self.num_classes, activation='softmax')\n",
    "        ])\n",
    "        optimizer = hp.Choice('optimizer', values=['rmsprop','adam', 'sgd'])\n",
    "        model.compile(optimizer=optimizer, loss = 'sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "        return model\n",
    "\n",
    "hypermodel = SimpleMLP(input_shape=(784,), num_classes=10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuner\n",
    "Next step is to define a *tuner* which is a for loop that will repeatedly...\n",
    "> Pick a set of hyperparameter values\n",
    "> Call the model-building function with these values to create a model\n",
    "> Train the model and record its metrics\n",
    "\n",
    "Several tuners are pre-built into kt such as *RandomSearch, BayesianOptimization, Hyperband.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build the tuner\n",
    "tuner = kt.BayesianOptimization(build_model, objective='val_accuracy', max_trials=10, executions_per_trial=2, directory='mnist_kt_test', project_name='intro_to_kt_mnist', overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search space summary\n",
      "Default search space size: 2\n",
      "units (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 16, 'max_value': 64, 'step': 32, 'sampling': 'linear'}\n",
      "optimizer (Choice)\n",
      "{'default': 'rmsprop', 'conditions': [], 'values': ['rmsprop', 'adam', 'sgd'], 'ordered': False}\n"
     ]
    }
   ],
   "source": [
    "tuner.search_space_summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now that the MLP tuner's build and constraints are defined, load the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "x_train = x_train.reshape(-1, 28*28).astype('float32') / 255.0\n",
    "x_test = x_test.reshape(-1, 28*28).astype('float32') / 255.0\n",
    "x_train_full = x_train\n",
    "y_train_full = y_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_val_samples = 10000\n",
    "x_train, x_val = x_train_full[:-num_val_samples], x_train_full[-num_val_samples:]\n",
    "y_train, y_val = y_train_full[:-num_val_samples], y_train_full[-num_val_samples:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 Complete [00h 01m 23s]\n",
      "val_accuracy: 0.9712500274181366\n",
      "\n",
      "Best val_accuracy So Far: 0.9736999869346619\n",
      "Total elapsed time: 00h 20m 31s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "callbacks = [keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)]\n",
    "\n",
    "tuner.search(x_train, y_train, epochs=50, validation_data=(x_val, y_val), callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-0.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-0.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-1.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-1.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4\n",
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-0.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-0.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-1.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-1.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4\n",
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-0.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-0.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-1.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-1.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.5\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.6\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.7\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.8\n"
     ]
    }
   ],
   "source": [
    "top_n = 3\n",
    "top_params = tuner.get_best_hyperparameters(num_trials=top_n)\n",
    "top_models = tuner.get_best_models(num_models=top_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_epoch(hp):\n",
    "    model=build_model(hp)\n",
    "    callbacks = [keras.callbacks.EarlyStopping(monitor='val_loss', mode=\"min\", patience=10)]\n",
    "    history = model.fit(x_train, y_train, epochs=50, validation_data=(x_val, y_val), batch_size=128, callbacks=callbacks)\n",
    "    val_loss_per_epoch = history.history['val_loss']\n",
    "    best_epoch = val_loss_per_epoch.index(min(val_loss_per_epoch)) + 1\n",
    "    print(f\"Best epoch: {best_epoch}\" )\n",
    "    return best_epoch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_trained_model(hp):\n",
    "    best_epoch = get_best_epoch(hp)\n",
    "    #model = build_model(hp)\n",
    "    model.fit(x_train, y_train, epochs=int(best_epoch*1.2), validation_data=(x_val, y_val), batch_size=128)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 0.4562 - accuracy: 0.8780 - val_loss: 0.2462 - val_accuracy: 0.9307\n",
      "Epoch 2/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 0.2357 - accuracy: 0.9328 - val_loss: 0.1989 - val_accuracy: 0.9458\n",
      "Epoch 3/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 0.1864 - accuracy: 0.9456 - val_loss: 0.1659 - val_accuracy: 0.9544\n",
      "Epoch 4/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 0.1553 - accuracy: 0.9553 - val_loss: 0.1456 - val_accuracy: 0.9594\n",
      "Epoch 5/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 0.1339 - accuracy: 0.9617 - val_loss: 0.1372 - val_accuracy: 0.9623\n",
      "Epoch 6/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 0.1174 - accuracy: 0.9662 - val_loss: 0.1285 - val_accuracy: 0.9644\n",
      "Epoch 7/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 0.1047 - accuracy: 0.9700 - val_loss: 0.1239 - val_accuracy: 0.9644\n",
      "Epoch 8/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 0.0941 - accuracy: 0.9730 - val_loss: 0.1144 - val_accuracy: 0.9684\n",
      "Epoch 9/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 0.0859 - accuracy: 0.9752 - val_loss: 0.1118 - val_accuracy: 0.9692\n",
      "Epoch 10/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 0.0792 - accuracy: 0.9770 - val_loss: 0.1058 - val_accuracy: 0.9687\n",
      "Epoch 11/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 0.0724 - accuracy: 0.9786 - val_loss: 0.1030 - val_accuracy: 0.9706\n",
      "Epoch 12/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 0.0666 - accuracy: 0.9805 - val_loss: 0.1027 - val_accuracy: 0.9708\n",
      "Epoch 13/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 0.0624 - accuracy: 0.9820 - val_loss: 0.1032 - val_accuracy: 0.9716\n",
      "Epoch 14/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 0.0573 - accuracy: 0.9834 - val_loss: 0.1060 - val_accuracy: 0.9702\n",
      "Epoch 15/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 0.0543 - accuracy: 0.9846 - val_loss: 0.1032 - val_accuracy: 0.9723\n",
      "Epoch 16/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 0.0503 - accuracy: 0.9861 - val_loss: 0.1002 - val_accuracy: 0.9734\n",
      "Epoch 17/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 0.0475 - accuracy: 0.9866 - val_loss: 0.1033 - val_accuracy: 0.9719\n",
      "Epoch 18/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 0.0442 - accuracy: 0.9877 - val_loss: 0.0999 - val_accuracy: 0.9728\n",
      "Epoch 19/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 0.0414 - accuracy: 0.9885 - val_loss: 0.1027 - val_accuracy: 0.9725\n",
      "Epoch 20/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 0.0393 - accuracy: 0.9887 - val_loss: 0.0982 - val_accuracy: 0.9739\n",
      "Epoch 21/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 0.0360 - accuracy: 0.9900 - val_loss: 0.0989 - val_accuracy: 0.9739\n",
      "Epoch 22/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 0.0346 - accuracy: 0.9902 - val_loss: 0.1000 - val_accuracy: 0.9725\n",
      "Epoch 23/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 0.0319 - accuracy: 0.9912 - val_loss: 0.1030 - val_accuracy: 0.9734\n",
      "Epoch 24/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 0.0308 - accuracy: 0.9915 - val_loss: 0.1007 - val_accuracy: 0.9733\n",
      "Epoch 25/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 0.0286 - accuracy: 0.9923 - val_loss: 0.1071 - val_accuracy: 0.9734\n",
      "Epoch 26/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 0.0271 - accuracy: 0.9925 - val_loss: 0.1057 - val_accuracy: 0.9714\n",
      "Epoch 27/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.0252 - accuracy: 0.9935 - val_loss: 0.1028 - val_accuracy: 0.9728\n",
      "Epoch 28/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 0.0237 - accuracy: 0.9941 - val_loss: 0.1055 - val_accuracy: 0.9726\n",
      "Epoch 29/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 0.0223 - accuracy: 0.9940 - val_loss: 0.1090 - val_accuracy: 0.9723\n",
      "Epoch 30/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 0.0211 - accuracy: 0.9949 - val_loss: 0.1085 - val_accuracy: 0.9726\n",
      "Best epoch: 20\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_37556\\1587805002.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mbest_models\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mhp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtop_params\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mget_best_trained_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mbest_models\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_37556\\1935505882.py\u001b[0m in \u001b[0;36mget_best_trained_model\u001b[1;34m(hp)\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mbest_epoch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_best_epoch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;31m#model = build_model(hp)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbest_epoch\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m1.2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "best_models=[]\n",
    "for hp in top_params:\n",
    "    model=get_best_trained_model(hp)\n",
    "    model.evaluate(x_test, y_test)\n",
    "    best_models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_models = tuner.get_best_models(top_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<keras.engine.sequential.Sequential object at 0x0000028E81609288>, <keras.engine.sequential.Sequential object at 0x0000028E80266AC8>, <keras.engine.sequential.Sequential object at 0x0000028E80266C88>]\n"
     ]
    }
   ],
   "source": [
    "#show the best models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in mnist_kt_test\\intro_to_kt_mnist\n",
      "Showing 10 best trials\n",
      "Objective(name=\"val_accuracy\", direction=\"max\")\n",
      "\n",
      "Trial 2 summary\n",
      "Hyperparameters:\n",
      "units: 48\n",
      "optimizer: adam\n",
      "Score: 0.9735999703407288\n",
      "\n",
      "Trial 4 summary\n",
      "Hyperparameters:\n",
      "units: 48\n",
      "optimizer: sgd\n",
      "Score: 0.9690999984741211\n",
      "\n",
      "Trial 0 summary\n",
      "Hyperparameters:\n",
      "units: 16\n",
      "optimizer: rmsprop\n",
      "Score: 0.9564999938011169\n",
      "\n",
      "Trial 1 summary\n",
      "Hyperparameters:\n",
      "units: 16\n",
      "optimizer: adam\n",
      "Score: 0.9539999961853027\n",
      "\n",
      "Trial 3 summary\n",
      "Hyperparameters:\n",
      "units: 16\n",
      "optimizer: sgd\n",
      "Score: 0.9538000226020813\n"
     ]
    }
   ],
   "source": [
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras_tuner.engine.hyperparameters.hyperparameters.HyperParameters at 0x28e817e67c8>]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuner.get_best_hyperparameters(num_trials=top_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.4921 - accuracy: 0.8641 - val_loss: 0.2526 - val_accuracy: 0.9302\n",
      "Epoch 2/50\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.2436 - accuracy: 0.9308 - val_loss: 0.2076 - val_accuracy: 0.9443\n",
      "Epoch 3/50\n",
      "391/391 [==============================] - 1s 1ms/step - loss: 0.1915 - accuracy: 0.9460 - val_loss: 0.1716 - val_accuracy: 0.9514\n",
      "Epoch 4/50\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.1607 - accuracy: 0.9546 - val_loss: 0.1520 - val_accuracy: 0.9558\n",
      "Epoch 5/50\n",
      "391/391 [==============================] - 1s 1ms/step - loss: 0.1373 - accuracy: 0.9609 - val_loss: 0.1359 - val_accuracy: 0.9604\n",
      "Epoch 6/50\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.1208 - accuracy: 0.9658 - val_loss: 0.1283 - val_accuracy: 0.9623\n",
      "Epoch 7/50\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.1071 - accuracy: 0.9697 - val_loss: 0.1215 - val_accuracy: 0.9650\n",
      "Epoch 8/50\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.0964 - accuracy: 0.9723 - val_loss: 0.1109 - val_accuracy: 0.9677\n",
      "Epoch 9/50\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.0871 - accuracy: 0.9752 - val_loss: 0.1100 - val_accuracy: 0.9678\n",
      "Epoch 10/50\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.0793 - accuracy: 0.9773 - val_loss: 0.1088 - val_accuracy: 0.9685\n",
      "Epoch 11/50\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.0725 - accuracy: 0.9793 - val_loss: 0.1017 - val_accuracy: 0.9705\n",
      "Epoch 12/50\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.0667 - accuracy: 0.9813 - val_loss: 0.1014 - val_accuracy: 0.9707\n",
      "Epoch 13/50\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.0615 - accuracy: 0.9828 - val_loss: 0.1023 - val_accuracy: 0.9696\n",
      "Epoch 14/50\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.0567 - accuracy: 0.9841 - val_loss: 0.1027 - val_accuracy: 0.9696\n",
      "Epoch 15/50\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.0518 - accuracy: 0.9855 - val_loss: 0.0995 - val_accuracy: 0.9718\n",
      "Epoch 16/50\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.0488 - accuracy: 0.9862 - val_loss: 0.1011 - val_accuracy: 0.9709\n",
      "Epoch 17/50\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.0448 - accuracy: 0.9878 - val_loss: 0.0996 - val_accuracy: 0.9721\n",
      "Epoch 18/50\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.0415 - accuracy: 0.9890 - val_loss: 0.1043 - val_accuracy: 0.9707\n",
      "Epoch 19/50\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.0392 - accuracy: 0.9895 - val_loss: 0.1008 - val_accuracy: 0.9715\n",
      "Epoch 20/50\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.0358 - accuracy: 0.9907 - val_loss: 0.1011 - val_accuracy: 0.9721\n",
      "Epoch 21/50\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.0333 - accuracy: 0.9914 - val_loss: 0.1015 - val_accuracy: 0.9722\n",
      "Epoch 22/50\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.0316 - accuracy: 0.9917 - val_loss: 0.1008 - val_accuracy: 0.9704\n",
      "Epoch 23/50\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.0289 - accuracy: 0.9924 - val_loss: 0.1098 - val_accuracy: 0.9709\n",
      "Epoch 24/50\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.0277 - accuracy: 0.9929 - val_loss: 0.1046 - val_accuracy: 0.9713\n",
      "Epoch 25/50\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.0252 - accuracy: 0.9941 - val_loss: 0.1055 - val_accuracy: 0.9730\n",
      "Best epoch: 15\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_37556\\1746080647.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mbest_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_best_trained_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtop_params\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_37556\\1935505882.py\u001b[0m in \u001b[0;36mget_best_trained_model\u001b[1;34m(hp)\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mbest_epoch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_best_epoch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;31m#model = build_model(hp)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbest_epoch\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m1.2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "best_model = get_best_trained_model(top_params[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
